[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Diary",
    "section": "",
    "text": "Introduction\nAbout this website\nThis website will include a summary of the content of CASA0023 Remotely Sensing Cities and Environments and my thoughts and ideas based on the content of the course.\nMany thanks to the lecturer Dr Andrew MacLachlan and all CASA teachers for their contributions to this course.\nAbout me\nHi, I am Xianlai Yin from Jiangxi, China. I am currently studying in MSc Urban Spatial Science at the Bartlett Centre for Advanced Spatial Analysis, UCL. My undergraduate degree is in Urban and Rural Planning at Chang’an University.\nMy research experience is mainly related to urban planning, including the study of the spatial structure of urban agglomerations based on social network analysis methods, and the study of the resilience of urban transport networks. My work experience is mainly in the field of urban construction, including working as an intern planner at the institute of urban planning and design and as an intern in the smart city department of a real estate company.\nI am very interested in the application of spatial data analysis in the field of urban planning, and remote sensing can provide a wide and diverse source of data. Therefore, I took CASA0023 in the hope of studying the application of remote sensing technology in the field of urban analysis. Meanwhile, during the creation of this learning dairy, thinking will mainly from the perspective of urban planning.\n\n\nContent\n\n\n\nWEEK\nTHEME\n\n\n\n\nWEEK 1\nAn Introduction to Remote Sensing\n\n\nWEEK 2\nPortfolio tools: Xaringan and Quarto\n\n\nWEEK 3\nRemote sensing data\n\n\nWEEK 4\nPolicy applications\n\n\nWEEK 5\nAn introduction to Google Earth Engine\n\n\nWEEK 6\nClassification\n\n\nWEEK 7\nClassification the big questions and accuracy\n\n\nWEEK 8\nTemperature and policy"
  },
  {
    "objectID": "WEEK1.html",
    "href": "WEEK1.html",
    "title": "WEEK 1",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 1, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK1.html#summary-lecture",
    "href": "WEEK1.html#summary-lecture",
    "title": "WEEK 1",
    "section": "1 Summary: lecture",
    "text": "1 Summary: lecture\n\n\n\nMindmap of Week 1 Leacture\n\n\n\n\n1.1 Remote sensing\n\nDefinition\nNASA defines remote sensing as acquiring information from a distance, interchangeable used with Earth Observation or EO.\n\n\nData acquisition\nThis is achieved through sensors mounted on a platform, e.g. satellites, planes (aerial imagery), drones, phones, free standing on the ground or sea (with hand held devices), there are more than 150 satellites in orbit carrying sensors.\n\n\nAdvantages\n\nMass of data: satellites collect data on the same points on Earth every day to every 16 days\nFrequency of update and less reliance on authorities (e.g. London Atlas)\nMore free resources to process large volumes of data (e.g. Google Earth Engine)\n\n\n\nTypes of sensor\nPassive sensor\n\nUse energy that is available\nDon’t emit anything\nUsually detecting reflected energy from the sun\nEnergy is in electromagnetic waves…\nSuch as: Human eye, camera, satellite sensor\n\nActive sensor\n\nHave an energy source for illumination\nActively emits electormagentic waves and then waits to receive\nSuch as: Radar, X-ray, LiDAR\n\n\n\n\n1.2 Electromagentic waves\n\n\n\n\n\n\nTerms\n\n\n\n\nWaves of an electromagnetic field, travel through space and carry radiant energy = Electromagnetic radiation (EMR). Waves are part of the EMR spectrum.\nEnergy carried by EMR waves = radiant energy\nEnergy per unit of time = radiant flux\nEnergy from the sun = incoming short wave radiation or shortwave radiation\nEnergy (solar power) from the sun per unit area per unit time (from electromagnetic radiation) = solar irradiance (per unit time - flux)\nEnergy leaving a surface per unit area per unit time = Exitance (emittance) (per unit time - flux)\nFlux means time here.\n\n\n\n\nElectromagnetic radiation (EMR)\nEMR has both electric and magnetic fields, propagates (moves) as waves: c = vλ\n\nc = velocity of light 3 x 10^8 meters per second\nv = frequency, rate of oscillation\nλ = wavelength, distance between two crests\n\nEMR isn’t automatically reflected. It experiences a number of changes prior to hitting the sensor\n\nSurface: Energy being absorbed by the surface and being transmitted through the surface\nAtmospheric: Energy can be scattered by particles in the atmosphere\n\n\n\n\n1.3 Interacting with Earth’s surface\n\nAtmospheric scattering\n\nRayleigh = particles are very small compared to the wavelength\nMie = particles are the same size compared to the wavelength\nNon selective = particles are much larger than the wavelength\n\n\n\nSynthetic Aperture Radar (SAR)\n\nRadar collects at longer wavelengths than optical sensors - pass through clouds that have smaller particle sizes (wavelength dictates how far it can penetrate into medium)\nHas it’s own bands - e.g. P, L, S, C, X, Ku, K\nCollects data at night\n\n\n\nBidirectional Reflectance Distribution Function (BRDF)\n\nView (e.g. sensor) and illumination (e.g. sun) angles can change\nEnergy being reflected from the surface that is smooth or diffuse\n\n\n\nPolarization\nDefinition\nApplicable to Radar: Electromagnetic waves are polarized and the direction depends on the oscillation of the electromagnetic field. When they are reflected from the surface the waves can be linked to surface properties - roughness, shape, orientation, moisture, salinity, density.\nDifferent ploarizations\n\nSingle polarization: same polarization transmitted and received = 1 horizontal (or vertical)\nDual polarization: One sent, different one received = transmits and receives both horizontal and vertical\nQuad polarization: system can transmit and receive four types = emitted in horizontal (H) and received in horizontal (H)\n\n\n\n\n1.4 Remote sensing data\n\nData formats\n\nband interleaved by line (BIL)\nband sequential (BSQ)\nband interleaved by pixel (BIP)\nGeoTIFF (most common)\n\n\n\nFour resolutions\n\nSpatial = the size of the raster grid per pixel (e.g. 20cm or 30m)\nSpectral = the number of bands it records data in…more soon\nTemporal = the time it revisits (e.g. daily, every 7 days, on demand)\nRadiometric = identify differences in light or reflectance, in practice this is the range of possible values.\n\n\n\n\nSpectral resolution. Source: NASA Science\n\n\n\n\nType of orbit\n\ngeosynchronous orbit (GSO) = satellite matches the Earth’s rotation\ngeostationary orbit = holds same position, usually only for communications but some sensors are geostationary."
  },
  {
    "objectID": "WEEK1.html#summary-practical",
    "href": "WEEK1.html#summary-practical",
    "title": "WEEK 1",
    "section": "2 Summary: practical",
    "text": "2 Summary: practical"
  },
  {
    "objectID": "WEEK1.html#application",
    "href": "WEEK1.html#application",
    "title": "WEEK 1",
    "section": "3 Application",
    "text": "3 Application\n\nThis week’s lecture is mainly about the basic knowledge of remote sensing and Electromagnetic radiation (EMR), so I would like to introduce some of the remote sensing applications based on spectral characteristics.\n\n\n2.1 Remote sensing applications based on spectral features\nRemote sensing uses spectral features to identify, classify and analyse a variety of features on the surface or in the atmosphere. Remote sensing has many applications using spectral features：\n\nIn the field of agriculture, the spectral characteristics of vegetation can be used to monitor the growth of crops, damage, yield prediction, etc.\nIn the field of environmental, the spectral characteristics of water bodies, soil and atmosphere can be used to monitor water quality, soil types, pollutant types and concentrations, etc.\nIn the field of geology, the spectral characteristics of rocks, minerals, etc. can be used to detect mineral resources, geological formations, seismic activity, etc.\nIn the field of urban planning, the spectral characteristics of buildings, roads, etc. can be used to extract urban spatial information, assess the level of urban development and influencing factors, etc.\n\nThe specific application methods of remote sensing based on spectral features in the field of urban planning are mainly as follows:\n\nUsing remote sensing images to obtain information on the current situation of land use, analyse the structure and spatial distribution characteristics of urban land use, and provide basic data for urban planning.\nUsing remote sensing images for urban ecological environment evaluation, monitoring urban heat island effect, air quality, tree health, water quality and other environmental indicators, and providing ecological guarantee for urban planning.\nUse remote sensing imagery for urban construction change monitoring, identifying the impact of urban construction activities on land use, and providing dynamic management for urban planning.\n\n\n\n2.2 Application case\n\n\n\n\n\n\nSourse\n\n\n\nCharacterizing and classifying urban tree species using bi-monthly terrestrial hyperspectral images in Hong Kong , Sourse: Abbas et al. (2021)\n\n\nUrban trees exhibit a wide range of ecosystem services that have long been unveiled and increasingly reported. The ability to map tree species and analyze tree health conditions would become vividly essential. Remote sensing techniques, especially hyperspectral imaging, are being evolved for species identification and vegetation monitoring from spectral reponse patterns.\n\n\n\nAn example of image clustering and corresponding spectral signatures of classes. The shadow class in grey represents canopy shadow and/or branches, and the shadow class in orange indicates shaded leaves.\n\n\nIn this study, a hyperspectral library for urban tree species in Hong Kong was established comprising 75 urban trees belonging to 19 species. 450 bi-monthly images were acquired by a terrestrial hyperspectral camera (SPECIM-IQ) from November 2018 to October 2019. A Deep Neural Network classification model was developed to identify tree species from the hyperspectral imagery with an overall accuracy ranging from 85% to 96% among different seasons. Representative spectral reflectance curves of healthy and unhealthy conditions for each species were extracted and analyzed. This can be used to identify urban trees and monitor their health.\n\n\n\nThe overall workflow of species classification framework using the Deep Neural Network modelling."
  },
  {
    "objectID": "WEEK1.html#reflection",
    "href": "WEEK1.html#reflection",
    "title": "WEEK 1",
    "section": "4 Reflection",
    "text": "4 Reflection\nDuring this week I have learnt about the basics of remote sensing and Electromagnetic radiation (EMR), which has greatly broadened my horizons when researching urban. Due to limited data collection facilities, detailed urban datasets (e.g. traffic flow data, mobile phone signalling data, etc.) are only available for main cities in developed areas, which makes many studies not reproducible in a wide range of non-developed or small cities. However, the extensive coverage of remote sensing data compensates well for this shortcoming, and the variety of data collected through the rich diversity of sensors can be of great help in urban (or regional) analysis.\n\n\n\n\nAbbas, Sawaid, Qian Peng, Man Sing Wong, Zhilin Li, Jicheng Wang, Kathy Tze Kwun Ng, Coco Yin Tung Kwok, and Karena Ka Wai Hui. 2021. “Characterizing and Classifying Urban Tree Species Using Bi-Monthly Terrestrial Hyperspectral Images in Hong Kong.” ISPRS Journal of Photogrammetry and Remote Sensing 177 (July): 204–16. https://doi.org/10.1016/j.isprsjprs.2021.05.003."
  },
  {
    "objectID": "WEEK2.html",
    "href": "WEEK2.html",
    "title": "WEEK 2",
    "section": "",
    "text": "Homework: Introduction to Hyperspectral Radiometer\nThis website and this slide can be used as a presentation of what I learnt the content of this week."
  },
  {
    "objectID": "WEEK3.html",
    "href": "WEEK3.html",
    "title": "WEEK 3",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 3, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK3.html#summary-lecture",
    "href": "WEEK3.html#summary-lecture",
    "title": "WEEK 3",
    "section": "1 Summary: lecture",
    "text": "1 Summary: lecture\n\n\n\nMindmap of Week 3 Leacture\n\n\n\n\n1.1 Pre-knowledge\n\nDifferent sensors\n\nMSS (Multispectral Scanner)\nRBV (Return Beam Vidicon Camera)\n\n\n\nPush broom vs Whisk broom\n\nWhisk broom or spotlight or across track scanners: Mirror reflects light onto 1 detector - Landsat\nPush broom or along track scanners: several detectors that are pushed along - SPOT, Quickbird\n\n\n\n\n1.2 Corrections\n\nRegression\n\\[\ny_i=\\beta_0+\\beta_1x_i+\\varepsilon_i\n\\]\n\nβ0 is the intercept (the value of y when x = 0)\nβ1 the ‘slope’ the change in the value of y for a 1 unit change in the value of x\nϵi is a random error term (positive or negative)- if you add all of the vertical differences between the blue line and all of the residuals, it should sum to 0\nAny value of y along the blue line can be modeled using the corresponding value of x\n\n\n\nGeometric correction\nWhat leads to image distortions\n\nView angle (off-nadir)\nTopography (e.g. hills not flat ground)\nWind (if from a plane)\nRotation of the earth (from satellite)\n\nGeometric correction solution\n\n\n\nGeometric correction. Source: Abdul Basith\n\n\n\nIdentify Ground Control Points (GPS) to match known points in the image and a reference dataset\nTake the coordinates and model them to give geometric transformation coefficients, linear regression with our distorted x or y as the dependent or independent\n\nInput to output (forward mapping): the issue with this is that we are modelling the rectified x and y which could fall anywhere on the gold standard map (e.g. not on a grid square or at a floating point)\nOutput to input (backward mapping): for every value in the output (gold standard) pixel we can get a value in the original input image. The images are distorted as so might not completely overlap. The goal is to match the distorted image with the gold standard image, so we want the pixels to line up\n\nPlot these and try to minimise the RMSE - Jensen sets a RMSE value of 0.5, typically might add more GCPs to reduce the RMSE (The model with the lowest RMSE will fit best)\n\nRMSE: (observed - predicted (the residual))^2, sum them and divide by number of data points, square root that total\nResample methods: Nearest Neighbor, Linear, Cubic, Cubic spline\n\n\n\n\nAtmospheric correction\nNecessary and unnecessary atmospheric correction\n\nNecessary\n\nBiophysical parameters needed (e.g. temperature, leaf area index, NDVI)\nUsing spectral signatures through time and space\n\nUnnecessary\n\nClassification of a single image\nIndependent classification of multi date imagery\nComposite images (combining images)\nSingle dates or where training data extracted from all data\n\n\nAtmospheric correction in action\n\n\n\nAtmospheric correction examples of three scenes (Bands 1, 2, and 3). Source: Liang et al. 2001\n\n\n\nAbsorption and scattering create the haze = reduces contrast of image\nScattering = can create the “adjacency effect”, radiance from pixels nearby mixed into pixel of interest\n\nAtmospheric correction types\n\nRelative (to something)\n\nNormalize\n\nNormalize intensities of different bands within a single image\nNormalise intensities of bands from many dates to one date\n\nDark object subtraction (DOS) or histogram adjustment\n\nSearches each band for the darkest value then subtracts that from each pixel\nLandsat bands 1-3 (visible) have increased scattering vs longer wavelengths\n\nPsuedo-invariant Features (PIFs)\n\nAssume brightness pixels linearly related to a base image\nRegression per band\nAdjust the image based on the regression result\nHere y is the value of our base. To get y we multiply our new date pixel (x) by the coefficient and add the intercept value\nApply this to the rest of the pixels\n\n\nAbsolute (definitive)\n\nMethod\n\nChange digital brightness values into scaled surface reflectance. We can then compare these scaled surface reflectance values across the planet\nWe do this through atmospheric radiative transfer models and there are many to select from\nHowever, nearly all assume atmospheric measurements are available which are used to “invert” the image radiance to scaled surface reflectance\nThe scattering and absorption information comes from atmopshierc radiative transfer code such as MODTRAN 4+ and the Second Simulation of the Satellite Signal in the Solar Spectrum (6S), which can now be used through python - called Py6S\n\nAbsolute Data requirements\n\nAn atmopsheric model (summer, tropical): usually you can select from the tool\nLocal atmopsheric visibility: from a weather station, like airports\nImage altitude\n\nAbsolute Tools\n\nACORN: Atmopsehic CORection Now\nFLAASH: Fast Line of-sight Atmopsheric Analysis\nQUAC: Quick Atmopsheric Correction\nATCOR: The ATmospheric CORrection program\nSMAC: Simplified Model for Atmospheric Correction (SMAC)\n\n\nEmpirical Line Correction\n\nWe can go and take measurements in situ using a field spectrometer, this does require measurements at the same time as the satellite overpass\nThen use these measurements in linear regression against the satellite data raw digital number\n\n\n\n\nOrthorectification / Topographic correction\n\n\n\nA view captured from an oblique angle (for example, 25°, left) must be corrected for relief displacement caused by terrain to generate the orthorectified view (looking straight down, right). Orthoimagery is produced by calculating the nadir view for every pixel. Source: Esri Insider, 2016\n\n\nA subset of georectification\n\nGeorectification = giving coordinates to an image\nOrthorectification = removing distortions… making the pixels viewed at nadir (straight down)\n\nRequires\n\nSensor geometry\nAn elevation model\n\nSoftware / formulas to do this\n\nJensen covers the following formulas: Cosine correction, Minnaert correction, Statistical Empirical correction, C Correction (advancing the Cosine)\nSoftware: QGIS, SAGA GIS, R package topocorr, R package RStoolbox\n\nSolar location\n\nSolar azimuth = compass angle of the sun (N =0°) 90° (E) at sunrise and 270° (W) at sunset\nSolar zenith = angle of local zenith (above the point on ground) and sun from vertical (90° - elevation)\n\n\n\nRadiometric calibration\n\nSensors capture image brightness and distributed as a Digital Number (or DN) - allows for efficient storage but has no units\nSpectral radiance is the amount of light within a band from a sensor in the field of view (FOV), it is independent of the sensor, measured in Watts (power or light here)\nDN to spectral radiance = radiometric calibration\nSensor calibration = the relationship between Gain and Bias are usually provided but we can calcaulte them\n\n\n\n\n\n\n\nTerms\n\n\n\n\nRadiance: refers to any radiation leaving the Earth (i.e. upwelling, toward the sensor\n\nMight also be called Top of Atmosphere (TOA) radiance\nHow much light the instrument sees in meaningful units but still have effects of: Light source, atmosphere and surface material\nWe can remove the effects of the light source to generate Top of Atmosphere reflectance but usually this is combined within the radiance to reflectance step\n\nIrradiance: is used to describe downwelling radiation reaching the Earth from the sun\nDigital number (DN)\n\nIntensity of the electromagnetic radiation per pixel\nPixel values that aren’t calibrated and have no unit\nHave light source\nEffects of sensor + atmosphere + material\nValues range from 0 - 255 (Lansat 5) = 8 bit or 0 - 65536 Landsat 8 (12 bit)\n\nReflectance: We need to account for atmospheric and illumination effects to create reflectance. BUT this typically doesn’t deal with shadows and directional effects (e.g. viewing angles) = apparent reflectance However, this is often called reflectance\n\nReflectance is a property of a material (e.g. reflectance of grass is a property of grass)\nThe issue with radiance is that is contains physical properties AND is dependent on the light source\n\nHemispherical reflectance: all of the light leaving the surface goes straight to the sensor (nothing is intercepted or at an angle)\nPath radiance: radiance reflected above the surface (e.g. scattering)\nAtmospheric attenuation: absorption of EMR due to materials in atmosphere (e.g. water vapour)\nLocal: specific to pixel\n`Neighbourhood: pixels within a range (nearby)\n\n\n\n\n\n\n1.3 Data joining and enhancement\n\nJoining data sets\n\nThis is termed “Mosaicking” in remote sensing - but it’s not much different to merging in GIS\nIn Remote Sensing we usually feather the images together\nThis creates a seamless mosaic or image(s)\nThe dividing line is termed the seamline\nWe have a base image and “other” or second image\n\n\n\nHow to join data sets\n\nStandardization (dividing the SR value by a maximum value per band) and normalization (divide the standarised value by the sum of values across all bands) applied to each image\nUndertake further relative radiometric normalization\nClassify each image alone\nCalculate other metrics from the image\n\n\n\nImage enhancement\nContrast enhancement\n\n\n\nContrast enhancement in QGIS. Source: Atilo Francois\n\n\n\nMinimum - Maximum\nPercentage Linear and Standard Deviation\nPiecewise Linear Contrast Stretch\n\nRatio\n\nBand ratioing means dividing the pixels in one band by the corresponding pixels in a second band.\nExample: Normalized Burn Ratio = (NIR - SWIR) / (NIR + SWIR)\n\nIn Landsat 4-7, NBR = (Band 4 – Band 7) / (Band 4 + Band 7)\nIn Landsat 8-9, NBR = (Band 5 – Band 7) / (Band 5 + Band 7)\n\n\nFiltering\n\nLow pass or low frequency (averages the surrounding pixels)\nHigh pass or high frequency - enhance local variations\nEdge enhancement\n\nPCA (Principal Component)\n\nTransform multi-spectral data into uncorrelated and smaller dataset\nHas most of the original information\nReduces future computation “dimensionatliy reduction”\nThe first component will capture most of the variance within the dataset\nIn R this is from the RStoolbox packagerasterPCA()\nPCA example, multi-date PCA - bands from both time points are combined into one image, then PCA\n\nTexture\n\nImages just use tonal (spectral) data not texture\nTexture: spatial variation of gray values\nFirst order (occurrence): use counts or occurrences\nSecond order(co-occurrence): relationship between pixel pairs “a function of both the angular relationship and distance between two (or kernel) neighboring pixels”\n\nFusion\nImage fusion is where data from multiple sensors / sources is fused together\n\nPan sharpen\nData Fusion"
  },
  {
    "objectID": "WEEK3.html#summary-practical",
    "href": "WEEK3.html#summary-practical",
    "title": "WEEK 3",
    "section": "2 Summary: practical",
    "text": "2 Summary: practical"
  },
  {
    "objectID": "WEEK3.html#application",
    "href": "WEEK3.html#application",
    "title": "WEEK 3",
    "section": "3 Application",
    "text": "3 Application\n\nThis week, the main focus was on the correction, joining and enhancement of remote sensing images, mostly applied to pre-processing before analysis, but remote sensing image enhancement has a wider range of applications.\n\n\n2.1 Applications of remote sensing image enhancement\nRemote sensing image enhancement refers to the improvement of the quality and information of remote sensing images through some technical means to make them more suitable for human vision or subsequent analytical processing. Remote sensing image enhancement can be applied to the following areas:\nContrast enhancement: By adjusting the grey level of a remotely sensing image, the contrast of the image is increased to make it clearer and brighter. Contrast enhancement can be done using methods such as histogram stretching, histogram equalisation and segmented linear stretching.\nBand ratioing: Extracts specific information from remote sensing images, such as vegetation indices, water indices, soil indices, etc., by calculating the ratio between different bands. Band ratios can be calculated using methods such as band arithmetic and band combination.\nFiltering: Remove noise or enhance edges and textures in an image by convolving the remote sensing image in the spatial or frequency domain. Filtering can use methods such as smoothing filtering, sharpening filtering and edge detection filtering.\nPrincipal component analysis (PCA): By applying orthogonal transformations to multiple bands of remote sensing images, the main information in the image is extracted and the redundancy and correlation of the data is reduced. Principal component analysis can use statistical methods or methods such as wavelet transform.\nTexture: Describes the surface roughness or structural features in an image by calculating the grey scale variation within a region of the remotely sensed image. Texturing can use methods such as grey level co-occurrence matrix, grey level distance matrix, grey level gradient matrix, etc.\nFusion: Increasing the spatial or spectral resolution of an image and increasing the amount of information in the image by combining remote sensing images from different sources or at different resolutions. Fusion can be done using methods such as HIS transform, wavelet transform, multi-resolution analysis, etc.\n\n\n2.2 Application case\n\n\n\n\n\n\nSourse\n\n\n\nPCA‐based land‐use change detection and analysis using multitemporal and multisensor satellite data , Sourse: Deng et al. (2008)\n\n\nRemote‐sensing change detection based on multitemporal, multispectral, and multisensor imagery has been developed over several decades and provided timely and comprehensive information for planning and decision‐making. In practice, however, it is still difficult to select a suitable change‐detection method, especially in urban areas, because of the impacts of complex factors.\nThis paper presents a new method using multitemporal and multisensor data (SPOT‐5 and Landsat data) to detect land‐use changes in an urban environment based on principal‐component analysis (PCA) and hybrid classification methods. After geometric correction and radiometric normalization, PCA was used to enhance the change information from stacked multisensor data. Then, a hybrid classifier combining unsupervised and supervised classification was performed to identify and quantify land‐use changes. Finally, stratified random and user‐defined plots sampling methods were synthetically used to obtain total 966 reference points for accuracy assessment.\n\n\n\nExample of land‐use changes from cropland to urban land (Economic and Technological Development Zone). (a) Pan image of ETM (2000); (b) aerial photograph (2000); (c) RGB composition image of SPOT‐5 (2003); (d) RGB composition image of IKONOS (2003); (e)–(h) first four principal components.\n\n\nAlthough errors and confusion exist, this method shows satisfying results with an overall accuracy to be 89.54% and 0.88 for the kappa coefficient. When compared with the post‐classification method, PCA‐based change detection also showed a better accuracy in terms of overall, producer’s, and user’s accuracy and kappa index. The results suggested that significant land‐use changes have occurred in Hangzhou City from 2000 to 2003, which may be related to rapid economy development and urban expansion. It is further indicated that most changes occurred in cropland areas due to urban encroachment.\n\n\n\nLand use and land‐use change detected using the PCA‐based approach."
  },
  {
    "objectID": "WEEK3.html#reflection",
    "href": "WEEK3.html#reflection",
    "title": "WEEK 3",
    "section": "4 Reflection",
    "text": "4 Reflection\nThis week I learnt the principles and methods of correcting, joining and enhancing remotely sensed images and understood how to pre-process remotely sensed data. Although most of the data we acquired had already been pre-processed, this knowledge gave me a better understanding of how to apply remote sensing images to the actual analysis and what could cause errors and whether further processing was needed. In addition, the study of remote sensing image enhancement has taught me more about remote sensing data analysis methods and principles in a deeper way.\n\n\n\n\nDeng, J. S., K. Wang, Y. H. Deng, and G. J. Qi. 2008. “PCA‐based Land‐use Change Detection and Analysis Using Multitemporal and Multisensor Satellite Data.” International Journal of Remote Sensing 29 (16): 4823–38. https://doi.org/10.1080/01431160801950162."
  },
  {
    "objectID": "WEEK4.html",
    "href": "WEEK4.html",
    "title": "WEEK 4",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 4, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK4.html#summary-lecture",
    "href": "WEEK4.html#summary-lecture",
    "title": "WEEK 4",
    "section": "1 Summary: lecture",
    "text": "1 Summary: lecture\n\n\n\nMindmap of Week 4 Leacture\n\n\n\n\n1.1 Using data from sensors\n\n\n\n\n\n\nExample\n\n\n\nMulti-temporal land cover mapping, Spectral signatures / libraries, Change detection, Vegetation stress, Precipitation, Elevation models, Temperature, Night time lights, Forest fire monitoring, Pollution monitoring, Drought indices, Informal housing detection, Water level data monitoring, Building or network outlineextraction, Environmental monitoring, Estimations of resources, Air pollution and LULC, Urban green space, Disaster response and preparedness, Droughts monitoring, Forest fires analysis\n\n\n\n\n1.2 Synthetic Aperture Radar (SAR)\n\nSAR background\n\n\n\nWhat is Synthetic Aperture Radar?. Source:NASA Earth Data\n\n\n\nActive sensors\nHave surface texture data\nSee through weather and clouds\nDifferent wavelengths - different applications\nDifferent ploarizations\n\n\n\nSAR polarization\nPolarization refers to the orientation of the plane in which the transmitted electromagnetic wave oscillates. While the orientation can occur at any angle, SAR sensors typically transmit linearly polarized. The horizontal polarization is indicated by the letter H, and the vertical polarization is indicated by V\n\nSingle = 1 horizontal (or vertical)\nDual = transmits and receives both horizontal and vertical\nHH = emitted in horizontal (H) and received in horizontal (H)\n\nDifferent surfaces respond differently to the polarizations\n\nRough scattering (e.g. bare earth) = most sensitive to VV\nVolume scattering (e.g. leaves) = cross, VH or HV\nDouble bounce (e.g. trees / buildings) = most sensitive to HH\n\nScattering can change based on wavelength, further penetration then the volume scattering will change\n\n\nAmplitude (backscatter) and phase\nA SAR signal has both amplitude (backscatter) and phase data\n\n\n\n\n\n\nTerms\n\n\n\n\nBackscatter is the portion of the outgoing radar signal that the target redirects directly back towards the radar antenna\nThe higher the backscattered intensity = rougher the surface. It is \"unitless\"\nCan be converted to “backscatter coefficient, or sigma nought”, measured in decibel (dB) units = normalised measure of the radar return from a distributed target\nIf the signal is from backscatter is not desired = \"clutter\"\n\n\n\nBackscatter (amplitude)\n\nPolarization\n\nVV = surface roughness\nVH = volume of surface (e.g. vegetation has a complex volume and can change the polarization)\n\nPermativity (dielectric constant) - how reflective is the property which means reflective back to the sensor. Water usually reflects it off elsewhere\nThe return value, also remember the band (wavelength)\nWind makes the water move and reflect back to the sensor (under VV)\n\nPhase\n\nLocation of wave on the cycle when it comes back to the sensor\n\n\n\nSAR floods\nSensor: Sentinel-1 SAR\n\nEl Niño–Southern Oscillation (ENSO) phases but this is from Australian La Niña 2022\n\nTrade winds from south america intensity\nDraw up cool deep waters and increase thermocline\nTemp difference increases, walker circulation intensifies - feedback loop\nMore cloud + more rain + cyclones in West Pacific\n\n\n\n\nInterferometry Synthetic Aperture Radar (InSAR)\n\nTake two RADAR observations of the target (e.g. the ground)\nUse the phase difference\n\nPhase: “total number of cycles of the wave at any given distance from the transmitter, including the fractional part”\nPhase difference: SUBTRACT the values (measured phase values) at two different measurement points\nDifferential distance depends on the height of the terrain (topography)\n\nUsed for creating DEMs\nMonitoring displacement of ground - earthquakes etc\n\n\n\n\n\n\n\nTerms\n\n\n\n\nCoherence Map: Coherence is defined as the degree of similarity of backscattering response (or reflection characteristic of as measured by the SAR sensor) between corresponding ground cells in both SAR image of an InSAR pair. Something is coherent when they are in phase (vibrate in unison)\nDifferential Interferometry Synthetic Aperture Radar (DInSAR): “quantification of the ground displacement that occurred between the two acquisitions can be achieved” through a “differential interferogram”\n\n\n\n\n\nSAR image\n\n\n\nUrban objects detection from C-band synthetic aperture radar (SAR) satellite images through simulating filter properties. Source:Deepak Kumar, 2021\n\n\n\n\nSAR applications\nDamage detection, Urban area mapping, Urban flooding (lower backscatter coefficient), Landslides, Earthquakes, Data fusion / DEM creation\n\n\n\n1.3 Monitoring forests + illegal logging\n\n\n\n\n\n\nSourse\n\n\n\nHigh-Resolution Global Maps of 21st-Century Forest Cover Change , Sourse: Hansen et al. (2013)\n\n\nSensor: Landsat (2000 to 2012)\n\nPre-processing\nLandsat pre-processing steps\n\nImage resampling\nConversion of raw digital values (DN) to top of atmosphere (TOA) reflectance\nCloud/shadow/water screening and quality assessment (QA)\nImage normalization\n\nThe stack of QA layers was used to create a perpixel set of cloud-free image observations which in turn was employed to calculate timeseries spectral metrics\n\n\nCreating metrics\nMetrics represent a generic feature space that facilitates regionalscale mapping and have been used extensively with MODIS and AVHRR data\nHow to create metrics\n\nReflectance values representing maximum, minimum and selected percentile values\nMean reflectance values for observations between selected percentiles\nSlope of linear regression of band reflectance value versus image date\nThe time-sequential MODIS 32-dayinputs were transformed to annual metrics to produce a more generalized feature space\n\n\n\n\n\n\n\n“a more generalized feature space”\n\n\n\n\nFeature space = scattergram of two bands (or things that have been made into bands)\nCan be used for very basic classification - selecting the values that represent land cover\n\n\n\n\n\nTraining data (in supervised machine learning)\nTraining data to relate to the Landsat metrics were derived from image interpretation methods, including mapping of crown/no crown categories using very high spatial resolution data such as Quickbird imagery, existing percent tree cover layers derived from Landsat data, and global MODIS percent tree cover, rescaled using the higher spatial resolution percent tree cover data sets\n\n\nClassification (supervised or unsupervised)\nDecision trees are hierarchical classifiers (top down) that predict class membership by recursively partitioning (splitting) a data set into more homogeneous or less varying subsets, referred to as nodes\n\nA random forest classifier is a collection of decision trees\nTake something complex and force into many decisions = if-else conditions or also called divide and conquer\nOften requires hyperparameters to train the model (or control the learning process)\n\nDBSCAN (radius of points, Epsilon or MinPts - to make a cluster)\nSpatial weight matrix (type and then weight)\n\nSplit the data into more and more homogeneous subsets (filtering!) this can be limited through\n\npre-pruning - set a number of iterations before\npost-pruning - reduce groups afterwards based on accuracy. Tree fully grows but will be overfit. (In post-pruning first, it goes deeper and deeper in the tree to build a complete tree. If the tree shows the overfitting problem then pruning is done as a post-pruning step. We use a cross-validation data to check the effect of our pruning. Using cross-validation data, it tests whether expanding a node will make an improvement or not. If it shows an improvement, then we can continue by expanding that node. But if it shows a reduction in accuracy then it should not be expanded i.e, the node should be converted to a leaf node.)\n\n\n\n\n\nREMAP method. Source:UN-SPIDER\n\n\n\n\n\n1.4 Integrating analysis\n\n\n\nExample of integrating analysis. Source: MacLachlan et al. 2021\n\n\n\n\n1.5 Global policy documents\n\nNew Urban Agenda\nStandards and principles for planning, construction, development, management and urban improvement (Environmentally sustainable and resilient urban development subsection)\npoint 64: We also recognize that urban centres worldwide, especially in developing countries, often have characteristics that make them and their inhabitants especially vulnerable to the adverse impacts of climate change and other natural and human-made hazards, including earthquakes, extreme weather events, flooding, subsidence, storms, including dust and sand storms, heatwaves, water scarcity, droughts, water and air pollution, vector-borne diseases and sea level rise, which particularly affect coastal areas, delta regions and small island developing States, among others\npoint 65: We commit ourselves to facilitating the sustainable management of natural resources in cities and human settlements in a manner that protects and improves the urban ecosystem and environmental services, reduces greenhouse gas emissions and air pollution and promotes disaster risk reduction and management, by supporting the development of disaster risk reduction strategies and periodical assessments of disaster risk caused by natural and human-made hazards, including standards for risk levels\npoint 67: We commit ourselves to promoting the creation and maintenance of well-connected and well distributed networks of open, multipurpose, safe, inclusive, accessible, green and quality public spaces, to improving the resilience of cities to disasters and climate change, including floods, drought risks and heat waves to improving food security and nutrition, physical and mental health, and household and ambient air quality, to reducing noise and promoting attractive and liveable cities, human settlements and urban landscapes and to prioritizing the conservation of endemic species\n\n\nSustainable Development Goals (SDG): targets with measurable indicators for monitoring\nGoal 11: Make cities and human settlements inclusive, safe, resilient and sustainable\nTarget 11.5: By 2030, significantly reduce the number of deaths and the number of people affected and substantially decrease the direct economic losses relative to global gross domestic product caused by disasters, including water-related disasters, with a focus on protecting the poor and people in vulnerable situations\n\nMonitoring 11.5\n\n11.5.1 Number of deaths, missing persons and directly affected persons attributed to disasters per 100,000 population\n11.5.2 Direct economic loss attributed to disasters in relation to global gross domestic product (GDP)\n11.5.3 (a) Damage to critical infrastructure and (b) number of disruptions to basic services, attributed to disasters\n\nData 11.5\n\n11.5.1 (and .2) Data provider at national level is appointed Sendai Framework Focal Points. In most countries disaster data are collected by line ministries and national disaster loss databases are established and managed by special purpose agencies including national disaster management agencies, civil protection agencies, and meteorological agencies. The Sendai Framework Focal Points in each country are responsible of data reporting through the Sendai Framework Monitoring System.\n11.5.3 National disaster loss database, reported to UNISDR…Not every country has a comparable national disaster loss database that is consistent with these guidelines (although current coverage exceeds 89 countries). Therefore, by 2020, it is expected that all countries will build/adjust national disaster loss databases according to the recommendations and guidelines by the OEIWG\n\n\nTarget 11.6: By 2030, reduce the adverse per capita environmental impact of cities, including by paying special attention to air quality and municipal and other waste management\n\nIndicator 11.6.2: Annual mean levels of fine particulate matter (e.g. PM2.5 and PM10) in cities (population weighted)\n\nTarget 11.7: By 2030, provide universal access to safe, inclusive and accessible, green and public spaces, in particular for women and children, older persons and persons with disabilities\n\nIndicator 11.7.1: Average share of the built-up area of cities that is open space for public use for all, by sex, age and persons with disabilities\n\n\n\n\n1.6 Metropolitan policy documents\n\nLondon\n\nIncreasing efficiency and resilience: These environmental threats are real and present, and London must be prepared for them. London’s homes and infrastructure must be protected against the increasing likelihood of heatwaves, and developments must plan for a more integrated approach to water management, while minimising flood risk\nPolicy SI 12 Flood risk management: Development Plans should use the Mayor’s Regional Flood Risk Appraisal and their Strategic Flood Risk Assessment as well as Local Flood Risk Management Strategies, where necessary, to identify areas where particular and cumulative flood risk issues exist and develop actions and policy approaches aimed at reducing these risks\n\n\n\nOneNYC 2050\n\nReferences the sustainable development goals\nHas a hazards matrix\n\n\n\nCape Town: Cape Town Municipal Spatial Development Framework\n\n2015-2018 “worst recorded drought in the city’s history, is a stark reminder that all cities will need to become more robust, resilient and efficient”\n“The Cape Town Spatial Development Framework (CTSDF) was approved in May 2012 and established a long-term spatial vision and policy framework for the City after extensive technical drafting and public participation.”\n“Careful management of development to avoid developing in high flood risk areas”\n\n\n\nAhmedabad: 2016 Heat Action Plan\n\nAwareness and outreach\nEarly warning system\nCapacity of health care professionals\nReduce heat exposure and promote adaptive mesaures …and mapping high risk areas, although mapping was removed later in the document (page 11)\n\n\n\n\n1.7 Local policy documents\nIn most of the previous examples the documents were created by the metropolitan government, they set the strategic plan for the city and may have other responsibilities such as fire, policing, transport and development guidelines. Lower tier government then carries out or adheres to these goals, but there are variations to this rule\n\nCity of Cape Town\n\nThe City of Cape Town is a metropolitan municipality or Category A municipality, there is no local municipality below it\nHowever, above the City of Cape Town is the Provincial government that is responsible for topics such as: agriculture, education, health and public housing. As such the City sets it’s own development plan and then implements it (whilst adhering to relevant Provincial topics)\n\n\n\nNew York\n\nCity of New York is responsible for public education, correctional institutions, public safety, recreational facilities, sanitation, water supply, and welfare services\n5 Boroughs under it act as spokespeople\nCity Council has 51 members from districts of about 157,000\nNew York City is responsible for setting and enacting the policy. State government is above it"
  },
  {
    "objectID": "WEEK4.html#summary-practical",
    "href": "WEEK4.html#summary-practical",
    "title": "WEEK 4",
    "section": "2 Summary: practical",
    "text": "2 Summary: practical\n\nThe summary of the policy and city I have selected.***"
  },
  {
    "objectID": "WEEK4.html#application",
    "href": "WEEK4.html#application",
    "title": "WEEK 4",
    "section": "3 Application",
    "text": "3 Application\n\nHow the remotely sensed data you sourced could be used to assist with contributing to the policy goal. How could the data be applied to solve the policy challenge."
  },
  {
    "objectID": "WEEK4.html#reflection",
    "href": "WEEK4.html#reflection",
    "title": "WEEK 4",
    "section": "4 Reflection",
    "text": "4 Reflection\n\nWhat I have learnt in relation to the policy, city and the application of the data.\n\n\n\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A. Tyukavina, D. Thau, et al. 2013. “High-Resolution Global Maps of 21st-Century Forest Cover Change.” Science 342 (6160): 850–53. https://doi.org/10.1126/science.1244693."
  },
  {
    "objectID": "WEEK5.html",
    "href": "WEEK5.html",
    "title": "WEEK 5",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 5, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK6.html",
    "href": "WEEK6.html",
    "title": "WEEK 6",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 6, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK7.html",
    "href": "WEEK7.html",
    "title": "WEEK 7",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 7, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK8.html",
    "href": "WEEK8.html",
    "title": "WEEK 8",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 8, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Abbas, Sawaid, Qian Peng, Man Sing Wong, Zhilin Li, Jicheng Wang, Kathy\nTze Kwun Ng, Coco Yin Tung Kwok, and Karena Ka Wai Hui. 2021.\n“Characterizing and Classifying Urban Tree Species Using\nBi-Monthly Terrestrial Hyperspectral Images in Hong\nKong.” ISPRS Journal of Photogrammetry and\nRemote Sensing 177 (July): 204–16. https://doi.org/10.1016/j.isprsjprs.2021.05.003.\n\n\nDeng, J. S., K. Wang, Y. H. Deng, and G. J. Qi. 2008.\n“PCA‐based Land‐use Change Detection and Analysis\nUsing Multitemporal and Multisensor Satellite Data.”\nInternational Journal of Remote Sensing 29 (16): 4823–38. https://doi.org/10.1080/01431160801950162.\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A.\nTyukavina, D. Thau, et al. 2013. “High-Resolution\nGlobal Maps of 21st-Century\nForest Cover Change.”\nScience 342 (6160): 850–53. https://doi.org/10.1126/science.1244693."
  }
]