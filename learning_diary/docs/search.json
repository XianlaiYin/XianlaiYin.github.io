[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Diary",
    "section": "",
    "text": "Introduction\n\n\n\n\n\n\nAcknowledgements\n\n\n\nMany thanks to the lecturer Dr Andrew MacLachlan and all CASA teachers for their contributions to this course.\n\n\nAbout this website\nThis website will include a summary of the content of CASA0023 Remotely Sensing Cities and Environments and my thoughts and ideas based on the content of the course.\nAbout me\nHi, I am Xianlai Yin from Jiangxi, China. I am currently studying in MSc Urban Spatial Science at the Bartlett Centre for Advanced Spatial Analysis, UCL. My undergraduate degree is in Urban and Rural Planning at Chang’an University.\nMy research experience is mainly related to urban planning, including the study of the spatial structure of urban agglomerations based on social network analysis methods, and the study of the resilience of urban transport networks. My work experience is mainly in the field of urban construction, including working as an intern planner at the institute of urban planning and design and as an intern in the smart city department of a real estate company.\nI am very interested in the application of spatial data analysis in the field of urban planning, and remote sensing can provide a wide and diverse source of data. Therefore, I took CASA0023 in the hope of studying the application of remote sensing technology in the field of urban analysis. Meanwhile, during the creation of this learning dairy, thinking will mainly from the perspective of urban planning.\n\n\nContent\n\n\n\nWEEK\nTHEME\n\n\n\n\nWEEK 1\nAn Introduction to Remote Sensing\n\n\nWEEK 2\nPortfolio tools: Xaringan and Quarto\n\n\nWEEK 3\nRemote sensing data\n\n\nWEEK 4\nPolicy applications\n\n\nWEEK 5\nAn introduction to Google Earth Engine\n\n\nWEEK 6\nClassification\n\n\nWEEK 7\nClassification the big questions and accuracy\n\n\nWEEK 8\nTemperature and policy"
  },
  {
    "objectID": "WEEK1.html",
    "href": "WEEK1.html",
    "title": "WEEK 1",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 1, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK1.html#summary-lecture",
    "href": "WEEK1.html#summary-lecture",
    "title": "WEEK 1",
    "section": "1 Summary: lecture",
    "text": "1 Summary: lecture\nThis week’s content focuses on an introduction to basic information on remote sensing and Electromagnetic radiation (EMR).\n\n\n\nMindmap of Week 1 Leacture\n\n\n\n\n1.1 Remote sensing\n\nDefinition\nNASA defines remote sensing as acquiring information from a distance, interchangeable used with Earth Observation or EO.\n\n\nData acquisition\nThis is achieved through sensors mounted on a platform, e.g. satellites, planes (aerial imagery), drones, phones, free standing on the ground or sea (with hand held devices), there are more than 150 satellites in orbit carrying sensors.\n\n\nAdvantages\n\nMass of data: satellites collect data on the same points on Earth every day to every 16 days\nFrequency of update and less reliance on authorities (e.g. London Atlas)\nMore free resources to process large volumes of data (e.g. Google Earth Engine)\n\n\n\nTypes of sensor\nPassive sensor\n\nUse energy that is available\nDon’t emit anything\nUsually detecting reflected energy from the sun\nEnergy is in electromagnetic waves…\nSuch as: Human eye, camera, satellite sensor\n\nActive sensor\n\nHave an energy source for illumination\nActively emits electormagentic waves and then waits to receive\nSuch as: Radar, X-ray, LiDAR\n\n\n\n\n1.2 Electromagentic waves\n\n\n\n\n\n\nTerms\n\n\n\n\nWaves of an electromagnetic field, travel through space and carry radiant energy = Electromagnetic radiation (EMR). Waves are part of the EMR spectrum.\nEnergy carried by EMR waves = radiant energy\nEnergy per unit of time = radiant flux\nEnergy from the sun = incoming short wave radiation or shortwave radiation\nEnergy (solar power) from the sun per unit area per unit time (from electromagnetic radiation) = solar irradiance (per unit time - flux)\nEnergy leaving a surface per unit area per unit time = Exitance (emittance) (per unit time - flux)\nFlux means time here.\n\n\n\n\nElectromagnetic radiation (EMR)\nEMR has both electric and magnetic fields, propagates (moves) as waves: c = vλ\n\nc = velocity of light 3 x 10^8 meters per second\nv = frequency, rate of oscillation\nλ = wavelength, distance between two crests\n\nEMR isn’t automatically reflected. It experiences a number of changes prior to hitting the sensor\n\nSurface: Energy being absorbed by the surface and being transmitted through the surface\nAtmospheric: Energy can be scattered by particles in the atmosphere\n\n\n\n\n1.3 Interacting with Earth’s surface\n\nAtmospheric scattering\n\nRayleigh = particles are very small compared to the wavelength\nMie = particles are the same size compared to the wavelength\nNon selective = particles are much larger than the wavelength\n\n\n\nSynthetic Aperture Radar (SAR)\n\nRadar collects at longer wavelengths than optical sensors - pass through clouds that have smaller particle sizes (wavelength dictates how far it can penetrate into medium)\nHas it’s own bands - e.g. P, L, S, C, X, Ku, K\nCollects data at night\n\n\n\nBidirectional Reflectance Distribution Function (BRDF)\n\nView (e.g. sensor) and illumination (e.g. sun) angles can change\nEnergy being reflected from the surface that is smooth or diffuse\n\n\n\nPolarization\nDefinition\nApplicable to Radar: Electromagnetic waves are polarized and the direction depends on the oscillation of the electromagnetic field. When they are reflected from the surface the waves can be linked to surface properties - roughness, shape, orientation, moisture, salinity, density.\nDifferent ploarizations\n\nSingle polarization: same polarization transmitted and received = 1 horizontal (or vertical)\nDual polarization: One sent, different one received = transmits and receives both horizontal and vertical\nQuad polarization: system can transmit and receive four types = emitted in horizontal (H) and received in horizontal (H)\n\n\n\n\n1.4 Remote sensing data\n\nData formats\n\nband interleaved by line (BIL)\nband sequential (BSQ)\nband interleaved by pixel (BIP)\nGeoTIFF (most common)\n\n\n\nFour resolutions\n\nSpatial = the size of the raster grid per pixel (e.g. 20cm or 30m)\nSpectral = the number of bands it records data in…more soon\nTemporal = the time it revisits (e.g. daily, every 7 days, on demand)\nRadiometric = identify differences in light or reflectance, in practice this is the range of possible values.\n\n\n\n\nSpectral resolution. Source: NASA Science\n\n\n\n\nType of orbit\n\ngeosynchronous orbit (GSO) = satellite matches the Earth’s rotation\ngeostationary orbit = holds same position, usually only for communications but some sensors are geostationary."
  },
  {
    "objectID": "WEEK1.html#summary-practical",
    "href": "WEEK1.html#summary-practical",
    "title": "WEEK 1",
    "section": "2 Summary: practical",
    "text": "2 Summary: practical\n\nThis week’s practical will consist mainly of the following:\n\nAcquisition and reading of remote sensing data\nThe specifics of processing remote sensing data using SNAP and R\nMethods for viewing the spectra of remote sensing data and comparing spectral features\n\n\nFor this week’s practical I chose Chelmsford, a city in the north-east suburbs of London, as my study area. I also followed the practical’s instructions to operate on remote sensing images within its administrative area. Through this practical I became familiar with the use of SNAP and the remote sensing related package of R. I also learnt about some of the features of remote sensing imagery, such as spectral features, through these operations.\n\n\n\nSNAP operating screen"
  },
  {
    "objectID": "WEEK1.html#application",
    "href": "WEEK1.html#application",
    "title": "WEEK 1",
    "section": "3 Application",
    "text": "3 Application\n\nThis week’s lecture is mainly about the basic knowledge of remote sensing and Electromagnetic radiation (EMR), so I would like to introduce some of the remote sensing applications based on spectral characteristics.\n\n\n3.1 Remote sensing applications based on spectral features\nRemote sensing uses spectral features to identify, classify and analyse a variety of features on the surface or in the atmosphere. Remote sensing has many applications using spectral features：\n\nIn the field of agriculture, the spectral characteristics of vegetation can be used to monitor the growth of crops, damage, yield prediction, etc.\nIn the field of environmental, the spectral characteristics of water bodies, soil and atmosphere can be used to monitor water quality, soil types, pollutant types and concentrations, etc.\nIn the field of geology, the spectral characteristics of rocks, minerals, etc. can be used to detect mineral resources, geological formations, seismic activity, etc.\nIn the field of urban planning, the spectral characteristics of buildings, roads, etc. can be used to extract urban spatial information, assess the level of urban development and influencing factors, etc.\n\nThe specific application methods of remote sensing based on spectral features in the field of urban planning are mainly as follows:\n\nUsing remote sensing images to obtain information on the current situation of land use, analyse the structure and spatial distribution characteristics of urban land use, and provide basic data for urban planning.\nUsing remote sensing images for urban ecological environment evaluation, monitoring urban heat island effect, air quality, tree health, water quality and other environmental indicators, and providing ecological guarantee for urban planning.\nUse remote sensing imagery for urban construction change monitoring, identifying the impact of urban construction activities on land use, and providing dynamic management for urban planning.\n\n\n\n3.2 Application case\n\n\n\n\n\n\nSourse\n\n\n\nCharacterizing and classifying urban tree species using bi-monthly terrestrial hyperspectral images in Hong Kong , Sourse: Abbas et al. (2021)\n\n\nUrban trees exhibit a wide range of ecosystem services that have long been unveiled and increasingly reported. The ability to map tree species and analyze tree health conditions would become vividly essential. Remote sensing techniques, especially hyperspectral imaging, are being evolved for species identification and vegetation monitoring from spectral reponse patterns.\n\n\n\nAn example of image clustering and corresponding spectral signatures of classes. The shadow class in grey represents canopy shadow and/or branches, and the shadow class in orange indicates shaded leaves.\n\n\nIn this study, a hyperspectral library for urban tree species in Hong Kong was established comprising 75 urban trees belonging to 19 species. 450 bi-monthly images were acquired by a terrestrial hyperspectral camera (SPECIM-IQ) from November 2018 to October 2019. A Deep Neural Network classification model was developed to identify tree species from the hyperspectral imagery with an overall accuracy ranging from 85% to 96% among different seasons. Representative spectral reflectance curves of healthy and unhealthy conditions for each species were extracted and analyzed. This can be used to identify urban trees and monitor their health.\n\n\n\nThe overall workflow of species classification framework using the Deep Neural Network modelling.\n\n\n\n\n3.3 Case comments\nAdvantages or contribution\n\nA hyperspectral library for urban tree species in Hong Kong was established , and trees were classified and detected with high accuracy, which could be a valuable resource for future research in Hong Kong or similar environments.\nHyperspectral phenology models were developed using deep neural network classification models to optimise data acquisition and improve accuracy in monitoring tree health, which provides experience in the field of machine learning of remote sensing images.\n\nDisadvantages or potential\n\nHyperspectral image acquisition cost and processing complexity: Acquisition and processing of hyperspectral images may be more costly and complex compared to other remote sensing techniques, and may face cost issues in actual applications.\nData set limitations: The study focuses on urban trees in Hong Kong and may not be directly applicable to other regions or cities with different ecological conditions. Expanding the study to include a wider range of geographical and ecological conditions would make the results more generalisable."
  },
  {
    "objectID": "WEEK1.html#reflection",
    "href": "WEEK1.html#reflection",
    "title": "WEEK 1",
    "section": "4 Reflection",
    "text": "4 Reflection\nDuring this week I have learnt about the basics of remote sensing and Electromagnetic radiation (EMR), which has greatly broadened my horizons when researching urban. Due to limited data collection facilities, detailed urban datasets (e.g. traffic flow data, mobile phone signalling data, etc.) are only available for main cities in developed areas, which makes many studies not reproducible in a wide range of non-developed or small cities. However, the extensive coverage of remote sensing data compensates well for this shortcoming, and the variety of data collected through the rich diversity of sensors can be of great help in urban (or regional) analysis.\nHowever, there are some limitations to remote sensing data at the level of accuracy and price. On the one hand, there is relatively little high-precision remote sensing data for inner-city scale studies, and on the other hand, high-precision data often leads to huge costs, which in practice can lead to some technologies not being implemented.\n\n\n\n\nAbbas, Sawaid, Qian Peng, Man Sing Wong, Zhilin Li, Jicheng Wang, Kathy Tze Kwun Ng, Coco Yin Tung Kwok, and Karena Ka Wai Hui. 2021. “Characterizing and Classifying Urban Tree Species Using Bi-Monthly Terrestrial Hyperspectral Images in Hong Kong.” ISPRS Journal of Photogrammetry and Remote Sensing 177 (July): 204–16. https://doi.org/10.1016/j.isprsjprs.2021.05.003."
  },
  {
    "objectID": "WEEK2.html",
    "href": "WEEK2.html",
    "title": "WEEK 2",
    "section": "",
    "text": "Homework: Introduction to Hyperspectral Radiometer\nThis week I learnt how to use Quarto to create websites and Xaringan to create presentations. This website and this slide can be used as a presentation of what I learnt the content of this week."
  },
  {
    "objectID": "WEEK3.html",
    "href": "WEEK3.html",
    "title": "WEEK 3",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 3, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK3.html#summary-lecture",
    "href": "WEEK3.html#summary-lecture",
    "title": "WEEK 3",
    "section": "1 Summary: lecture",
    "text": "1 Summary: lecture\nThis week focuses on the pre-processing of remote sensing data, including the correction, joining and enhancement of various types of remote sensing data.\n\n\n\nMindmap of Week 3 Leacture\n\n\n\n\n1.1 Pre-knowledge\n\nDifferent sensors\n\nMSS (Multispectral Scanner)\nRBV (Return Beam Vidicon Camera)\n\n\n\nPush broom vs Whisk broom\n\nWhisk broom or spotlight or across track scanners: Mirror reflects light onto 1 detector - Landsat\nPush broom or along track scanners: several detectors that are pushed along - SPOT, Quickbird\n\n\n\n\n1.2 Corrections\n\nRegression\n\\[\ny_i=\\beta_0+\\beta_1x_i+\\varepsilon_i\n\\]\n\nβ0 is the intercept (the value of y when x = 0)\nβ1 the ‘slope’ the change in the value of y for a 1 unit change in the value of x\nϵi is a random error term (positive or negative)- if you add all of the vertical differences between the blue line and all of the residuals, it should sum to 0\nAny value of y along the blue line can be modeled using the corresponding value of x\n\n\n\nGeometric correction\nWhat leads to image distortions\n\nView angle (off-nadir)\nTopography (e.g. hills not flat ground)\nWind (if from a plane)\nRotation of the earth (from satellite)\n\nGeometric correction solution\n\n\n\nGeometric correction. Source: Abdul Basith\n\n\n\nIdentify Ground Control Points (GPS) to match known points in the image and a reference dataset\nTake the coordinates and model them to give geometric transformation coefficients, linear regression with our distorted x or y as the dependent or independent\n\nInput to output (forward mapping): the issue with this is that we are modelling the rectified x and y which could fall anywhere on the gold standard map (e.g. not on a grid square or at a floating point)\nOutput to input (backward mapping): for every value in the output (gold standard) pixel we can get a value in the original input image. The images are distorted as so might not completely overlap. The goal is to match the distorted image with the gold standard image, so we want the pixels to line up\n\nPlot these and try to minimise the RMSE - Jensen sets a RMSE value of 0.5, typically might add more GCPs to reduce the RMSE (The model with the lowest RMSE will fit best)\n\nRMSE: (observed - predicted (the residual))^2, sum them and divide by number of data points, square root that total\nResample methods: Nearest Neighbor, Linear, Cubic, Cubic spline\n\n\n\n\nAtmospheric correction\nNecessary and unnecessary atmospheric correction\n\nNecessary\n\nBiophysical parameters needed (e.g. temperature, leaf area index, NDVI)\nUsing spectral signatures through time and space\n\nUnnecessary\n\nClassification of a single image\nIndependent classification of multi date imagery\nComposite images (combining images)\nSingle dates or where training data extracted from all data\n\n\nAtmospheric correction in action\n\n\n\nAtmospheric correction examples of three scenes (Bands 1, 2, and 3). Source: Liang et al. 2001\n\n\n\nAbsorption and scattering create the haze = reduces contrast of image\nScattering = can create the “adjacency effect”, radiance from pixels nearby mixed into pixel of interest\n\nAtmospheric correction types\n\nRelative (to something)\n\nNormalize\n\nNormalize intensities of different bands within a single image\nNormalise intensities of bands from many dates to one date\n\nDark object subtraction (DOS) or histogram adjustment\n\nSearches each band for the darkest value then subtracts that from each pixel\nLandsat bands 1-3 (visible) have increased scattering vs longer wavelengths\n\nPsuedo-invariant Features (PIFs)\n\nAssume brightness pixels linearly related to a base image\nRegression per band\nAdjust the image based on the regression result\nHere y is the value of our base. To get y we multiply our new date pixel (x) by the coefficient and add the intercept value\nApply this to the rest of the pixels\n\n\nAbsolute (definitive)\n\nMethod\n\nChange digital brightness values into scaled surface reflectance. We can then compare these scaled surface reflectance values across the planet\nWe do this through atmospheric radiative transfer models and there are many to select from\nHowever, nearly all assume atmospheric measurements are available which are used to “invert” the image radiance to scaled surface reflectance\nThe scattering and absorption information comes from atmopshierc radiative transfer code such as MODTRAN 4+ and the Second Simulation of the Satellite Signal in the Solar Spectrum (6S), which can now be used through python - called Py6S\n\nAbsolute Data requirements\n\nAn atmopsheric model (summer, tropical): usually you can select from the tool\nLocal atmopsheric visibility: from a weather station, like airports\nImage altitude\n\nAbsolute Tools\n\nACORN: Atmopsehic CORection Now\nFLAASH: Fast Line of-sight Atmopsheric Analysis\nQUAC: Quick Atmopsheric Correction\nATCOR: The ATmospheric CORrection program\nSMAC: Simplified Model for Atmospheric Correction (SMAC)\n\n\nEmpirical Line Correction\n\nWe can go and take measurements in situ using a field spectrometer, this does require measurements at the same time as the satellite overpass\nThen use these measurements in linear regression against the satellite data raw digital number\n\n\n\n\nOrthorectification / Topographic correction\n\n\n\nA view captured from an oblique angle (for example, 25°, left) must be corrected for relief displacement caused by terrain to generate the orthorectified view (looking straight down, right). Orthoimagery is produced by calculating the nadir view for every pixel. Source: Esri Insider, 2016\n\n\nA subset of georectification\n\nGeorectification = giving coordinates to an image\nOrthorectification = removing distortions… making the pixels viewed at nadir (straight down)\n\nRequires\n\nSensor geometry\nAn elevation model\n\nSoftware / formulas to do this\n\nJensen covers the following formulas: Cosine correction, Minnaert correction, Statistical Empirical correction, C Correction (advancing the Cosine)\nSoftware: QGIS, SAGA GIS, R package topocorr, R package RStoolbox\n\nSolar location\n\nSolar azimuth = compass angle of the sun (N =0°) 90° (E) at sunrise and 270° (W) at sunset\nSolar zenith = angle of local zenith (above the point on ground) and sun from vertical (90° - elevation)\n\n\n\nRadiometric calibration\n\nSensors capture image brightness and distributed as a Digital Number (or DN) - allows for efficient storage but has no units\nSpectral radiance is the amount of light within a band from a sensor in the field of view (FOV), it is independent of the sensor, measured in Watts (power or light here)\nDN to spectral radiance = radiometric calibration\nSensor calibration = the relationship between Gain and Bias are usually provided but we can calcaulte them\n\n\n\n\n\n\n\nTerms\n\n\n\n\nRadiance: refers to any radiation leaving the Earth (i.e. upwelling, toward the sensor\n\nMight also be called Top of Atmosphere (TOA) radiance\nHow much light the instrument sees in meaningful units but still have effects of: Light source, atmosphere and surface material\nWe can remove the effects of the light source to generate Top of Atmosphere reflectance but usually this is combined within the radiance to reflectance step\n\nIrradiance: is used to describe downwelling radiation reaching the Earth from the sun\nDigital number (DN)\n\nIntensity of the electromagnetic radiation per pixel\nPixel values that aren’t calibrated and have no unit\nHave light source\nEffects of sensor + atmosphere + material\nValues range from 0 - 255 (Lansat 5) = 8 bit or 0 - 65536 Landsat 8 (12 bit)\n\nReflectance: We need to account for atmospheric and illumination effects to create reflectance. BUT this typically doesn’t deal with shadows and directional effects (e.g. viewing angles) = apparent reflectance However, this is often called reflectance\n\nReflectance is a property of a material (e.g. reflectance of grass is a property of grass)\nThe issue with radiance is that is contains physical properties AND is dependent on the light source\n\nHemispherical reflectance: all of the light leaving the surface goes straight to the sensor (nothing is intercepted or at an angle)\nPath radiance: radiance reflected above the surface (e.g. scattering)\nAtmospheric attenuation: absorption of EMR due to materials in atmosphere (e.g. water vapour)\nLocal: specific to pixel\n`Neighbourhood: pixels within a range (nearby)\n\n\n\n\n\n\n1.3 Data joining and enhancement\n\nJoining data sets\n\nThis is termed “Mosaicking” in remote sensing - but it’s not much different to merging in GIS\nIn Remote Sensing we usually feather the images together\nThis creates a seamless mosaic or image(s)\nThe dividing line is termed the seamline\nWe have a base image and “other” or second image\n\n\n\nHow to join data sets\n\nStandardization (dividing the SR value by a maximum value per band) and normalization (divide the standarised value by the sum of values across all bands) applied to each image\nUndertake further relative radiometric normalization\nClassify each image alone\nCalculate other metrics from the image\n\n\n\nImage enhancement\nContrast enhancement\n\n\n\nContrast enhancement in QGIS. Source: Atilo Francois\n\n\n\nMinimum - Maximum\nPercentage Linear and Standard Deviation\nPiecewise Linear Contrast Stretch\n\nRatio\n\nBand ratioing means dividing the pixels in one band by the corresponding pixels in a second band.\nExample: Normalized Burn Ratio = (NIR - SWIR) / (NIR + SWIR)\n\nIn Landsat 4-7, NBR = (Band 4 – Band 7) / (Band 4 + Band 7)\nIn Landsat 8-9, NBR = (Band 5 – Band 7) / (Band 5 + Band 7)\n\n\nFiltering\n\nLow pass or low frequency (averages the surrounding pixels)\nHigh pass or high frequency - enhance local variations\nEdge enhancement\n\nPCA (Principal Component)\n\nTransform multi-spectral data into uncorrelated and smaller dataset\nHas most of the original information\nReduces future computation “dimensionatliy reduction”\nThe first component will capture most of the variance within the dataset\nIn R this is from the RStoolbox packagerasterPCA()\nPCA example, multi-date PCA - bands from both time points are combined into one image, then PCA\n\nTexture\n\nImages just use tonal (spectral) data not texture\nTexture: spatial variation of gray values\nFirst order (occurrence): use counts or occurrences\nSecond order(co-occurrence): relationship between pixel pairs “a function of both the angular relationship and distance between two (or kernel) neighboring pixels”\n\nFusion\nImage fusion is where data from multiple sensors / sources is fused together\n\nPan sharpen\nData Fusion"
  },
  {
    "objectID": "WEEK3.html#summary-practical",
    "href": "WEEK3.html#summary-practical",
    "title": "WEEK 3",
    "section": "2 Summary: practical",
    "text": "2 Summary: practical\n\nThis week’s practical will consist mainly of the following:\n\nIntroduction and access to Landsat data\nA deeper understanding of atmospheric correction and how it works in practice\nIntroduction to the principles of Radiance (or DN) to Reflectance\nPractical exercises in image joining\nA deep understanding of image enhancement and how it works in practice\n\n\nFor this week’s practical I chose to follow the guidance using Landsat data from Cape Town. I used R to do atmospheric corrections, merging, data enhancement and other operations on the data. Through practical, I gained a better understanding of remote sensing data pre-processing and was able to apply this to my workflow in R. Combined with the previous term’s CASA0005 course, I can now use R to analyse more types of data.\n\n\n\nTexture of landsat data from Cape Town"
  },
  {
    "objectID": "WEEK3.html#application",
    "href": "WEEK3.html#application",
    "title": "WEEK 3",
    "section": "3 Application",
    "text": "3 Application\n\nThis week, the main focus was on the correction, joining and enhancement of remote sensing images, mostly applied to pre-processing before analysis, but remote sensing image enhancement has a wider range of applications.\n\n\n3.1 Applications of remote sensing image enhancement\nRemote sensing image enhancement refers to the improvement of the quality and information of remote sensing images through some technical means to make them more suitable for human vision or subsequent analytical processing. Remote sensing image enhancement can be applied to the following areas:\nContrast enhancement: By adjusting the grey level of a remotely sensing image, the contrast of the image is increased to make it clearer and brighter. Contrast enhancement can be done using methods such as histogram stretching, histogram equalisation and segmented linear stretching.\nBand ratioing: Extracts specific information from remote sensing images, such as vegetation indices, water indices, soil indices, etc., by calculating the ratio between different bands. Band ratios can be calculated using methods such as band arithmetic and band combination.\nFiltering: Remove noise or enhance edges and textures in an image by convolving the remote sensing image in the spatial or frequency domain. Filtering can use methods such as smoothing filtering, sharpening filtering and edge detection filtering.\nPrincipal component analysis (PCA): By applying orthogonal transformations to multiple bands of remote sensing images, the main information in the image is extracted and the redundancy and correlation of the data is reduced. Principal component analysis can use statistical methods or methods such as wavelet transform.\nTexture: Describes the surface roughness or structural features in an image by calculating the grey scale variation within a region of the remotely sensed image. Texturing can use methods such as grey level co-occurrence matrix, grey level distance matrix, grey level gradient matrix, etc.\nFusion: Increasing the spatial or spectral resolution of an image and increasing the amount of information in the image by combining remote sensing images from different sources or at different resolutions. Fusion can be done using methods such as HIS transform, wavelet transform, multi-resolution analysis, etc.\n\n\n3.2 Application case\n\n\n\n\n\n\nSourse\n\n\n\nPCA‐based land‐use change detection and analysis using multitemporal and multisensor satellite data , Sourse: Deng et al. (2008)\n\n\nRemote‐sensing change detection based on multitemporal, multispectral, and multisensor imagery has been developed over several decades and provided timely and comprehensive information for planning and decision‐making. In practice, however, it is still difficult to select a suitable change‐detection method, especially in urban areas, because of the impacts of complex factors.\nThis paper presents a new method using multitemporal and multisensor data (SPOT‐5 and Landsat data) to detect land‐use changes in an urban environment based on principal‐component analysis (PCA) and hybrid classification methods. After geometric correction and radiometric normalization, PCA was used to enhance the change information from stacked multisensor data. Then, a hybrid classifier combining unsupervised and supervised classification was performed to identify and quantify land‐use changes. Finally, stratified random and user‐defined plots sampling methods were synthetically used to obtain total 966 reference points for accuracy assessment.\n\n\n\nExample of land‐use changes from cropland to urban land (Economic and Technological Development Zone). (a) Pan image of ETM (2000); (b) aerial photograph (2000); (c) RGB composition image of SPOT‐5 (2003); (d) RGB composition image of IKONOS (2003); (e)–(h) first four principal components.\n\n\nAlthough errors and confusion exist, this method shows satisfying results with an overall accuracy to be 89.54% and 0.88 for the kappa coefficient. When compared with the post‐classification method, PCA‐based change detection also showed a better accuracy in terms of overall, producer’s, and user’s accuracy and kappa index. The results suggested that significant land‐use changes have occurred in Hangzhou City from 2000 to 2003, which may be related to rapid economy development and urban expansion. It is further indicated that most changes occurred in cropland areas due to urban encroachment.\n\n\n\nLand use and land‐use change detected using the PCA‐based approach.\n\n\n\n\n3.3 Case comments\nAdvantages or contribution\n\nFlexible classification strategies: The hybrid classification approach allows the authors to combine the accuracy of supervised classification methods while taking advantage of the automation of unsupervised classification methods. This flexibility allows the method to be better adapted to different types of land use change scenarios.\nPCA-based feature extraction: By combining multi-temporal and multi-sensor data into a single Principal Component Analysis (PCA) model, the authors are able to extract more meaningful features that help distinguish between changing and non-changing areas. This approach has advantages in dealing with high-dimensional data and reducing data redundancy.\nCorrection and radiation normalisation: This paper corrected and radiation normalised the data prior to analysis, which helped to reduce errors due to sensor differences, variations in atmospheric conditions and land cover type, thus improving the accuracy and reliability of the results.\n\nDisadvantages or potential\n\nLimitations of Principal Component Analysis (PCA): While PCA is able to extract and enhance variation information from multi-sensor data, it may not be able to completely eliminate noise and other non-target factors. In addition, PCA may have limitations in handling non-linear data, which may lead to inaccurate detection results.\nLimitations of sensor data: SPOT-5 and Landsat data were used in this paper. While these data sources are of value in land cover change detection, they may not capture the detailed information that finer spatial resolution and higher spectral resolution can provide. In addition, these data sources may be affected by issues such as cloud occlusion, atmospheric interference and timing inconsistencies."
  },
  {
    "objectID": "WEEK3.html#reflection",
    "href": "WEEK3.html#reflection",
    "title": "WEEK 3",
    "section": "4 Reflection",
    "text": "4 Reflection\nThis week I learnt the principles and methods of correcting, joining and enhancing remotely sensed images and understood how to pre-process remotely sensed data. Although most of the data we acquired had already been pre-processed, this knowledge gave me a better understanding of how to apply remote sensing images to the actual analysis and what could cause errors and whether further processing was needed. In addition, the study of remote sensing image enhancement has taught me more about remote sensing data analysis methods and principles in a deeper way.\nHowever, not all data pre-processing can be perfectly accurate, errors are allowed but need to be controlled according to the actual situation. Also, in practice, some R packages are no longer available due to version updates. This is a common problem in data analysis and can be solved by downloading a lower version of the package or replacing it.\n\n\n\n\nDeng, J. S., K. Wang, Y. H. Deng, and G. J. Qi. 2008. “PCA‐based Land‐use Change Detection and Analysis Using Multitemporal and Multisensor Satellite Data.” International Journal of Remote Sensing 29 (16): 4823–38. https://doi.org/10.1080/01431160801950162."
  },
  {
    "objectID": "WEEK4.html",
    "href": "WEEK4.html",
    "title": "WEEK 4",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 4, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK4.html#summary-lecture",
    "href": "WEEK4.html#summary-lecture",
    "title": "WEEK 4",
    "section": "1 Summary: lecture",
    "text": "1 Summary: lecture\nThis week focuses on the scenarios and application methods of various types of remote sensing data, as well as policy documents related to remote sensing at various levels.\n\n\nMindmap of Week 4 Leacture\n\n\n\n1.1 Using data from sensors\n\n\n\n\n\n\nExample\n\n\n\nMulti-temporal land cover mapping, Spectral signatures / libraries, Change detection, Vegetation stress, Precipitation, Elevation models, Temperature, Night time lights, Forest fire monitoring, Pollution monitoring, Drought indices, Informal housing detection, Water level data monitoring, Building or network outlineextraction, Environmental monitoring, Estimations of resources, Air pollution and LULC, Urban green space, Disaster response and preparedness, Droughts monitoring, Forest fires analysis\n\n\n1.2 Synthetic Aperture Radar (SAR)\nSAR background\n\n\nWhat is Synthetic Aperture Radar?. Source:NASA Earth Data\n\n\n\nActive sensors\nHave surface texture data\nSee through weather and clouds\nDifferent wavelengths - different applications\nDifferent ploarizations\nSAR polarization\nPolarization refers to the orientation of the plane in which the transmitted electromagnetic wave oscillates. While the orientation can occur at any angle, SAR sensors typically transmit linearly polarized. The horizontal polarization is indicated by the letter H, and the vertical polarization is indicated by V\n\n\nSingle = 1 horizontal (or vertical)\n\nDual = transmits and receives both horizontal and vertical\n\nHH = emitted in horizontal (H) and received in horizontal (H)\n\nDifferent surfaces respond differently to the polarizations\n\n\nRough scattering (e.g. bare earth) = most sensitive to VV\n\nVolume scattering (e.g. leaves) = cross, VH or HV\n\nDouble bounce (e.g. trees / buildings) = most sensitive to HH\n\nScattering can change based on wavelength, further penetration then the volume scattering will change\nAmplitude (backscatter) and phase\nA SAR signal has both amplitude (backscatter) and phase data\n\n\n\n\n\n\nTerms\n\n\n\n\nBackscatter is the portion of the outgoing radar signal that the target redirects directly back towards the radar antenna\nThe higher the backscattered intensity = rougher the surface. It is \"unitless\"\n\nCan be converted to “backscatter coefficient, or sigma nought”, measured in decibel (dB) units = normalised measure of the radar return from a distributed target\nIf the signal is from backscatter is not desired = \"clutter\"\n\n\n\n\nBackscatter (amplitude)\n\nPolarization\n\n\nVV = surface roughness\n\nVH = volume of surface (e.g. vegetation has a complex volume and can change the polarization)\n\n\nPermativity (dielectric constant) - how reflective is the property which means reflective back to the sensor. Water usually reflects it off elsewhere\nThe return value, also remember the band (wavelength)\nWind makes the water move and reflect back to the sensor (under VV)\n\nPhase\n\nLocation of wave on the cycle when it comes back to the sensor\nSAR floods\nSensor: Sentinel-1 SAR\n\n\nEl Niño–Southern Oscillation (ENSO) phases but this is from Australian La Niña 2022\n\nTrade winds from south america intensity\nDraw up cool deep waters and increase thermocline\nTemp difference increases, walker circulation intensifies - feedback loop\nMore cloud + more rain + cyclones in West Pacific\n\n\nInterferometry Synthetic Aperture Radar (InSAR)\n\nTake two RADAR observations of the target (e.g. the ground)\nUse the phase difference\n\n\nPhase: “total number of cycles of the wave at any given distance from the transmitter, including the fractional part”\n\nPhase difference: SUBTRACT the values (measured phase values) at two different measurement points\nDifferential distance depends on the height of the terrain (topography)\n\n\nUsed for creating DEMs\n\nMonitoring displacement of ground - earthquakes etc\n\n\n\n\n\n\n\nTerms\n\n\n\n\n\nCoherence Map: Coherence is defined as the degree of similarity of backscattering response (or reflection characteristic of as measured by the SAR sensor) between corresponding ground cells in both SAR image of an InSAR pair. Something is coherent when they are in phase (vibrate in unison)\n\nDifferential Interferometry Synthetic Aperture Radar (DInSAR): “quantification of the ground displacement that occurred between the two acquisitions can be achieved” through a “differential interferogram”\n\n\n\nSAR image\n\n\nUrban objects detection from C-band synthetic aperture radar (SAR) satellite images through simulating filter properties. Source:Deepak Kumar, 2021\n\n\nSAR applications\nDamage detection, Urban area mapping, Urban flooding (lower backscatter coefficient), Landslides, Earthquakes, Data fusion / DEM creation\n1.3 Monitoring forests + illegal logging\n\n\n\n\n\n\nSourse\n\n\n\nHigh-Resolution Global Maps of 21st-Century Forest Cover Change , Sourse: Hansen et al. (2013)\n\n\nSensor: Landsat (2000 to 2012)\nPre-processing\nLandsat pre-processing steps\n\nImage resampling\nConversion of raw digital values (DN) to top of atmosphere (TOA) reflectance\nCloud/shadow/water screening and quality assessment (QA)\n\nImage normalization\n\nThe stack of QA layers was used to create a perpixel set of cloud-free image observations which in turn was employed to calculate timeseries spectral metrics\nCreating metrics\nMetrics represent a generic feature space that facilitates regionalscale mapping and have been used extensively with MODIS and AVHRR data\nHow to create metrics\n\n\nReflectance values representing maximum, minimum and selected percentile values\nMean reflectance values for observations between selected percentiles\nSlope of linear regression of band reflectance value versus image date\n\nThe time-sequential MODIS 32-dayinputs were transformed to annual metrics to produce a more generalized feature space\n\n\n\n\n\n\n\n“a more generalized feature space”\n\n\n\n\n\nFeature space = scattergram of two bands (or things that have been made into bands)\nCan be used for very basic classification - selecting the values that represent land cover\n\n\n\nTraining data (in supervised machine learning)\nTraining data to relate to the Landsat metrics were derived from image interpretation methods, including mapping of crown/no crown categories using very high spatial resolution data such as Quickbird imagery, existing percent tree cover layers derived from Landsat data, and global MODIS percent tree cover, rescaled using the higher spatial resolution percent tree cover data sets\nClassification (supervised or unsupervised)\nDecision trees are hierarchical classifiers (top down) that predict class membership by recursively partitioning (splitting) a data set into more homogeneous or less varying subsets, referred to as nodes\n\n\nA random forest classifier is a collection of decision trees\nTake something complex and force into many decisions = if-else conditions or also called divide and conquer\nOften requires hyperparameters to train the model (or control the learning process)\n\n\nDBSCAN (radius of points, Epsilon or MinPts - to make a cluster)\n\nSpatial weight matrix (type and then weight)\n\n\nSplit the data into more and more homogeneous subsets (filtering!) this can be limited through\n\n\npre-pruning - set a number of iterations before\n\npost-pruning - reduce groups afterwards based on accuracy. Tree fully grows but will be overfit. (In post-pruning first, it goes deeper and deeper in the tree to build a complete tree. If the tree shows the overfitting problem then pruning is done as a post-pruning step. We use a cross-validation data to check the effect of our pruning. Using cross-validation data, it tests whether expanding a node will make an improvement or not. If it shows an improvement, then we can continue by expanding that node. But if it shows a reduction in accuracy then it should not be expanded i.e, the node should be converted to a leaf node.)\n\n\n\n\n\nREMAP method. Source:UN-SPIDER\n\n\n1.4 Integrating analysis\n\n\nExample of integrating analysis. Source: MacLachlan et al. 2021\n\n\n1.5 Global policy documents\nNew Urban Agenda\nStandards and principles for planning, construction, development, management and urban improvement (Environmentally sustainable and resilient urban development subsection)\npoint 64: We also recognize that urban centres worldwide, especially in developing countries, often have characteristics that make them and their inhabitants especially vulnerable to the adverse impacts of climate change and other natural and human-made hazards, including earthquakes, extreme weather events, flooding, subsidence, storms, including dust and sand storms, heatwaves, water scarcity, droughts, water and air pollution, vector-borne diseases and sea level rise, which particularly affect coastal areas, delta regions and small island developing States, among others\npoint 65: We commit ourselves to facilitating the sustainable management of natural resources in cities and human settlements in a manner that protects and improves the urban ecosystem and environmental services, reduces greenhouse gas emissions and air pollution and promotes disaster risk reduction and management, by supporting the development of disaster risk reduction strategies and periodical assessments of disaster risk caused by natural and human-made hazards, including standards for risk levels\npoint 67: We commit ourselves to promoting the creation and maintenance of well-connected and well distributed networks of open, multipurpose, safe, inclusive, accessible, green and quality public spaces, to improving the resilience of cities to disasters and climate change, including floods, drought risks and heat waves to improving food security and nutrition, physical and mental health, and household and ambient air quality, to reducing noise and promoting attractive and liveable cities, human settlements and urban landscapes and to prioritizing the conservation of endemic species\nSustainable Development Goals (SDG): targets with measurable indicators for monitoring\nGoal 11: Make cities and human settlements inclusive, safe, resilient and sustainable\nTarget 11.5: By 2030, significantly reduce the number of deaths and the number of people affected and substantially decrease the direct economic losses relative to global gross domestic product caused by disasters, including water-related disasters, with a focus on protecting the poor and people in vulnerable situations\n\nMonitoring 11.5\n\n11.5.1 Number of deaths, missing persons and directly affected persons attributed to disasters per 100,000 population\n11.5.2 Direct economic loss attributed to disasters in relation to global gross domestic product (GDP)\n11.5.3 (a) Damage to critical infrastructure and (b) number of disruptions to basic services, attributed to disasters\n\n\nData 11.5\n\n11.5.1 (and .2) Data provider at national level is appointed Sendai Framework Focal Points. In most countries disaster data are collected by line ministries and national disaster loss databases are established and managed by special purpose agencies including national disaster management agencies, civil protection agencies, and meteorological agencies. The Sendai Framework Focal Points in each country are responsible of data reporting through the Sendai Framework Monitoring System.\n11.5.3 National disaster loss database, reported to UNISDR…Not every country has a comparable national disaster loss database that is consistent with these guidelines (although current coverage exceeds 89 countries). Therefore, by 2020, it is expected that all countries will build/adjust national disaster loss databases according to the recommendations and guidelines by the OEIWG\n\n\n\nTarget 11.6: By 2030, reduce the adverse per capita environmental impact of cities, including by paying special attention to air quality and municipal and other waste management\n\nIndicator 11.6.2: Annual mean levels of fine particulate matter (e.g. PM2.5 and PM10) in cities (population weighted)\n\nTarget 11.7: By 2030, provide universal access to safe, inclusive and accessible, green and public spaces, in particular for women and children, older persons and persons with disabilities\n\nIndicator 11.7.1: Average share of the built-up area of cities that is open space for public use for all, by sex, age and persons with disabilities\n1.6 Metropolitan policy documents\nLondon\n\nIncreasing efficiency and resilience: These environmental threats are real and present, and London must be prepared for them. London’s homes and infrastructure must be protected against the increasing likelihood of heatwaves, and developments must plan for a more integrated approach to water management, while minimising flood risk\nPolicy SI 12 Flood risk management: Development Plans should use the Mayor’s Regional Flood Risk Appraisal and their Strategic Flood Risk Assessment as well as Local Flood Risk Management Strategies, where necessary, to identify areas where particular and cumulative flood risk issues exist and develop actions and policy approaches aimed at reducing these risks\nOneNYC 2050\n\nReferences the sustainable development goals\nHas a hazards matrix\nCape Town: Cape Town Municipal Spatial Development Framework\n\n2015-2018 “worst recorded drought in the city’s history, is a stark reminder that all cities will need to become more robust, resilient and efficient”\n“The Cape Town Spatial Development Framework (CTSDF) was approved in May 2012 and established a long-term spatial vision and policy framework for the City after extensive technical drafting and public participation.”\n“Careful management of development to avoid developing in high flood risk areas”\nAhmedabad: 2016 Heat Action Plan\n\nAwareness and outreach\nEarly warning system\nCapacity of health care professionals\nReduce heat exposure and promote adaptive mesaures …and mapping high risk areas, although mapping was removed later in the document (page 11)\n1.7 Local policy documents\nIn most of the previous examples the documents were created by the metropolitan government, they set the strategic plan for the city and may have other responsibilities such as fire, policing, transport and development guidelines. Lower tier government then carries out or adheres to these goals, but there are variations to this rule\nCity of Cape Town\n\nThe City of Cape Town is a metropolitan municipality or Category A municipality, there is no local municipality below it\nHowever, above the City of Cape Town is the Provincial government that is responsible for topics such as: agriculture, education, health and public housing. As such the City sets it’s own development plan and then implements it (whilst adhering to relevant Provincial topics)\nNew York\n\nCity of New York is responsible for public education, correctional institutions, public safety, recreational facilities, sanitation, water supply, and welfare services\n5 Boroughs under it act as spokespeople\nCity Council has 51 members from districts of about 157,000\nNew York City is responsible for setting and enacting the policy. State government is above it"
  },
  {
    "objectID": "WEEK4.html#summary-practical",
    "href": "WEEK4.html#summary-practical",
    "title": "WEEK 4",
    "section": "2 Summary: practical",
    "text": "2 Summary: practical\n\nThe summary of the policy and city I have selected.\n\n\n\n\n\n\n\nbackground\n\n\n\nIstanbul, the largest city in Turkey and connecting Europe and Asia, is scaling up its urban regeneration by joining the European Bank for Reconstruction and Development’s flagship EBRD Green Cities urban sustainability programme. Source: EBRD\n\n\n2.1 City\nIstanbul\nIstanbul, formerly known as Constantinople, is the largest city in Turkey, serving as the country’s economic, cultural and historic hub. The city straddles the Bosporus strait, lying in both Europe and Asia, and has a population of over 15 million residents, comprising 19% of the population of Turkey. Istanbul is the most populous European city, and the world’s 15th-largest city.\n\n\nİstanbul view\n\n\n\n\nİstanbul at a glance. Source: Governership of Istanbul\n\n\nEnvironment challange\nIstanbul are faces many environmental problems.\n\n\nUrban expansion and land use change: Istanbul has experienced rapid urbanisation in recent years, resulting in the expansion of the city and the replacement of green spaces and ecologically sensitive areas with built-up land. This land use change has had a negative impact on the urban ecosystem, such as a decline in biodiversity and destruction of natural habitats.\n\nAir pollution: Istanbul has a growing air quality problem, mainly caused by traffic emissions, industrial emissions and fossil fuel combustion.\n\nWater management: Water management issues in Istanbul include water scarcity, water quality pollution and deterioration of the water environment. With the growth of the city’s population and industrial development, the conflict between water supply and demand has increased and the pressure on the water environment to carry water has increased.\n\nUrban heat island effect: With the accelerated urbanisation, the density of buildings and roads in Istanbul is increasing, leading to a more pronounced urban heat island effect.\n\nTherefore, the implementation of a green city plan is urgent.\n2.2 Policy\nEBRD Green Cities\nTo address environmental challenges, the EBRD developed EBRD Green Cities, with the aim of building a better and more sustainable future for cities and their residents. The programme has three central components:\n\nGreen City Action Plans (GCAPs): Assessing and prioritising environmental challenges, and developing an action plan to tackle these challenges through policy interventions and sustainable infrastructure investments.\nSustainable infrastructure investment: Facilitating and stimulating public or private green investments in: water and wastewater, urban transport, district energy, energy efficiency in buildings, solid waste and other interventions that improve the city’s adaptation and resilience to climate shocks.\nCapacity-building: Providing technical support to city administrators and local stakeholders to ensure that infrastructure investments and policy measures identified in GCAPs can be developed, implemented and monitored effectively.\n\nEBRD Green city aims to:\n\nPreserve the quality of environmental assets (air, water, land and biodiversity) and use these resources sustainably.\nMitigate and adapt to the risks of climate change.\nEnsure that environmental policies and developments contribute to the social and economic well-being of residents.\n\nThe path to becoming a Green City is continuous, allowing cities to adjust their strategic goals and visions over time. The process has three key stages:\n\nDeveloping a Green City Action Plan (GCAP)\n\nIdentifying and prioritising challenges\nPlanning actions\n\n\nImplementing the GCAP\nMonitoring THE GCAP"
  },
  {
    "objectID": "WEEK4.html#application",
    "href": "WEEK4.html#application",
    "title": "WEEK 4",
    "section": "3 Application",
    "text": "3 Application\n\nHow the remotely sensed data you sourced could be used to assist with contributing to the policy goal. How could the data be applied to solve the policy challenge.\n\nAccording to EBRD Green city，The first step in developing a GCAP involves assessing the city’s environmental performance using 35 core indicators that cover a wide range of urban issues. The indicators evaluate the state of the city’s environmental assets, its overall resource efficiency and climate change risks. Therefore, the remote sensing data could be applied to evaluate and monitor the city’s environmental performance.\nDue to the large number of indicators, we are unable to discuss them all here, so we are analysing the environmental issues that stand out in Istanbul.\n\n\nUrban expansion and land use change: By classifying and detecting land cover changes from remote sensing imagery over multiple time periods, the rate of urban expansion, land use changes and ecological impacts in Istanbul can be assessed. Land use type classification using Landsat or Sentinel-2 satellite data combined with classification algorithms (e.g. support vector machines, random forests, etc.).\n\nAir pollution: Use remote sensing data to monitor concentrations of atmospheric pollutants (e.g. nitrogen oxides, particulate matter, etc.) and to assess the air quality status of Istanbul. Air pollutant concentrations are monitored using satellite data such as MODIS and Sentinel-5P, combined with air pollutant inversion methods.\n\nWater management: The extraction of hydrological parameters from remote sensing data, such as the area of water bodies, suspended sediment concentrations and chlorophyll a concentrations, allows the assessment of water resource status and water pollution in Istanbul. In addition, synthetic Aperture Radar (SAR) data can be used to detect water environment problems such as oil pollution on water surfaces.\n\nUrban heat island effect: Remote sensing data is used to calculate surface temperatures and to analyse the distribution and influencing factors of the urban heat island effect. Landsat and MODIS data are used in conjunction with surface temperature inversion methods to assess the urban heat island effect in Istanbul.\n\n\n\nland surface temperature (LST) distribution (a) and map of the Surface Urban Heat Island (SUHI) effect (b) on 25th July 2017 in Istanbul. LST anomalies above the average (34.73 °C) indicate the SUHI effect at various levels. Source: Erdem Okumus and Terzi (2021)"
  },
  {
    "objectID": "WEEK4.html#reflection",
    "href": "WEEK4.html#reflection",
    "title": "WEEK 4",
    "section": "4 Reflection",
    "text": "4 Reflection\n\nWhat I have learnt in relation to the policy, city and the application of the data.\n\nThrough this week’s study, I learnt about the scenarios and application methods of remote sensing images, as well as many different levels of policies related to remote sensing. In the process of learning, I gradually found out the role that remote sensing imagery can play in urban policy: assessment and monitoring. Remote sensing images can provide a wealth of information to assist in decision making, but on the other hand they also need to be responsive to policy in order to create value. As the EBRD Green city also provides over 50 policy tools to help promote and implement policy. It is only when the application of remote sensing data is closely aligned with urban policy that the information can be used to maximum effect.\nIn the field of urban planning, remote sensing data is even more closely integrated with policies, for example, [the evaluation of the carrying capacity of resources and environment and the suitability of territorial spatial development] launched in China in recent years, which is guided by policies, using various types of data including remote sensing data to evaluate the development of territorial space. Meanwhile, the results obtained from remote sensing data often rely on policy tools such as urban planning for implementation.\n\n\n\n\nErdem Okumus, Deniz, and Fatih Terzi. 2021. “Evaluating the Role of Urban Fabric on Surface Urban Heat Island: The Case of Istanbul.” Sustainable Cities and Society 73 (October): 103128. https://doi.org/10.1016/j.scs.2021.103128.\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A. Tyukavina, D. Thau, et al. 2013. “High-Resolution Global Maps of 21st-Century Forest Cover Change.” Science 342 (6160): 850–53. https://doi.org/10.1126/science.1244693."
  },
  {
    "objectID": "WEEK5.html",
    "href": "WEEK5.html",
    "title": "WEEK 5",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 5, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK5.html#summary-lecture",
    "href": "WEEK5.html#summary-lecture",
    "title": "WEEK 5",
    "section": "1 Summary: lecture",
    "text": "1 Summary: lecture\nThis week’s content is an introduction to the basics of GEE, including its features, functions and application scenarios. It also introduces the use of the basic functions of GEE Javascript in relation to R, such as loading image collections, reducing images, regression, joins and filtering.\n\n\nMindmap of Week 5 Leacture\n\n\n\n1.1 The setup of GEE\nGoogle Earth Engine\n\n\n\n\n\n\n\n\n\n\n\"Geospatial\" processing service\nIt permits geospatial analysis at scale\n\nStores data on servers\nTakes the code and applies it\nCan be used to make queryable online applications\n\n\n\n\n\n\n\n\nGEE terms\n\n\n\n\n\nImage = raster\n\nFeature = vector\n\nImage stack = ImageCollection\n\nFeature stack (lots of polygons) = FeatureColletion\n\n\n\nGEE Javascript\nGEE uses Javascript (Website programming language)\nThere are some similarities to python and R but there are some notable differences\n\nVariables (or objects) as defined with var\nA specific part of code ends with a ;\nObjects are dictionaries in Javascript\nClient vs server side\n\nWithin GEE we have code that runs on the client side (browser)\n\nWe have code that runs on the server side (on the server where data is stored)\nIn GEE we have Earth Engine Objects = starting with , for example, ee\n\nAnything that has ee in front of it is stored on the server\n\nIt has no data in script. Recall in R the data environments, this would be empty\nThey are termed \"proxy objects\": the agency, function, or office of a deputy who acts as a substitute for another\nAny pre-loaded data product will be on the server side\n\n\n\nLooping\n\nWe can’t (or shouldn’t) use a loop for something on the server\nThe loop doesn’t know what is in the ee object\n\nMapping functions\n\nInstead we can create a function and save it into an object (or variable here)\nThen apply it to everything on the server\nSame idea as map() in R from the purrr package\n\nServer side functions\n\nSame as the data\nee.Thing.method()\nSaved function on the sever that can be run without mapping\nLoop vs Map\nLoop\n\nRun some code on each element in an array\nSave it in a new array (or update existing)\n\nMap\n\nCode is applied to each element\nThe conditions are dealt with, no indexing at the end\n\nWhy map in GEE?\n\nOtherwise we might load the complete image collection many, many times when looping\nThe loop doesn’t know what is inside the collection\nMapping lets GEE allocate the the processing to different machines with map. I assume as it knows how many images we have and the function it must apply…With a loop it doesn’t know until the next interation\nScale\n\nImage scale in GEE refers to pixel resolution\n\nIn GEE the scale (resolution) is set by the output not input\n\nWhen doing analysis\n\nGEE aggregates the image to fit a 256x256 grid\n\nEarth Engine selects the pyramid with the closest scale to that of analysis (or specified by it) and resamples as needed\nresampling uses nearest neighbor by default\n\n\nProjections\n\nDo not need to worry about projects in GEE\nGEE converts all data into the Mercator projection (EPSG: 3857) when displayed, specifically: WGS 84 / Pseudo-Mercator – Spherical Mercator, Google Maps, OpenStreetMap, Bing, ArcGIS, ESRI\nThe operations of the proejction are determined by the output\nSetting the projection is allowed, but there is no real reason to do this\n1.2 GEE in action\n\n\nWhat does GEE look like. Source: lecture\n\n\nBuilding blocks of GEE\n\n\nObject classes. Source: GEE\n\n\nObject: vector, raster, feature, string, number\n\nEach of these belongs to a class\n\nEach class has specific GEE functions (or methods) for it\n\nRaster data (lots of images)\n\nThey belong to an image collection (as there are lots of images)\nUsing the specific function (method or \"constructor\") to load and manipulate\n\nGeometries and Features\n\n\nGeometry = point/line/polygon with no attributes\n\nNote we can also have MultiPolygon or MultiGeometry\n\n\n\nFeature = geometry with attributes\n\nFeature collection = several features with attributes\nWhat typical processes can do in GEE?\nGeometry operations (e.g. spatial operations)\n\nJoins\n\nZonal statistics (e.g. average temperature per neighbourhood)\n\nFiltering of images or specific values\n\nMethods\n\nMachine learning\nSupervised and unsupervised classification\n\n\nDeep learning with Tensor Flow\nExploring relationships between variables\n\nApplications/outputs\n\nOnline charts\nScalable geospatial applications with GEE data\nThese let us query the data with a user inteface that then updates the results\nReducing images\nThis is combines the previous two ideas\n\nIn the first instance we load an image collection from a dates and place\nWe want to reduce the collection to the extreme values for each pixel\n\nReducing images by region\n\nOne of the most useful functions we can use here is termed zonal statistics\nIn GEE this is termed reduceRegion()\n\nWhat if we want to use a feature collection (with many polygons), same idea, but with image.reduceRegions()\n\n\nReducing images by neighbourhood\n\nInstead of using a polygon to reduce our collection we can use the image neighbourhood\n\nA window of pixels surrounding a central pixel\nLike a filter or texture measure\nAlthough texture has its own function\n\n\nLinear regression\nThe real benefit of GEE is being able to access all imagery for multiple sensors, what if we wanted to see the change over time in pixel values - linearFit()\n\n\nlinearFit() takes a least squares approach of one variable. 2 bands:\n\nBand 1: dependent variable\nBand 2: independent variable (often time)\n\n\nThis runs of a per pixel basis\nThis is still considered a reducer as we are reducing all of the data to two images\n\n\nOffset - intercept\n\nScale - line of the slope We can use additional variables like we have seen before, including multiple dependent variables…this is termed Multivariate Multiple Linear Regression. This just does the same as OLS for both of the dependent variables, the only difference is with a covariance matrix.\n\n\n\nWe can combine reducers for regression\n\nRegression per pixels (typically with an image collection over several years)\nRegression of all the values within a polygon (taking an image of 1 date, extracting all the pixels and then running regression)\nIn GEE we must add a constant as an independent variable for the intercept (unless it is 0)\nJoins\nJoins in GEE are similar to joins in R\n\nWe can join image collections (e.g. satellite data from January with data from October)\nWe can join feature collections (e.g. different polygons)\n\nTo use joins we have to put them within a filter (ee.Filter)\n\nThe leftField is the index (or attribute) in the primary data\nThe rightField is the secondary data\nWe set the type of join\n\nsimple: primary matches any in secondary\ninverted: retain those in primary that are not in secondary\ninner: shows all matches between collections as a feature collection\n\n\nWe then combine (or join) with join.apply()\n\n\nGEE can also do a spatial join and intersect"
  },
  {
    "objectID": "WEEK5.html#summary-practical",
    "href": "WEEK5.html#summary-practical",
    "title": "WEEK 5",
    "section": "2 Summary: practical",
    "text": "2 Summary: practical\n\nThis week’s practical will consist mainly of the following:\n\nAcquire remote sensing image data using GEE and perform basic operations such as clipping and mosaicing of data\nRemote sensing image pre-processing and band mathing using GEE\nExporting GEE analysis results\nGEE-related applications and data\n\n\nIn this week’s practical, I learnt the basic operations of remote sensing data processing using GEE. I followed the instructions to process and analyse the Landsat remote sensing image data from New Delhi, including texture measures, PCA, band math, etc. However, I was pleasantly surprised to learn about a lot of applications developed using GEE, which were very interesting and greatly broadened my view of remote sensing image applications and made me look forwards to developing applications using GEE.\n\n\nPCA analysis of Landsat 8 images in New Delhi."
  },
  {
    "objectID": "WEEK5.html#application",
    "href": "WEEK5.html#application",
    "title": "WEEK 5",
    "section": "3 Application",
    "text": "3 Application\n\nAs mentioned above, there are a wide variety of valuable applications that can be developed using GEE, and I would like to explore the applications that can be developed based on GEE\n\n3.1 Applications developed on the basis of GEE\nGEE provides powerful computing capabilities for processing and analysing geospatial data and can be of great use in a number of areas.\nLand cover change detection: By comparing remotely sensed images from different time periods, land cover changes such as urban expansion, deforestation and wetland degradation can be detected. For example: Google Earth Engine Timelapse.\nForest health monitoring: Using high resolution and multi-temporal remote sensing imagery to analyse forest growth and identify forest health issues such as pests, drought and fire. For example: Global Forest Watch (GFW).\nAgricultural management: Remote sensing imagery is used to analyse crop growth, acreage and yields to provide strong support for agricultural production and food security. For example: Cropland Mapping App.\nWater resources monitoring: Using remote sensing data to analyse the area of water bodies, water quality conditions and changes in water resources, providing a scientific basis for water resources management and protection. For example: Global Surface Water Explorer (GSWE).\nClimate change research: To explore the causes and impacts of climate change by analysing long-term changes in surface temperature, precipitation, snow and ice and other climate factors. For example: Climate Engine.\nDisaster assessment and management: Using remote sensing images to detect natural disasters such as floods, earthquakes and landslides in a timely manner, providing information to support disaster assessment and rescue work. For example: DFO Flood Observatory Web Map Server.\nEcosystem service assessment: Evaluate the value of ecosystem services to humans by analysing ecological indicators such as land cover, vegetation productivity and biodiversity. For example: NDVI slider.\nUrban planning and management: Analyse urban construction land, traffic conditions and green space distribution through remote sensing images to provide decision support for urban planning and management. For example: Urbanization Explorer.\nAir quality monitoring: Using remote sensing data to analyse the concentration and distribution of atmospheric pollutants, providing data support for air quality monitoring and environmental protection. For example: Europe’s Air Quality Winner.\nWildlife protection: analyse wildlife habitats, migration paths and the status of protected areas through remote sensing images to provide scientific basis for wildlife protection. For example: eBird.\n3.2 Application case\n\n\n\n\n\n\nSourse\n\n\n\nGlobal Forest Watch (GFW) , Sourse: GFW\n\n\nAbout GFW\nGlobal Forest Watch (GFW) is an online platform that provides data and tools for monitoring forests. By harnessing cutting-edge technology, GFW allows anyone to access near real-time information about where and how forests are changing around the world.\n\n\n\n\n\n\n\n\nMap & dashboards on GFW\nThe map & dashboards on GFW allow to explore hundreds of spatial datasets that help explain when, where and why forests are changing around the world.\nThe map helps tell a visual story about what’s happening to forests in a particular place. Zoom in anywhere in the world to explore how forests are changing, how they’re managed and the values they provide. Layer data – like annual tree cover loss, land use data and satellite imagery – to better understand the underlying causes and impacts of forest change.\nThe dashboards help answer important questions about forest change in any area and enable you to view hundreds of statistics through interactive charts and graphs, all derived from analysis of spatial data. Statistics can be customized to be as general or specific as you like and can be easily shared and downloaded for offline use.\n3.3 Case comments\nAdvantages or contribution\n\nGlobal: GFW can provide forest monitoring data and information on a global scale, allowing governments, businesses, NGOs and citizens to understand the state of the world’s forest resources.\nTimeliness: GFW can provide almost real-time forest monitoring data and information that can help identify and respond to deforestation, wildfires and other natural disasters in a timely manner.\nDiversity: GFW can provide a wide range of data and information, including maps, satellite imagery, data analysis and stories, to meet the needs of a variety of users.\nOpenness: GFW uses open data principles that allow anyone to use and share data and information, thus increasing the reliability and value of the data used.\n\nDisadvantages or potential\n\nData quality: GFW relies on a variety of data sources, including satellite imagery, ground-based observations, interviews, etc. Data quality varies and may be subject to error.\nData updates: Although GFW can provide almost real-time forest monitoring data and information, some data can be slow to update and it can take some time to wait for the latest data to become available.\nThreshold of data use: GFW data and information require a certain level of expertise and skills to use and analyse, which may be difficult for non-expert users.\nData privacy: GFW’s data and information may contain some sensitive information that requires attention to data privacy protection."
  },
  {
    "objectID": "WEEK5.html#reflection",
    "href": "WEEK5.html#reflection",
    "title": "WEEK 5",
    "section": "4 Reflection",
    "text": "4 Reflection\nDuring the week I have been learning about the basic principles and operational aspects of GEE and have been excited to learn about the many applications of GEE. Sometimes I want to upload my research to the web for interactive use, but I don’t know much about web development or software development due to my professional background, and GEE provides a platform for this, as well as a very rich data source and analysis tools to support the development of applications, which has a very wide range of applications. In addition, the interactive web platform provides a window of communication between urban planning and the public, making it easier to collect and publicise data.\nHowever, I have concerns about data privacy and copyright. On the one hand, I am concerned that my privacy may be compromised, and on the other hand, I am concerned that there may be unknowing copyright infringement in the data used, which requires careful attention during development."
  },
  {
    "objectID": "WEEK6.html",
    "href": "WEEK6.html",
    "title": "WEEK 6",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 6, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK7.html",
    "href": "WEEK7.html",
    "title": "WEEK 7",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 7, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK8.html",
    "href": "WEEK8.html",
    "title": "WEEK 8",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 8, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Abbas, Sawaid, Qian Peng, Man Sing Wong, Zhilin Li, Jicheng Wang, Kathy\nTze Kwun Ng, Coco Yin Tung Kwok, and Karena Ka Wai Hui. 2021.\n“Characterizing and Classifying Urban Tree Species Using\nBi-Monthly Terrestrial Hyperspectral Images in Hong\nKong.” ISPRS Journal of Photogrammetry and\nRemote Sensing 177 (July): 204–16. https://doi.org/10.1016/j.isprsjprs.2021.05.003.\n\n\nDeng, J. S., K. Wang, Y. H. Deng, and G. J. Qi. 2008.\n“PCA‐based Land‐use Change Detection and Analysis\nUsing Multitemporal and Multisensor Satellite Data.”\nInternational Journal of Remote Sensing 29 (16): 4823–38. https://doi.org/10.1080/01431160801950162.\n\n\nErdem Okumus, Deniz, and Fatih Terzi. 2021. “Evaluating the Role\nof Urban Fabric on Surface Urban Heat Island: The Case of\nIstanbul.” Sustainable Cities and Society\n73 (October): 103128. https://doi.org/10.1016/j.scs.2021.103128.\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A.\nTyukavina, D. Thau, et al. 2013. “High-Resolution\nGlobal Maps of 21st-Century\nForest Cover Change.”\nScience 342 (6160): 850–53. https://doi.org/10.1126/science.1244693."
  }
]