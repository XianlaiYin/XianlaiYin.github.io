[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Diary",
    "section": "",
    "text": "Introduction\n\n\n\n\n\n\nAcknowledgements\n\n\n\nMany thanks to the lecturer Dr Andrew MacLachlan and all CASA teachers for their contributions to this course.\n\n\nAbout this website\nThis website will include a summary of the content of CASA0023 Remotely Sensing Cities and Environments and my thoughts and ideas based on the content of the course.\nAbout me\nHi, I am Xianlai Yin from Jiangxi, China. I am currently studying in MSc Urban Spatial Science at the Bartlett Centre for Advanced Spatial Analysis, UCL. My undergraduate degree is in Urban and Rural Planning at Chang’an University.\nMy research experience is mainly related to urban planning, including the study of the spatial structure of urban agglomerations based on social network analysis methods, and the study of the resilience of urban transport networks. My work experience is mainly in the field of urban construction, including working as an intern planner at the institute of urban planning and design and as an intern in the smart city department of a real estate company.\nI am very interested in the application of spatial data analysis in the field of urban planning, and remote sensing can provide a wide and diverse source of data. Therefore, I took CASA0023 in the hope of studying the application of remote sensing technology in the field of urban analysis. Meanwhile, during the creation of this learning dairy, thinking will mainly from the perspective of urban planning.\n\n\nContent\n\n\n\nWEEK\nTHEME\n\n\n\n\nWEEK 1\nAn Introduction to Remote Sensing\n\n\nWEEK 2\nPortfolio tools: Xaringan and Quarto\n\n\nWEEK 3\nRemote sensing data\n\n\nWEEK 4\nPolicy applications\n\n\nWEEK 5\nAn introduction to Google Earth Engine\n\n\nWEEK 6\nClassification\n\n\nWEEK 7\nClassification the big questions and accuracy\n\n\nWEEK 8\nTemperature and policy"
  },
  {
    "objectID": "WEEK1.html",
    "href": "WEEK1.html",
    "title": "WEEK 1",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 1, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK1.html#summary-lecture",
    "href": "WEEK1.html#summary-lecture",
    "title": "WEEK 1",
    "section": "1 Summary: lecture",
    "text": "1 Summary: lecture\nThis week’s content focuses on an introduction to basic information on remote sensing and Electromagnetic radiation (EMR).\n\n\n\nMindmap of Week 1 Leacture\n\n\n\n\n1.1 Remote sensing\n\nDefinition\nNASA defines remote sensing as acquiring information from a distance, interchangeable used with Earth Observation or EO.\n\n\nData acquisition\nThis is achieved through sensors mounted on a platform, e.g. satellites, planes (aerial imagery), drones, phones, free standing on the ground or sea (with hand held devices), there are more than 150 satellites in orbit carrying sensors.\n\n\nAdvantages\n\nMass of data: satellites collect data on the same points on Earth every day to every 16 days\nFrequency of update and less reliance on authorities (e.g. London Atlas)\nMore free resources to process large volumes of data (e.g. Google Earth Engine)\n\n\n\nTypes of sensor\nPassive sensor\n\nUse energy that is available\nDon’t emit anything\nUsually detecting reflected energy from the sun\nEnergy is in electromagnetic waves…\nSuch as: Human eye, camera, satellite sensor\n\nActive sensor\n\nHave an energy source for illumination\nActively emits electormagentic waves and then waits to receive\nSuch as: Radar, X-ray, LiDAR\n\n\n\n\n1.2 Electromagentic waves\n\n\n\n\n\n\nTerms\n\n\n\n\nWaves of an electromagnetic field, travel through space and carry radiant energy = Electromagnetic radiation (EMR). Waves are part of the EMR spectrum.\nEnergy carried by EMR waves = radiant energy\nEnergy per unit of time = radiant flux\nEnergy from the sun = incoming short wave radiation or shortwave radiation\nEnergy (solar power) from the sun per unit area per unit time (from electromagnetic radiation) = solar irradiance (per unit time - flux)\nEnergy leaving a surface per unit area per unit time = Exitance (emittance) (per unit time - flux)\nFlux means time here.\n\n\n\n\nElectromagnetic radiation (EMR)\nEMR has both electric and magnetic fields, propagates (moves) as waves: c = vλ\n\nc = velocity of light 3 x 10^8 meters per second\nv = frequency, rate of oscillation\nλ = wavelength, distance between two crests\n\nEMR isn’t automatically reflected. It experiences a number of changes prior to hitting the sensor\n\nSurface: Energy being absorbed by the surface and being transmitted through the surface\nAtmospheric: Energy can be scattered by particles in the atmosphere\n\n\n\n\n1.3 Interacting with Earth’s surface\n\nAtmospheric scattering\n\nRayleigh = particles are very small compared to the wavelength\nMie = particles are the same size compared to the wavelength\nNon selective = particles are much larger than the wavelength\n\n\n\nSynthetic Aperture Radar (SAR)\n\nRadar collects at longer wavelengths than optical sensors - pass through clouds that have smaller particle sizes (wavelength dictates how far it can penetrate into medium)\nHas it’s own bands - e.g. P, L, S, C, X, Ku, K\nCollects data at night\n\n\n\nBidirectional Reflectance Distribution Function (BRDF)\n\nView (e.g. sensor) and illumination (e.g. sun) angles can change\nEnergy being reflected from the surface that is smooth or diffuse\n\n\n\nPolarization\nDefinition\nApplicable to Radar: Electromagnetic waves are polarized and the direction depends on the oscillation of the electromagnetic field. When they are reflected from the surface the waves can be linked to surface properties - roughness, shape, orientation, moisture, salinity, density.\nDifferent ploarizations\n\nSingle polarization: same polarization transmitted and received = 1 horizontal (or vertical)\nDual polarization: One sent, different one received = transmits and receives both horizontal and vertical\nQuad polarization: system can transmit and receive four types = emitted in horizontal (H) and received in horizontal (H)\n\n\n\n\n1.4 Remote sensing data\n\nData formats\n\nband interleaved by line (BIL)\nband sequential (BSQ)\nband interleaved by pixel (BIP)\nGeoTIFF (most common)\n\n\n\nFour resolutions\n\nSpatial = the size of the raster grid per pixel (e.g. 20cm or 30m)\nSpectral = the number of bands it records data in…more soon\nTemporal = the time it revisits (e.g. daily, every 7 days, on demand)\nRadiometric = identify differences in light or reflectance, in practice this is the range of possible values.\n\n\n\n\nSpectral resolution. Source: NASA Science\n\n\n\n\nType of orbit\n\ngeosynchronous orbit (GSO) = satellite matches the Earth’s rotation\ngeostationary orbit = holds same position, usually only for communications but some sensors are geostationary."
  },
  {
    "objectID": "WEEK1.html#summary-practical",
    "href": "WEEK1.html#summary-practical",
    "title": "WEEK 1",
    "section": "2 Summary: practical",
    "text": "2 Summary: practical\n\nThis week’s practical will consist mainly of the following:\n\nAcquisition and reading of remote sensing data\nThe specifics of processing remote sensing data using SNAP and R\nMethods for viewing the spectra of remote sensing data and comparing spectral features\n\n\nFor this week’s practical I chose Chelmsford, a city in the north-east suburbs of London, as my study area. I also followed the practical’s instructions to operate on remote sensing images within its administrative area. Through this practical I became familiar with the use of SNAP and the remote sensing related package of R. I also learnt about some of the features of remote sensing imagery, such as spectral features, through these operations.\n\n\n\nPractical output: SNAP operating screen"
  },
  {
    "objectID": "WEEK1.html#application",
    "href": "WEEK1.html#application",
    "title": "WEEK 1",
    "section": "3 Application",
    "text": "3 Application\n\nThis week’s lecture is mainly about the basic knowledge of remote sensing and Electromagnetic radiation (EMR), so I would like to introduce some of the remote sensing applications based on spectral characteristics.\n\n\n3.1 Remote sensing applications based on spectral features\nRemote sensing uses spectral features to identify, classify and analyse a variety of features on the surface or in the atmosphere. Remote sensing has many applications using spectral features：\n\nIn the field of agriculture, the spectral characteristics of vegetation can be used to monitor the growth of crops, damage, yield prediction, etc.\nIn the field of environmental, the spectral characteristics of water bodies, soil and atmosphere can be used to monitor water quality, soil types, pollutant types and concentrations, etc.\nIn the field of geology, the spectral characteristics of rocks, minerals, etc. can be used to detect mineral resources, geological formations, seismic activity, etc.\nIn the field of urban planning, the spectral characteristics of buildings, roads, etc. can be used to extract urban spatial information, assess the level of urban development and influencing factors, etc.\n\nThe specific application methods of remote sensing based on spectral features in the field of urban planning are mainly as follows:\n\nUsing remote sensing images to obtain information on the current situation of land use, analyse the structure and spatial distribution characteristics of urban land use, and provide basic data for urban planning.\nUsing remote sensing images for urban ecological environment evaluation, monitoring urban heat island effect, air quality, tree health, water quality and other environmental indicators, and providing ecological guarantee for urban planning.\nUse remote sensing imagery for urban construction change monitoring, identifying the impact of urban construction activities on land use, and providing dynamic management for urban planning.\n\n\n\n3.2 Application case\n\n\n\n\n\n\nSourse\n\n\n\nCharacterizing and classifying urban tree species using bi-monthly terrestrial hyperspectral images in Hong Kong , Sourse: Abbas et al. (2021)\n\n\nUrban trees exhibit a wide range of ecosystem services that have long been unveiled and increasingly reported. The ability to map tree species and analyze tree health conditions would become vividly essential. Remote sensing techniques, especially hyperspectral imaging, are being evolved for species identification and vegetation monitoring from spectral reponse patterns.\n\n\n\nAn example of image clustering and corresponding spectral signatures of classes. The shadow class in grey represents canopy shadow and/or branches, and the shadow class in orange indicates shaded leaves.\n\n\nIn this study, a hyperspectral library for urban tree species in Hong Kong was established comprising 75 urban trees belonging to 19 species. 450 bi-monthly images were acquired by a terrestrial hyperspectral camera (SPECIM-IQ) from November 2018 to October 2019. A Deep Neural Network classification model was developed to identify tree species from the hyperspectral imagery with an overall accuracy ranging from 85% to 96% among different seasons. Representative spectral reflectance curves of healthy and unhealthy conditions for each species were extracted and analyzed. This can be used to identify urban trees and monitor their health.\n\n\n\nThe overall workflow of species classification framework using the Deep Neural Network modelling.\n\n\n\n\n3.3 Case comments\nAdvantages or contribution\n\nA hyperspectral library for urban tree species in Hong Kong was established , and trees were classified and detected with high accuracy, which could be a valuable resource for future research in Hong Kong or similar environments.\nHyperspectral phenology models were developed using deep neural network classification models to optimise data acquisition and improve accuracy in monitoring tree health, which provides experience in the field of machine learning of remote sensing images.\n\nDisadvantages or potential\n\nHyperspectral image acquisition cost and processing complexity: Acquisition and processing of hyperspectral images may be more costly and complex compared to other remote sensing techniques, and may face cost issues in actual applications.\nData set limitations: The study focuses on urban trees in Hong Kong and may not be directly applicable to other regions or cities with different ecological conditions. Expanding the study to include a wider range of geographical and ecological conditions would make the results more generalisable."
  },
  {
    "objectID": "WEEK1.html#reflection",
    "href": "WEEK1.html#reflection",
    "title": "WEEK 1",
    "section": "4 Reflection",
    "text": "4 Reflection\nDuring this week I have learnt about the basics of remote sensing and Electromagnetic radiation (EMR), which has greatly broadened my horizons when researching urban. Due to limited data collection facilities, detailed urban datasets (e.g. traffic flow data, mobile phone signalling data, etc.) are only available for main cities in developed areas, which makes many studies not reproducible in a wide range of non-developed or small cities. However, the extensive coverage of remote sensing data compensates well for this shortcoming, and the variety of data collected through the rich diversity of sensors can be of great help in urban (or regional) analysis.\nHowever, there are some limitations to remote sensing data at the level of accuracy and price. On the one hand, there is relatively little high-precision remote sensing data for inner-city scale studies, and on the other hand, high-precision data often leads to huge costs, which in practice can lead to some technologies not being implemented.\n\n\n\n\nAbbas, Sawaid, Qian Peng, Man Sing Wong, Zhilin Li, Jicheng Wang, Kathy Tze Kwun Ng, Coco Yin Tung Kwok, and Karena Ka Wai Hui. 2021. “Characterizing and Classifying Urban Tree Species Using Bi-Monthly Terrestrial Hyperspectral Images in Hong Kong.” ISPRS Journal of Photogrammetry and Remote Sensing 177 (July): 204–16. https://doi.org/10.1016/j.isprsjprs.2021.05.003."
  },
  {
    "objectID": "WEEK2.html",
    "href": "WEEK2.html",
    "title": "WEEK 2",
    "section": "",
    "text": "Homework: Introduction to Hyperspectral Radiometer\nThis week I learnt how to use Quarto to create websites and Xaringan to create presentations. This website and this slide can be used as a presentation of what I learnt the content of this week."
  },
  {
    "objectID": "WEEK3.html",
    "href": "WEEK3.html",
    "title": "WEEK 3",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 3, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK3.html#summary-lecture",
    "href": "WEEK3.html#summary-lecture",
    "title": "WEEK 3",
    "section": "1 Summary: lecture",
    "text": "1 Summary: lecture\nThis week focuses on the pre-processing of remote sensing data, including the correction, joining and enhancement of various types of remote sensing data.\n\n\n\nMindmap of Week 3 Leacture\n\n\n\n\n1.1 Pre-knowledge\n\nDifferent sensors\n\nMSS (Multispectral Scanner)\nRBV (Return Beam Vidicon Camera)\n\n\n\nPush broom vs Whisk broom\n\nWhisk broom or spotlight or across track scanners: Mirror reflects light onto 1 detector - Landsat\nPush broom or along track scanners: several detectors that are pushed along - SPOT, Quickbird\n\n\n\n\n1.2 Corrections\n\nRegression\n\\[\ny_i=\\beta_0+\\beta_1x_i+\\varepsilon_i\n\\]\n\nβ0 is the intercept (the value of y when x = 0)\nβ1 the ‘slope’ the change in the value of y for a 1 unit change in the value of x\nϵi is a random error term (positive or negative)- if you add all of the vertical differences between the blue line and all of the residuals, it should sum to 0\nAny value of y along the blue line can be modeled using the corresponding value of x\n\n\n\nGeometric correction\nWhat leads to image distortions\n\nView angle (off-nadir)\nTopography (e.g. hills not flat ground)\nWind (if from a plane)\nRotation of the earth (from satellite)\n\nGeometric correction solution\n\n\n\nGeometric correction. Source: Abdul Basith\n\n\n\nIdentify Ground Control Points (GPS) to match known points in the image and a reference dataset\nTake the coordinates and model them to give geometric transformation coefficients, linear regression with our distorted x or y as the dependent or independent\n\nInput to output (forward mapping): the issue with this is that we are modelling the rectified x and y which could fall anywhere on the gold standard map (e.g. not on a grid square or at a floating point)\nOutput to input (backward mapping): for every value in the output (gold standard) pixel we can get a value in the original input image. The images are distorted as so might not completely overlap. The goal is to match the distorted image with the gold standard image, so we want the pixels to line up\n\nPlot these and try to minimise the RMSE - Jensen sets a RMSE value of 0.5, typically might add more GCPs to reduce the RMSE (The model with the lowest RMSE will fit best)\n\nRMSE: (observed - predicted (the residual))^2, sum them and divide by number of data points, square root that total\nResample methods: Nearest Neighbor, Linear, Cubic, Cubic spline\n\n\n\n\nAtmospheric correction\nNecessary and unnecessary atmospheric correction\n\nNecessary\n\nBiophysical parameters needed (e.g. temperature, leaf area index, NDVI)\nUsing spectral signatures through time and space\n\nUnnecessary\n\nClassification of a single image\nIndependent classification of multi date imagery\nComposite images (combining images)\nSingle dates or where training data extracted from all data\n\n\nAtmospheric correction in action\n\n\n\nAtmospheric correction examples of three scenes (Bands 1, 2, and 3). Source: Liang et al. 2001\n\n\n\nAbsorption and scattering create the haze = reduces contrast of image\nScattering = can create the “adjacency effect”, radiance from pixels nearby mixed into pixel of interest\n\nAtmospheric correction types\n\nRelative (to something)\n\nNormalize\n\nNormalize intensities of different bands within a single image\nNormalise intensities of bands from many dates to one date\n\nDark object subtraction (DOS) or histogram adjustment\n\nSearches each band for the darkest value then subtracts that from each pixel\nLandsat bands 1-3 (visible) have increased scattering vs longer wavelengths\n\nPsuedo-invariant Features (PIFs)\n\nAssume brightness pixels linearly related to a base image\nRegression per band\nAdjust the image based on the regression result\nHere y is the value of our base. To get y we multiply our new date pixel (x) by the coefficient and add the intercept value\nApply this to the rest of the pixels\n\n\nAbsolute (definitive)\n\nMethod\n\nChange digital brightness values into scaled surface reflectance. We can then compare these scaled surface reflectance values across the planet\nWe do this through atmospheric radiative transfer models and there are many to select from\nHowever, nearly all assume atmospheric measurements are available which are used to “invert” the image radiance to scaled surface reflectance\nThe scattering and absorption information comes from atmopshierc radiative transfer code such as MODTRAN 4+ and the Second Simulation of the Satellite Signal in the Solar Spectrum (6S), which can now be used through python - called Py6S\n\nAbsolute Data requirements\n\nAn atmopsheric model (summer, tropical): usually you can select from the tool\nLocal atmopsheric visibility: from a weather station, like airports\nImage altitude\n\nAbsolute Tools\n\nACORN: Atmopsehic CORection Now\nFLAASH: Fast Line of-sight Atmopsheric Analysis\nQUAC: Quick Atmopsheric Correction\nATCOR: The ATmospheric CORrection program\nSMAC: Simplified Model for Atmospheric Correction (SMAC)\n\n\nEmpirical Line Correction\n\nWe can go and take measurements in situ using a field spectrometer, this does require measurements at the same time as the satellite overpass\nThen use these measurements in linear regression against the satellite data raw digital number\n\n\n\n\nOrthorectification / Topographic correction\n\n\n\nA view captured from an oblique angle (for example, 25°, left) must be corrected for relief displacement caused by terrain to generate the orthorectified view (looking straight down, right). Orthoimagery is produced by calculating the nadir view for every pixel. Source: Esri Insider, 2016\n\n\nA subset of georectification\n\nGeorectification = giving coordinates to an image\nOrthorectification = removing distortions… making the pixels viewed at nadir (straight down)\n\nRequires\n\nSensor geometry\nAn elevation model\n\nSoftware / formulas to do this\n\nJensen covers the following formulas: Cosine correction, Minnaert correction, Statistical Empirical correction, C Correction (advancing the Cosine)\nSoftware: QGIS, SAGA GIS, R package topocorr, R package RStoolbox\n\nSolar location\n\nSolar azimuth = compass angle of the sun (N =0°) 90° (E) at sunrise and 270° (W) at sunset\nSolar zenith = angle of local zenith (above the point on ground) and sun from vertical (90° - elevation)\n\n\n\nRadiometric calibration\n\nSensors capture image brightness and distributed as a Digital Number (or DN) - allows for efficient storage but has no units\nSpectral radiance is the amount of light within a band from a sensor in the field of view (FOV), it is independent of the sensor, measured in Watts (power or light here)\nDN to spectral radiance = radiometric calibration\nSensor calibration = the relationship between Gain and Bias are usually provided but we can calcaulte them\n\n\n\n\n\n\n\nTerms\n\n\n\n\nRadiance: refers to any radiation leaving the Earth (i.e. upwelling, toward the sensor\n\nMight also be called Top of Atmosphere (TOA) radiance\nHow much light the instrument sees in meaningful units but still have effects of: Light source, atmosphere and surface material\nWe can remove the effects of the light source to generate Top of Atmosphere reflectance but usually this is combined within the radiance to reflectance step\n\nIrradiance: is used to describe downwelling radiation reaching the Earth from the sun\nDigital number (DN)\n\nIntensity of the electromagnetic radiation per pixel\nPixel values that aren’t calibrated and have no unit\nHave light source\nEffects of sensor + atmosphere + material\nValues range from 0 - 255 (Lansat 5) = 8 bit or 0 - 65536 Landsat 8 (12 bit)\n\nReflectance: We need to account for atmospheric and illumination effects to create reflectance. BUT this typically doesn’t deal with shadows and directional effects (e.g. viewing angles) = apparent reflectance However, this is often called reflectance\n\nReflectance is a property of a material (e.g. reflectance of grass is a property of grass)\nThe issue with radiance is that is contains physical properties AND is dependent on the light source\n\nHemispherical reflectance: all of the light leaving the surface goes straight to the sensor (nothing is intercepted or at an angle)\nPath radiance: radiance reflected above the surface (e.g. scattering)\nAtmospheric attenuation: absorption of EMR due to materials in atmosphere (e.g. water vapour)\nLocal: specific to pixel\n`Neighbourhood: pixels within a range (nearby)\n\n\n\n\n\n\n1.3 Data joining and enhancement\n\nJoining data sets\n\nThis is termed “Mosaicking” in remote sensing - but it’s not much different to merging in GIS\nIn Remote Sensing we usually feather the images together\nThis creates a seamless mosaic or image(s)\nThe dividing line is termed the seamline\nWe have a base image and “other” or second image\n\n\n\nHow to join data sets\n\nStandardization (dividing the SR value by a maximum value per band) and normalization (divide the standarised value by the sum of values across all bands) applied to each image\nUndertake further relative radiometric normalization\nClassify each image alone\nCalculate other metrics from the image\n\n\n\nImage enhancement\nContrast enhancement\n\n\n\nContrast enhancement in QGIS. Source: Atilo Francois\n\n\n\nMinimum - Maximum\nPercentage Linear and Standard Deviation\nPiecewise Linear Contrast Stretch\n\nRatio\n\nBand ratioing means dividing the pixels in one band by the corresponding pixels in a second band.\nExample: Normalized Burn Ratio = (NIR - SWIR) / (NIR + SWIR)\n\nIn Landsat 4-7, NBR = (Band 4 – Band 7) / (Band 4 + Band 7)\nIn Landsat 8-9, NBR = (Band 5 – Band 7) / (Band 5 + Band 7)\n\n\nFiltering\n\nLow pass or low frequency (averages the surrounding pixels)\nHigh pass or high frequency - enhance local variations\nEdge enhancement\n\nPCA (Principal Component)\n\nTransform multi-spectral data into uncorrelated and smaller dataset\nHas most of the original information\nReduces future computation “dimensionatliy reduction”\nThe first component will capture most of the variance within the dataset\nIn R this is from the RStoolbox packagerasterPCA()\nPCA example, multi-date PCA - bands from both time points are combined into one image, then PCA\n\nTexture\n\nImages just use tonal (spectral) data not texture\nTexture: spatial variation of gray values\nFirst order (occurrence): use counts or occurrences\nSecond order(co-occurrence): relationship between pixel pairs “a function of both the angular relationship and distance between two (or kernel) neighboring pixels”\n\nFusion\nImage fusion is where data from multiple sensors / sources is fused together\n\nPan sharpen\nData Fusion"
  },
  {
    "objectID": "WEEK3.html#summary-practical",
    "href": "WEEK3.html#summary-practical",
    "title": "WEEK 3",
    "section": "2 Summary: practical",
    "text": "2 Summary: practical\n\nThis week’s practical will consist mainly of the following:\n\nIntroduction and access to Landsat data\nA deeper understanding of atmospheric correction and how it works in practice\nIntroduction to the principles of Radiance (or DN) to Reflectance\nPractical exercises in image joining\nA deep understanding of image enhancement and how it works in practice\n\n\nFor this week’s practical I chose to follow the guidance using Landsat data from Cape Town. I used R to do atmospheric corrections, merging, data enhancement and other operations on the data. Through practical, I gained a better understanding of remote sensing data pre-processing and was able to apply this to my workflow in R. Combined with the previous term’s CASA0005 course, I can now use R to analyse more types of data.\n\n\n\nPractical output: texture of landsat data from Cape Town"
  },
  {
    "objectID": "WEEK3.html#application",
    "href": "WEEK3.html#application",
    "title": "WEEK 3",
    "section": "3 Application",
    "text": "3 Application\n\nThis week, the main focus was on the correction, joining and enhancement of remote sensing images, mostly applied to pre-processing before analysis, but remote sensing image enhancement has a wider range of applications.\n\n\n3.1 Applications of remote sensing image enhancement\nRemote sensing image enhancement refers to the improvement of the quality and information of remote sensing images through some technical means to make them more suitable for human vision or subsequent analytical processing. Remote sensing image enhancement can be applied to the following areas:\nContrast enhancement: By adjusting the grey level of a remotely sensing image, the contrast of the image is increased to make it clearer and brighter. Contrast enhancement can be done using methods such as histogram stretching, histogram equalisation and segmented linear stretching.\nBand ratioing: Extracts specific information from remote sensing images, such as vegetation indices, water indices, soil indices, etc., by calculating the ratio between different bands. Band ratios can be calculated using methods such as band arithmetic and band combination.\nFiltering: Remove noise or enhance edges and textures in an image by convolving the remote sensing image in the spatial or frequency domain. Filtering can use methods such as smoothing filtering, sharpening filtering and edge detection filtering.\nPrincipal component analysis (PCA): By applying orthogonal transformations to multiple bands of remote sensing images, the main information in the image is extracted and the redundancy and correlation of the data is reduced. Principal component analysis can use statistical methods or methods such as wavelet transform.\nTexture: Describes the surface roughness or structural features in an image by calculating the grey scale variation within a region of the remotely sensed image. Texturing can use methods such as grey level co-occurrence matrix, grey level distance matrix, grey level gradient matrix, etc.\nFusion: Increasing the spatial or spectral resolution of an image and increasing the amount of information in the image by combining remote sensing images from different sources or at different resolutions. Fusion can be done using methods such as HIS transform, wavelet transform, multi-resolution analysis, etc.\n\n\n3.2 Application case\n\n\n\n\n\n\nSourse\n\n\n\nPCA‐based land‐use change detection and analysis using multitemporal and multisensor satellite data , Sourse: Deng et al. (2008)\n\n\nRemote‐sensing change detection based on multitemporal, multispectral, and multisensor imagery has been developed over several decades and provided timely and comprehensive information for planning and decision‐making. In practice, however, it is still difficult to select a suitable change‐detection method, especially in urban areas, because of the impacts of complex factors.\nThis paper presents a new method using multitemporal and multisensor data (SPOT‐5 and Landsat data) to detect land‐use changes in an urban environment based on principal‐component analysis (PCA) and hybrid classification methods. After geometric correction and radiometric normalization, PCA was used to enhance the change information from stacked multisensor data. Then, a hybrid classifier combining unsupervised and supervised classification was performed to identify and quantify land‐use changes. Finally, stratified random and user‐defined plots sampling methods were synthetically used to obtain total 966 reference points for accuracy assessment.\n\n\n\nExample of land‐use changes from cropland to urban land (Economic and Technological Development Zone). (a) Pan image of ETM (2000); (b) aerial photograph (2000); (c) RGB composition image of SPOT‐5 (2003); (d) RGB composition image of IKONOS (2003); (e)–(h) first four principal components.\n\n\nAlthough errors and confusion exist, this method shows satisfying results with an overall accuracy to be 89.54% and 0.88 for the kappa coefficient. When compared with the post‐classification method, PCA‐based change detection also showed a better accuracy in terms of overall, producer’s, and user’s accuracy and kappa index. The results suggested that significant land‐use changes have occurred in Hangzhou City from 2000 to 2003, which may be related to rapid economy development and urban expansion. It is further indicated that most changes occurred in cropland areas due to urban encroachment.\n\n\n\nLand use and land‐use change detected using the PCA‐based approach.\n\n\n\n\n3.3 Case comments\nAdvantages or contribution\n\nFlexible classification strategies: The hybrid classification approach allows the authors to combine the accuracy of supervised classification methods while taking advantage of the automation of unsupervised classification methods. This flexibility allows the method to be better adapted to different types of land use change scenarios.\nPCA-based feature extraction: By combining multi-temporal and multi-sensor data into a single Principal Component Analysis (PCA) model, the authors are able to extract more meaningful features that help distinguish between changing and non-changing areas. This approach has advantages in dealing with high-dimensional data and reducing data redundancy.\nCorrection and radiation normalisation: This paper corrected and radiation normalised the data prior to analysis, which helped to reduce errors due to sensor differences, variations in atmospheric conditions and land cover type, thus improving the accuracy and reliability of the results.\n\nDisadvantages or potential\n\nLimitations of Principal Component Analysis (PCA): While PCA is able to extract and enhance variation information from multi-sensor data, it may not be able to completely eliminate noise and other non-target factors. In addition, PCA may have limitations in handling non-linear data, which may lead to inaccurate detection results.\nLimitations of sensor data: SPOT-5 and Landsat data were used in this paper. While these data sources are of value in land cover change detection, they may not capture the detailed information that finer spatial resolution and higher spectral resolution can provide. In addition, these data sources may be affected by issues such as cloud occlusion, atmospheric interference and timing inconsistencies."
  },
  {
    "objectID": "WEEK3.html#reflection",
    "href": "WEEK3.html#reflection",
    "title": "WEEK 3",
    "section": "4 Reflection",
    "text": "4 Reflection\nThis week I learnt the principles and methods of correcting, joining and enhancing remotely sensed images and understood how to pre-process remotely sensed data. Although most of the data we acquired had already been pre-processed, this knowledge gave me a better understanding of how to apply remote sensing images to the actual analysis and what could cause errors and whether further processing was needed. In addition, the study of remote sensing image enhancement has taught me more about remote sensing data analysis methods and principles in a deeper way.\nHowever, not all data pre-processing can be perfectly accurate, errors are allowed but need to be controlled according to the actual situation. Also, in practice, some R packages are no longer available due to version updates. This is a common problem in data analysis and can be solved by downloading a lower version of the package or replacing it.\n\n\n\n\nDeng, J. S., K. Wang, Y. H. Deng, and G. J. Qi. 2008. “PCA‐based Land‐use Change Detection and Analysis Using Multitemporal and Multisensor Satellite Data.” International Journal of Remote Sensing 29 (16): 4823–38. https://doi.org/10.1080/01431160801950162."
  },
  {
    "objectID": "WEEK4.html",
    "href": "WEEK4.html",
    "title": "WEEK 4",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 4, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK4.html#summary-lecture",
    "href": "WEEK4.html#summary-lecture",
    "title": "WEEK 4",
    "section": "1 Summary: lecture",
    "text": "1 Summary: lecture\nThis week focuses on the scenarios and application methods of various types of remote sensing data, as well as policy documents related to remote sensing at various levels.\n\n\nMindmap of Week 4 Leacture\n\n\n\n1.1 Using data from sensors\n\n\n\n\n\n\nExample\n\n\n\nMulti-temporal land cover mapping, Spectral signatures / libraries, Change detection, Vegetation stress, Precipitation, Elevation models, Temperature, Night time lights, Forest fire monitoring, Pollution monitoring, Drought indices, Informal housing detection, Water level data monitoring, Building or network outlineextraction, Environmental monitoring, Estimations of resources, Air pollution and LULC, Urban green space, Disaster response and preparedness, Droughts monitoring, Forest fires analysis\n\n\n1.2 Synthetic Aperture Radar (SAR)\nSAR background\n\n\nWhat is Synthetic Aperture Radar?. Source:NASA Earth Data\n\n\n\nActive sensors\nHave surface texture data\nSee through weather and clouds\nDifferent wavelengths - different applications\nDifferent ploarizations\nSAR polarization\nPolarization refers to the orientation of the plane in which the transmitted electromagnetic wave oscillates. While the orientation can occur at any angle, SAR sensors typically transmit linearly polarized. The horizontal polarization is indicated by the letter H, and the vertical polarization is indicated by V\n\n\nSingle = 1 horizontal (or vertical)\n\nDual = transmits and receives both horizontal and vertical\n\nHH = emitted in horizontal (H) and received in horizontal (H)\n\nDifferent surfaces respond differently to the polarizations\n\n\nRough scattering (e.g. bare earth) = most sensitive to VV\n\nVolume scattering (e.g. leaves) = cross, VH or HV\n\nDouble bounce (e.g. trees / buildings) = most sensitive to HH\n\nScattering can change based on wavelength, further penetration then the volume scattering will change\nAmplitude (backscatter) and phase\nA SAR signal has both amplitude (backscatter) and phase data\n\n\n\n\n\n\nTerms\n\n\n\n\nBackscatter is the portion of the outgoing radar signal that the target redirects directly back towards the radar antenna\nThe higher the backscattered intensity = rougher the surface. It is \"unitless\"\n\nCan be converted to “backscatter coefficient, or sigma nought”, measured in decibel (dB) units = normalised measure of the radar return from a distributed target\nIf the signal is from backscatter is not desired = \"clutter\"\n\n\n\n\nBackscatter (amplitude)\n\nPolarization\n\n\nVV = surface roughness\n\nVH = volume of surface (e.g. vegetation has a complex volume and can change the polarization)\n\n\nPermativity (dielectric constant) - how reflective is the property which means reflective back to the sensor. Water usually reflects it off elsewhere\nThe return value, also remember the band (wavelength)\nWind makes the water move and reflect back to the sensor (under VV)\n\nPhase\n\nLocation of wave on the cycle when it comes back to the sensor\nSAR floods\nSensor: Sentinel-1 SAR\n\n\nEl Niño–Southern Oscillation (ENSO) phases but this is from Australian La Niña 2022\n\nTrade winds from south america intensity\nDraw up cool deep waters and increase thermocline\nTemp difference increases, walker circulation intensifies - feedback loop\nMore cloud + more rain + cyclones in West Pacific\n\n\nInterferometry Synthetic Aperture Radar (InSAR)\n\nTake two RADAR observations of the target (e.g. the ground)\nUse the phase difference\n\n\nPhase: “total number of cycles of the wave at any given distance from the transmitter, including the fractional part”\n\nPhase difference: SUBTRACT the values (measured phase values) at two different measurement points\nDifferential distance depends on the height of the terrain (topography)\n\n\nUsed for creating DEMs\n\nMonitoring displacement of ground - earthquakes etc\n\n\n\n\n\n\n\nTerms\n\n\n\n\n\nCoherence Map: Coherence is defined as the degree of similarity of backscattering response (or reflection characteristic of as measured by the SAR sensor) between corresponding ground cells in both SAR image of an InSAR pair. Something is coherent when they are in phase (vibrate in unison)\n\nDifferential Interferometry Synthetic Aperture Radar (DInSAR): “quantification of the ground displacement that occurred between the two acquisitions can be achieved” through a “differential interferogram”\n\n\n\nSAR image\n\n\nUrban objects detection from C-band synthetic aperture radar (SAR) satellite images through simulating filter properties. Source:Deepak Kumar, 2021\n\n\nSAR applications\nDamage detection, Urban area mapping, Urban flooding (lower backscatter coefficient), Landslides, Earthquakes, Data fusion / DEM creation\n1.3 Monitoring forests + illegal logging\n\n\n\n\n\n\nSourse\n\n\n\nHigh-Resolution Global Maps of 21st-Century Forest Cover Change , Sourse: Hansen et al. (2013)\n\n\nSensor: Landsat (2000 to 2012)\nPre-processing\nLandsat pre-processing steps\n\nImage resampling\nConversion of raw digital values (DN) to top of atmosphere (TOA) reflectance\nCloud/shadow/water screening and quality assessment (QA)\n\nImage normalization\n\nThe stack of QA layers was used to create a perpixel set of cloud-free image observations which in turn was employed to calculate timeseries spectral metrics\nCreating metrics\nMetrics represent a generic feature space that facilitates regionalscale mapping and have been used extensively with MODIS and AVHRR data\nHow to create metrics\n\n\nReflectance values representing maximum, minimum and selected percentile values\nMean reflectance values for observations between selected percentiles\nSlope of linear regression of band reflectance value versus image date\n\nThe time-sequential MODIS 32-dayinputs were transformed to annual metrics to produce a more generalized feature space\n\n\n\n\n\n\n\n“a more generalized feature space”\n\n\n\n\n\nFeature space = scattergram of two bands (or things that have been made into bands)\nCan be used for very basic classification - selecting the values that represent land cover\n\n\n\nTraining data (in supervised machine learning)\nTraining data to relate to the Landsat metrics were derived from image interpretation methods, including mapping of crown/no crown categories using very high spatial resolution data such as Quickbird imagery, existing percent tree cover layers derived from Landsat data, and global MODIS percent tree cover, rescaled using the higher spatial resolution percent tree cover data sets\nClassification (supervised or unsupervised)\nDecision trees are hierarchical classifiers (top down) that predict class membership by recursively partitioning (splitting) a data set into more homogeneous or less varying subsets, referred to as nodes\n\n\nA random forest classifier is a collection of decision trees\nTake something complex and force into many decisions = if-else conditions or also called divide and conquer\nOften requires hyperparameters to train the model (or control the learning process)\n\n\nDBSCAN (radius of points, Epsilon or MinPts - to make a cluster)\n\nSpatial weight matrix (type and then weight)\n\n\nSplit the data into more and more homogeneous subsets (filtering!) this can be limited through\n\n\npre-pruning - set a number of iterations before\n\npost-pruning - reduce groups afterwards based on accuracy. Tree fully grows but will be overfit. (In post-pruning first, it goes deeper and deeper in the tree to build a complete tree. If the tree shows the overfitting problem then pruning is done as a post-pruning step. We use a cross-validation data to check the effect of our pruning. Using cross-validation data, it tests whether expanding a node will make an improvement or not. If it shows an improvement, then we can continue by expanding that node. But if it shows a reduction in accuracy then it should not be expanded i.e, the node should be converted to a leaf node.)\n\n\n\n\n\nREMAP method. Source:UN-SPIDER\n\n\n1.4 Integrating analysis\n\n\nExample of integrating analysis. Source: MacLachlan et al. 2021\n\n\n1.5 Global policy documents\nNew Urban Agenda\nStandards and principles for planning, construction, development, management and urban improvement (Environmentally sustainable and resilient urban development subsection)\npoint 64: We also recognize that urban centres worldwide, especially in developing countries, often have characteristics that make them and their inhabitants especially vulnerable to the adverse impacts of climate change and other natural and human-made hazards, including earthquakes, extreme weather events, flooding, subsidence, storms, including dust and sand storms, heatwaves, water scarcity, droughts, water and air pollution, vector-borne diseases and sea level rise, which particularly affect coastal areas, delta regions and small island developing States, among others\npoint 65: We commit ourselves to facilitating the sustainable management of natural resources in cities and human settlements in a manner that protects and improves the urban ecosystem and environmental services, reduces greenhouse gas emissions and air pollution and promotes disaster risk reduction and management, by supporting the development of disaster risk reduction strategies and periodical assessments of disaster risk caused by natural and human-made hazards, including standards for risk levels\npoint 67: We commit ourselves to promoting the creation and maintenance of well-connected and well distributed networks of open, multipurpose, safe, inclusive, accessible, green and quality public spaces, to improving the resilience of cities to disasters and climate change, including floods, drought risks and heat waves to improving food security and nutrition, physical and mental health, and household and ambient air quality, to reducing noise and promoting attractive and liveable cities, human settlements and urban landscapes and to prioritizing the conservation of endemic species\nSustainable Development Goals (SDG): targets with measurable indicators for monitoring\nGoal 11: Make cities and human settlements inclusive, safe, resilient and sustainable\nTarget 11.5: By 2030, significantly reduce the number of deaths and the number of people affected and substantially decrease the direct economic losses relative to global gross domestic product caused by disasters, including water-related disasters, with a focus on protecting the poor and people in vulnerable situations\n\nMonitoring 11.5\n\n11.5.1 Number of deaths, missing persons and directly affected persons attributed to disasters per 100,000 population\n11.5.2 Direct economic loss attributed to disasters in relation to global gross domestic product (GDP)\n11.5.3 (a) Damage to critical infrastructure and (b) number of disruptions to basic services, attributed to disasters\n\n\nData 11.5\n\n11.5.1 (and .2) Data provider at national level is appointed Sendai Framework Focal Points. In most countries disaster data are collected by line ministries and national disaster loss databases are established and managed by special purpose agencies including national disaster management agencies, civil protection agencies, and meteorological agencies. The Sendai Framework Focal Points in each country are responsible of data reporting through the Sendai Framework Monitoring System.\n11.5.3 National disaster loss database, reported to UNISDR…Not every country has a comparable national disaster loss database that is consistent with these guidelines (although current coverage exceeds 89 countries). Therefore, by 2020, it is expected that all countries will build/adjust national disaster loss databases according to the recommendations and guidelines by the OEIWG\n\n\n\nTarget 11.6: By 2030, reduce the adverse per capita environmental impact of cities, including by paying special attention to air quality and municipal and other waste management\n\nIndicator 11.6.2: Annual mean levels of fine particulate matter (e.g. PM2.5 and PM10) in cities (population weighted)\n\nTarget 11.7: By 2030, provide universal access to safe, inclusive and accessible, green and public spaces, in particular for women and children, older persons and persons with disabilities\n\nIndicator 11.7.1: Average share of the built-up area of cities that is open space for public use for all, by sex, age and persons with disabilities\n1.6 Metropolitan policy documents\nLondon\n\nIncreasing efficiency and resilience: These environmental threats are real and present, and London must be prepared for them. London’s homes and infrastructure must be protected against the increasing likelihood of heatwaves, and developments must plan for a more integrated approach to water management, while minimising flood risk\nPolicy SI 12 Flood risk management: Development Plans should use the Mayor’s Regional Flood Risk Appraisal and their Strategic Flood Risk Assessment as well as Local Flood Risk Management Strategies, where necessary, to identify areas where particular and cumulative flood risk issues exist and develop actions and policy approaches aimed at reducing these risks\nOneNYC 2050\n\nReferences the sustainable development goals\nHas a hazards matrix\nCape Town: Cape Town Municipal Spatial Development Framework\n\n2015-2018 “worst recorded drought in the city’s history, is a stark reminder that all cities will need to become more robust, resilient and efficient”\n“The Cape Town Spatial Development Framework (CTSDF) was approved in May 2012 and established a long-term spatial vision and policy framework for the City after extensive technical drafting and public participation.”\n“Careful management of development to avoid developing in high flood risk areas”\nAhmedabad: 2016 Heat Action Plan\n\nAwareness and outreach\nEarly warning system\nCapacity of health care professionals\nReduce heat exposure and promote adaptive mesaures …and mapping high risk areas, although mapping was removed later in the document (page 11)\n1.7 Local policy documents\nIn most of the previous examples the documents were created by the metropolitan government, they set the strategic plan for the city and may have other responsibilities such as fire, policing, transport and development guidelines. Lower tier government then carries out or adheres to these goals, but there are variations to this rule\nCity of Cape Town\n\nThe City of Cape Town is a metropolitan municipality or Category A municipality, there is no local municipality below it\nHowever, above the City of Cape Town is the Provincial government that is responsible for topics such as: agriculture, education, health and public housing. As such the City sets it’s own development plan and then implements it (whilst adhering to relevant Provincial topics)\nNew York\n\nCity of New York is responsible for public education, correctional institutions, public safety, recreational facilities, sanitation, water supply, and welfare services\n5 Boroughs under it act as spokespeople\nCity Council has 51 members from districts of about 157,000\nNew York City is responsible for setting and enacting the policy. State government is above it"
  },
  {
    "objectID": "WEEK4.html#summary-practical",
    "href": "WEEK4.html#summary-practical",
    "title": "WEEK 4",
    "section": "2 Summary: practical",
    "text": "2 Summary: practical\n\nThe summary of the policy and city I have selected.\n\n\n\n\n\n\n\nbackground\n\n\n\nIstanbul, the largest city in Turkey and connecting Europe and Asia, is scaling up its urban regeneration by joining the European Bank for Reconstruction and Development’s flagship EBRD Green Cities urban sustainability programme. Source: EBRD\n\n\n2.1 City\nIstanbul\nIstanbul, formerly known as Constantinople, is the largest city in Turkey, serving as the country’s economic, cultural and historic hub. The city straddles the Bosporus strait, lying in both Europe and Asia, and has a population of over 15 million residents, comprising 19% of the population of Turkey. Istanbul is the most populous European city, and the world’s 15th-largest city.\n\n\nİstanbul view\n\n\n\n\nİstanbul at a glance. Source: Governership of Istanbul\n\n\nEnvironment challange\nIstanbul are faces many environmental problems.\n\n\nUrban expansion and land use change: Istanbul has experienced rapid urbanisation in recent years, resulting in the expansion of the city and the replacement of green spaces and ecologically sensitive areas with built-up land. This land use change has had a negative impact on the urban ecosystem, such as a decline in biodiversity and destruction of natural habitats.\n\nAir pollution: Istanbul has a growing air quality problem, mainly caused by traffic emissions, industrial emissions and fossil fuel combustion.\n\nWater management: Water management issues in Istanbul include water scarcity, water quality pollution and deterioration of the water environment. With the growth of the city’s population and industrial development, the conflict between water supply and demand has increased and the pressure on the water environment to carry water has increased.\n\nUrban heat island effect: With the accelerated urbanisation, the density of buildings and roads in Istanbul is increasing, leading to a more pronounced urban heat island effect.\n\nTherefore, the implementation of a green city plan is urgent.\n2.2 Policy\nEBRD Green Cities\nTo address environmental challenges, the EBRD developed EBRD Green Cities, with the aim of building a better and more sustainable future for cities and their residents. The programme has three central components:\n\nGreen City Action Plans (GCAPs): Assessing and prioritising environmental challenges, and developing an action plan to tackle these challenges through policy interventions and sustainable infrastructure investments.\nSustainable infrastructure investment: Facilitating and stimulating public or private green investments in: water and wastewater, urban transport, district energy, energy efficiency in buildings, solid waste and other interventions that improve the city’s adaptation and resilience to climate shocks.\nCapacity-building: Providing technical support to city administrators and local stakeholders to ensure that infrastructure investments and policy measures identified in GCAPs can be developed, implemented and monitored effectively.\n\nEBRD Green city aims to:\n\nPreserve the quality of environmental assets (air, water, land and biodiversity) and use these resources sustainably.\nMitigate and adapt to the risks of climate change.\nEnsure that environmental policies and developments contribute to the social and economic well-being of residents.\n\nThe path to becoming a Green City is continuous, allowing cities to adjust their strategic goals and visions over time. The process has three key stages:\n\nDeveloping a Green City Action Plan (GCAP)\n\nIdentifying and prioritising challenges\nPlanning actions\n\n\nImplementing the GCAP\nMonitoring THE GCAP"
  },
  {
    "objectID": "WEEK4.html#application",
    "href": "WEEK4.html#application",
    "title": "WEEK 4",
    "section": "3 Application",
    "text": "3 Application\n\nHow the remotely sensed data you sourced could be used to assist with contributing to the policy goal. How could the data be applied to solve the policy challenge.\n\nAccording to EBRD Green city，The first step in developing a GCAP involves assessing the city’s environmental performance using 35 core indicators that cover a wide range of urban issues. The indicators evaluate the state of the city’s environmental assets, its overall resource efficiency and climate change risks. Therefore, the remote sensing data could be applied to evaluate and monitor the city’s environmental performance.\nDue to the large number of indicators, we are unable to discuss them all here, so we are analysing the environmental issues that stand out in Istanbul.\n\n\nUrban expansion and land use change: By classifying and detecting land cover changes from remote sensing imagery over multiple time periods, the rate of urban expansion, land use changes and ecological impacts in Istanbul can be assessed. Land use type classification using Landsat or Sentinel-2 satellite data combined with classification algorithms (e.g. support vector machines, random forests, etc.).\n\nAir pollution: Use remote sensing data to monitor concentrations of atmospheric pollutants (e.g. nitrogen oxides, particulate matter, etc.) and to assess the air quality status of Istanbul. Air pollutant concentrations are monitored using satellite data such as MODIS and Sentinel-5P, combined with air pollutant inversion methods.\n\nWater management: The extraction of hydrological parameters from remote sensing data, such as the area of water bodies, suspended sediment concentrations and chlorophyll a concentrations, allows the assessment of water resource status and water pollution in Istanbul. In addition, synthetic Aperture Radar (SAR) data can be used to detect water environment problems such as oil pollution on water surfaces.\n\nUrban heat island effect: Remote sensing data is used to calculate surface temperatures and to analyse the distribution and influencing factors of the urban heat island effect. Landsat and MODIS data are used in conjunction with surface temperature inversion methods to assess the urban heat island effect in Istanbul.\n\n\n\nland surface temperature (LST) distribution (a) and map of the Surface Urban Heat Island (SUHI) effect (b) on 25th July 2017 in Istanbul. LST anomalies above the average (34.73 °C) indicate the SUHI effect at various levels. Source: Erdem Okumus and Terzi (2021)"
  },
  {
    "objectID": "WEEK4.html#reflection",
    "href": "WEEK4.html#reflection",
    "title": "WEEK 4",
    "section": "4 Reflection",
    "text": "4 Reflection\n\nWhat I have learnt in relation to the policy, city and the application of the data.\n\nThrough this week’s study, I learnt about the scenarios and application methods of remote sensing images, as well as many different levels of policies related to remote sensing. In the process of learning, I gradually found out the role that remote sensing imagery can play in urban policy: assessment and monitoring. Remote sensing images can provide a wealth of information to assist in decision making, but on the other hand they also need to be responsive to policy in order to create value. As the EBRD Green city also provides over 50 policy tools to help promote and implement policy. It is only when the application of remote sensing data is closely aligned with urban policy that the information can be used to maximum effect.\nIn the field of urban planning, remote sensing data is even more closely integrated with policies, for example, [the evaluation of the carrying capacity of resources and environment and the suitability of territorial spatial development] launched in China in recent years, which is guided by policies, using various types of data including remote sensing data to evaluate the development of territorial space. Meanwhile, the results obtained from remote sensing data often rely on policy tools such as urban planning for implementation.\n\n\n\n\nErdem Okumus, Deniz, and Fatih Terzi. 2021. “Evaluating the Role of Urban Fabric on Surface Urban Heat Island: The Case of Istanbul.” Sustainable Cities and Society 73 (October): 103128. https://doi.org/10.1016/j.scs.2021.103128.\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A. Tyukavina, D. Thau, et al. 2013. “High-Resolution Global Maps of 21st-Century Forest Cover Change.” Science 342 (6160): 850–53. https://doi.org/10.1126/science.1244693."
  },
  {
    "objectID": "WEEK5.html",
    "href": "WEEK5.html",
    "title": "WEEK 5",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 5, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK5.html#summary-lecture",
    "href": "WEEK5.html#summary-lecture",
    "title": "WEEK 5",
    "section": "1 Summary: lecture",
    "text": "1 Summary: lecture\nThis week’s content is an introduction to the basics of GEE, including its features, functions and application scenarios. It also introduces the use of the basic functions of GEE Javascript in relation to R, such as loading image collections, reducing images, regression, joins and filtering.\n\n\nMindmap of Week 5 Leacture\n\n\n\n1.1 The setup of GEE\nGoogle Earth Engine\n\n\n\n\n\n\n\n\n\n\n\"Geospatial\" processing service\nIt permits geospatial analysis at scale\n\nStores data on servers\nTakes the code and applies it\nCan be used to make queryable online applications\n\n\n\n\n\n\n\n\nGEE terms\n\n\n\n\n\nImage = raster\n\nFeature = vector\n\nImage stack = ImageCollection\n\nFeature stack (lots of polygons) = FeatureColletion\n\n\n\nGEE Javascript\nGEE uses Javascript (Website programming language)\nThere are some similarities to python and R but there are some notable differences\n\nVariables (or objects) as defined with var\nA specific part of code ends with a ;\nObjects are dictionaries in Javascript\nClient vs server side\n\nWithin GEE we have code that runs on the client side (browser)\n\nWe have code that runs on the server side (on the server where data is stored)\nIn GEE we have Earth Engine Objects = starting with , for example, ee\n\nAnything that has ee in front of it is stored on the server\n\nIt has no data in script. Recall in R the data environments, this would be empty\nThey are termed \"proxy objects\": the agency, function, or office of a deputy who acts as a substitute for another\nAny pre-loaded data product will be on the server side\n\n\n\nLooping\n\nWe can’t (or shouldn’t) use a loop for something on the server\nThe loop doesn’t know what is in the ee object\n\nMapping functions\n\nInstead we can create a function and save it into an object (or variable here)\nThen apply it to everything on the server\nSame idea as map() in R from the purrr package\n\nServer side functions\n\nSame as the data\nee.Thing.method()\nSaved function on the sever that can be run without mapping\nLoop vs Map\nLoop\n\nRun some code on each element in an array\nSave it in a new array (or update existing)\n\nMap\n\nCode is applied to each element\nThe conditions are dealt with, no indexing at the end\n\nWhy map in GEE?\n\nOtherwise we might load the complete image collection many, many times when looping\nThe loop doesn’t know what is inside the collection\nMapping lets GEE allocate the the processing to different machines with map. I assume as it knows how many images we have and the function it must apply…With a loop it doesn’t know until the next interation\nScale\n\nImage scale in GEE refers to pixel resolution\n\nIn GEE the scale (resolution) is set by the output not input\n\nWhen doing analysis\n\nGEE aggregates the image to fit a 256x256 grid\n\nEarth Engine selects the pyramid with the closest scale to that of analysis (or specified by it) and resamples as needed\nresampling uses nearest neighbor by default\n\n\nProjections\n\nDo not need to worry about projects in GEE\nGEE converts all data into the Mercator projection (EPSG: 3857) when displayed, specifically: WGS 84 / Pseudo-Mercator – Spherical Mercator, Google Maps, OpenStreetMap, Bing, ArcGIS, ESRI\nThe operations of the proejction are determined by the output\nSetting the projection is allowed, but there is no real reason to do this\n1.2 GEE in action\n\n\nWhat does GEE look like. Source: lecture\n\n\nBuilding blocks of GEE\n\n\nObject classes. Source: GEE\n\n\nObject: vector, raster, feature, string, number\n\nEach of these belongs to a class\n\nEach class has specific GEE functions (or methods) for it\n\nRaster data (lots of images)\n\nThey belong to an image collection (as there are lots of images)\nUsing the specific function (method or \"constructor\") to load and manipulate\n\nGeometries and Features\n\n\nGeometry = point/line/polygon with no attributes\n\nNote we can also have MultiPolygon or MultiGeometry\n\n\n\nFeature = geometry with attributes\n\nFeature collection = several features with attributes\nWhat typical processes can do in GEE?\nGeometry operations (e.g. spatial operations)\n\nJoins\n\nZonal statistics (e.g. average temperature per neighbourhood)\n\nFiltering of images or specific values\n\nMethods\n\nMachine learning\nSupervised and unsupervised classification\n\n\nDeep learning with Tensor Flow\nExploring relationships between variables\n\nApplications/outputs\n\nOnline charts\nScalable geospatial applications with GEE data\nThese let us query the data with a user inteface that then updates the results\nReducing images\nThis is combines the previous two ideas\n\nIn the first instance we load an image collection from a dates and place\nWe want to reduce the collection to the extreme values for each pixel\n\nReducing images by region\n\nOne of the most useful functions we can use here is termed zonal statistics\nIn GEE this is termed reduceRegion()\n\nWhat if we want to use a feature collection (with many polygons), same idea, but with image.reduceRegions()\n\n\nReducing images by neighbourhood\n\nInstead of using a polygon to reduce our collection we can use the image neighbourhood\n\nA window of pixels surrounding a central pixel\nLike a filter or texture measure\nAlthough texture has its own function\n\n\nLinear regression\nThe real benefit of GEE is being able to access all imagery for multiple sensors, what if we wanted to see the change over time in pixel values - linearFit()\n\n\nlinearFit() takes a least squares approach of one variable. 2 bands:\n\nBand 1: dependent variable\nBand 2: independent variable (often time)\n\n\nThis runs of a per pixel basis\nThis is still considered a reducer as we are reducing all of the data to two images\n\n\nOffset - intercept\n\nScale - line of the slope We can use additional variables like we have seen before, including multiple dependent variables…this is termed Multivariate Multiple Linear Regression. This just does the same as OLS for both of the dependent variables, the only difference is with a covariance matrix.\n\n\n\nWe can combine reducers for regression\n\nRegression per pixels (typically with an image collection over several years)\nRegression of all the values within a polygon (taking an image of 1 date, extracting all the pixels and then running regression)\nIn GEE we must add a constant as an independent variable for the intercept (unless it is 0)\nJoins\nJoins in GEE are similar to joins in R\n\nWe can join image collections (e.g. satellite data from January with data from October)\nWe can join feature collections (e.g. different polygons)\n\nTo use joins we have to put them within a filter (ee.Filter)\n\nThe leftField is the index (or attribute) in the primary data\nThe rightField is the secondary data\nWe set the type of join\n\nsimple: primary matches any in secondary\ninverted: retain those in primary that are not in secondary\ninner: shows all matches between collections as a feature collection\n\n\nWe then combine (or join) with join.apply()\n\n\nGEE can also do a spatial join and intersect"
  },
  {
    "objectID": "WEEK5.html#summary-practical",
    "href": "WEEK5.html#summary-practical",
    "title": "WEEK 5",
    "section": "2 Summary: practical",
    "text": "2 Summary: practical\n\nThis week’s practical will consist mainly of the following:\n\nAcquire remote sensing image data using GEE and perform basic operations such as clipping and mosaicing of data\nRemote sensing image pre-processing and band mathing using GEE\nExporting GEE analysis results\nGEE-related applications and data\n\n\nIn this week’s practical, I learnt the basic operations of remote sensing data processing using GEE. I followed the instructions to process and analyse the Landsat remote sensing image data from New Delhi, including texture measures, PCA, band math, etc. However, I was pleasantly surprised to learn about a lot of applications developed using GEE, which were very interesting and greatly broadened my view of remote sensing image applications and made me look forwards to developing applications using GEE.\n\n\nPractical output: PCA analysis of Landsat 8 images in New Delhi."
  },
  {
    "objectID": "WEEK5.html#application",
    "href": "WEEK5.html#application",
    "title": "WEEK 5",
    "section": "3 Application",
    "text": "3 Application\n\nAs mentioned above, there are a wide variety of valuable applications that can be developed using GEE, and I would like to explore the applications that can be developed based on GEE\n\n3.1 Applications developed on the basis of GEE\nGEE provides powerful computing capabilities for processing and analysing geospatial data and can be of great use in a number of areas.\nLand cover change detection: By comparing remotely sensed images from different time periods, land cover changes such as urban expansion, deforestation and wetland degradation can be detected. For example: Google Earth Engine Timelapse.\nForest health monitoring: Using high resolution and multi-temporal remote sensing imagery to analyse forest growth and identify forest health issues such as pests, drought and fire. For example: Global Forest Watch (GFW).\nAgricultural management: Remote sensing imagery is used to analyse crop growth, acreage and yields to provide strong support for agricultural production and food security. For example: Cropland Mapping App.\nWater resources monitoring: Using remote sensing data to analyse the area of water bodies, water quality conditions and changes in water resources, providing a scientific basis for water resources management and protection. For example: Global Surface Water Explorer (GSWE).\nClimate change research: To explore the causes and impacts of climate change by analysing long-term changes in surface temperature, precipitation, snow and ice and other climate factors. For example: Climate Engine.\nDisaster assessment and management: Using remote sensing images to detect natural disasters such as floods, earthquakes and landslides in a timely manner, providing information to support disaster assessment and rescue work. For example: DFO Flood Observatory Web Map Server.\nEcosystem service assessment: Evaluate the value of ecosystem services to humans by analysing ecological indicators such as land cover, vegetation productivity and biodiversity. For example: NDVI slider.\nUrban planning and management: Analyse urban construction land, traffic conditions and green space distribution through remote sensing images to provide decision support for urban planning and management. For example: Urbanization Explorer.\nAir quality monitoring: Using remote sensing data to analyse the concentration and distribution of atmospheric pollutants, providing data support for air quality monitoring and environmental protection. For example: Europe’s Air Quality Winner.\nWildlife protection: analyse wildlife habitats, migration paths and the status of protected areas through remote sensing images to provide scientific basis for wildlife protection. For example: eBird.\n3.2 Application case\n\n\n\n\n\n\nSourse\n\n\n\nGlobal Forest Watch (GFW) , Sourse: GFW\n\n\nAbout GFW\nGlobal Forest Watch (GFW) is an online platform that provides data and tools for monitoring forests. By harnessing cutting-edge technology, GFW allows anyone to access near real-time information about where and how forests are changing around the world.\n\n\n\n\n\n\n\n\nMap & dashboards on GFW\nThe map & dashboards on GFW allow to explore hundreds of spatial datasets that help explain when, where and why forests are changing around the world.\nThe map helps tell a visual story about what’s happening to forests in a particular place. Zoom in anywhere in the world to explore how forests are changing, how they’re managed and the values they provide. Layer data – like annual tree cover loss, land use data and satellite imagery – to better understand the underlying causes and impacts of forest change.\nThe dashboards help answer important questions about forest change in any area and enable you to view hundreds of statistics through interactive charts and graphs, all derived from analysis of spatial data. Statistics can be customized to be as general or specific as you like and can be easily shared and downloaded for offline use.\n3.3 Case comments\nAdvantages or contribution\n\n\nGlobal: GFW can provide forest monitoring data and information on a global scale, allowing governments, businesses, NGOs and citizens to understand the state of the world’s forest resources.\n\nTimeliness: GFW can provide almost real-time forest monitoring data and information that can help identify and respond to deforestation, wildfires and other natural disasters in a timely manner.\n\nDiversity: GFW can provide a wide range of data and information, including maps, satellite imagery, data analysis and stories, to meet the needs of a variety of users.\n\nOpenness: GFW uses open data principles that allow anyone to use and share data and information, thus increasing the reliability and value of the data used.\n\nDisadvantages or potential\n\n\nData quality: GFW relies on a variety of data sources, including satellite imagery, ground-based observations, interviews, etc. Data quality varies and may be subject to error.\n\nData updates: Although GFW can provide almost real-time forest monitoring data and information, some data can be slow to update and it can take some time to wait for the latest data to become available.\n\nThreshold of data use: GFW data and information require a certain level of expertise and skills to use and analyse, which may be difficult for non-expert users.\n\nData privacy: GFW’s data and information may contain some sensitive information that requires attention to data privacy protection."
  },
  {
    "objectID": "WEEK5.html#reflection",
    "href": "WEEK5.html#reflection",
    "title": "WEEK 5",
    "section": "4 Reflection",
    "text": "4 Reflection\nDuring the week I have been learning about the basic principles and operational aspects of GEE and have been excited to learn about the many applications of GEE. Sometimes I want to upload my research to the web for interactive use, but I don’t know much about web development or software development due to my professional background, and GEE provides a platform for this, as well as a very rich data source and analysis tools to support the development of applications, which has a very wide range of applications. In addition, the interactive web platform provides a window of communication between urban planning and the public, making it easier to collect and publicise data.\nHowever, I have concerns about data privacy and copyright. On the one hand, I am concerned that my privacy may be compromised, and on the other hand, I am concerned that there may be unknowing copyright infringement in the data used, which requires careful attention during development."
  },
  {
    "objectID": "WEEK6.html",
    "href": "WEEK6.html",
    "title": "WEEK 6",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 6, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK6.html#summary-lecture",
    "href": "WEEK6.html#summary-lecture",
    "title": "WEEK 6",
    "section": "1 Summary: lecture",
    "text": "1 Summary: lecture\nThis week, after understanding the basic concepts of machine learning, classification and regression trees (CART) including regression trees, overfitting, random forests were studied. After that, extend it to the field of image classification and learn about unsupervised classification including DBSCAN, ISODATA and supervised classification including maximum likelihood, support vector machine (SVM).\n\n\n\nMindmap of Week 6 Leacture\n\n\n\n\n1.1 How classified data is used\nIn some form all these studies extracted Land Cover from EO data\n\nUrban expansion\nAir pollution and LULC\nUrban green spaces\nMonitoring forests + illegal logging\nForest fires\n\n\n\n1.2 Introduction of machine learning\n\nExpert Systems\nA system that uses human knowledge to solve problems that normally require human intelligence\n\nKnowledge Base = Rules of thumb, not always correct\nInference Engine = Process of reaching a conclusion and the expert system is implemented\nYou might try and represent your knowledge through a series of decisions = knowledge representation through a decision tree\n\n\n\nMachine learning\n\nMachine learning = science of computer modeling of learning process\nWhen humans have some generalizations we can reach a logical assumption or conclusion = inductive learning\nMachine learning is a search through all the data to explain the input data and can be used on new input data\n\n\n\nIs linear regression machine learning?\n\nYes, the model finds the best fit between independent and dependent variables\nYou are fitting a model to some data which could be used for prediction\n\n\n\n\n1.3 Classification and regression trees (CART)\n\nComposition\n\nClassification trees: classify data into two or more discrete (can only have certain values) categories\nRegression trees: predict continuous dependent variable, subset the data into smaller chunks\n\n\n\nGini Impurity\nWhen we create a decision tree the final leaves might be a mixture of the categories = impure, quantify this with the Gini Impurity\n\n\n\n\n\n\nCalculation\n\n\n\n\n1-(probability of yes)^2-(the probability of no)^2\nWeighted based on numbers\n\n\n\n\nThe one with the lowest impurity goes at the top of the tree to start the decision making…the root\nWe then use the Gini impurity at each branch to split the nodes further\nOnce we don’t need to split these turn into leaves and the output has the most votes\n\n\n\nRegression trees\n\n\n\nHow do Regression Trees Work?. Source:Luka Beverin\n\n\nDifference\n\nTake and predict continuous values (e.g. amount of pollution)\nClassification trees take and predict discrete values (e.g. landcover)\nEach leaf is a numeric value not category like in classification trees\n\nHow do we decide where to make the breaks in the data?\nresiduals (like linear regression) for each threshold (which is a value on the x axis)\n\nWe divide this up into sections based on thresholds (nodes) and calculate the sum of the squared residuals\nWe can then check the SSR for different thresholds, the one with the lowest SSR is the root of the tree to start with, then repeat\nTo prevent over fitting we can set a minimum number of observations before splitting the data again\n\nWe can do this with many predictor variables, we try different thresholds and calculate the sum of squared residuals (SSR) - e.g. age or gender\n\n\nOverfitting\nWhat if we have a leaf with just one person or one pixel value? = overfitting\n\n\n\nWhat is overfitting?.Source:Seema Singh\n\n\n\nBias = difference between predicted value and true value = oversimplifies model\nVariance = variability of model for a given point = does not genearlise well\n\nHow to limit overfitting?\n\nLimit how trees grow (e.g. a minimum number of pixels in a leaf, 20 is often used)\nWeakest link pruning (with tree score)\n\nUse one less leaf, remove a leaf = sub-tree, SSR will get larger = termed PRUNING or cost complexity pruning\nTree score = SSR + tree penalty (alpha) * T (number of leaves)\nChanging Alpha (Different values of alpha give us give different sub trees and tree scores)\n\nUse a full size regression tree (with all data)\nStart with a value of 0 (this will give lowest value of tree score)\nThen increase until pruning (removing a leaf) gives lower tree score\nSave those alpha values\n\nGo back to all the data\n\nDivide the data into training (70%) and testing data (30%)\nTake training data and use alpha values from before\nEach alpha will be made into a new tree with this new data\n\nTake each tree\n\nPlace the testing data within the divisions based on the different trees\nCalculate the SSR with the test data (testing data bold, train light)\nWhich tree has the smallest SSR\n\nRepeat previous slide with different training and testing data (10 times cross validation), on average from the 10 tests the value of alpha that gives lowest SSR from testing data is the final value, select the tree from that used the full data with that alpha!\n\n\n\n\nRandom Forests\n\n\n\nRandom Forest and overview. Source: Science Direct\n\n\n\nGrow many classification decision trees - Many better than one\n\nTake our data and take bootstrap samples (same data can be picked many times)\nMake decision tree from random number of variables (never all of them)\nNext at the node take a random subset of variables again = RANDOM\nRepeat\n\nWe get many, many different trees = a forest\nRun the data we have down the trees\nWhich option gets more votes based on all the tree\nBootstrapping (re-sampling by replacement data to make a decision = bagging)\n\nFor each tree about 70% of the training data is used in the bootstrap, 30% is left out of the bag (OOB)\nTest the OOB data in the forest where all the trees didn’t use it and repeat for all OOB samples, most votes wins!\nOut of Bag Error: proportion of OOB incorrectly classified = OOB error\nOften the number of variables per tree is calculated from square root of variables in the original data.\n\nNo pruning: trees can do down to largest extent\n\n\n\n\n\n\n\nTerms\n\n\n\nValidation data: different from OOB and never included within the decision trees\n\n\n\n\n\n1.4 Image classification\nTurn every pixel in the image into one of a pre-defined categorical classification, either supervised or unsupervised classification procedure, there are generic machine learning algorithms and remote sensing specific ones\n\nCharacteristic\nSupervised\n\nPattern recognition or machine learning\nClassifier learns patterns in the data\nUses that to place labels onto new data\nPattern vector is used to classify the image\n\nUnsupervised\n\nIdentify of land cover classes aren’t know a priori (before)\nTell them computer to cluster based on info it has (e.g. bands)\nLabel the clusters\n\n\n\nUnsupervised classification (Clustering / K-means)\n\n\n\nUnsupervised Classification. Source: Yuting Wan\n\n\nDBSCAN\nradius(Epsilon) and min points(for the cluster): place points randomly or uniformly across spectral feature space or across the first PCA\n\nSet the radius in spectral feature space at which new cluster to new started\nSpectral distance to merge (within they are the same)\nNumber of pixels to be considered before merging\nMax number of clusters\nClusters migrate over time\nRepeat until N iterations or no allocations of pixels left\n\nISODATA\nSame as k-means but adds:\n\nAny clusters have so few pixels = meaningless\nClusters are so close they can be merged\nClusters can be split - elongated clusters in feature space\n\nTypically inputs can include:\n\nMax clusters\nMax % pixels of class values that can be unchanged - stops\nMax times of iterations\nMin pixels per cluster\nMax standard deviation - then split the cluster\nMin distance between clusters\n\nCluster busting: ISODATA can create lots of clusters and it’s difficult to assign meaning (e.g. landcover)\n\nTwo types of landcover in the pixel\nDistribution of mean vectors not good enough to differentiate them\nLet’s bust those clusters!\n\nTake the incorrect or difficult to label ones\nMask them\nPerform a separate classification\nRepeat\n\n\n\n\nSupervised classification\n\n\n\nSupervised Classification. Source: skilltohire\n\n\nMethods\n\nParametric (normal distribution): Maximum likelihood\nNon-parametric (Non-parametric): Density slicing, Parallelpiped, Minimum distance to mean, Nearest neighbor, Neural networks, Machine learning / expert systems\nMore recent work uses machine learning / expert systems(e.g. Support Vector Machine, Neural Networks ) or spectral mixture analysis\n\nSame process for all\n\nClass definition\nPre-processing\nTraining\nPixel assignment\nAccuracy assessment\n\nAn approach to select a classifier…in most cases training samples will overlap…unless you select spectrally pure endmembers or use a spectral library\nMaximum likelihood\n\nBasics\n\nDecision rule classifier\nUses probability\nTakes the image and assigns pixel to the most probable land cover type\nYou can set a probability threshold which means if a pixel is below it = no classification\n\nSpecifics\n\nFrom histogram to probability density function: mean and standard deviation of training data\nIn imagery this is n dimensional multivariate normal density function\nEach pixel from image data is passed to the maximum likelihood rule > assigns landover to the largest product\nThe key is it is based on probability…the data (landcover) most probably to have the values in our pixel\n\n\nMaximum Likelihood allows classification with prior pobablity information (e.g. 60% expected to be urban, usually we don’t have this though)\n\n\n\n\n\n\nTerms\n\n\n\n\nPattern vector: all the band values per pixel (could include texture etc)\n\n\n\nSupport Vector Machine (SVM)\nSimply a linear binary classifier - like logistic regression\n\n\n\n\n\n\nTerms\n\n\n\n\nMaximum margin between two classes of training data = maximum margin classifier\nPoints on the boundaries (and within) are support vectors\nMiddle margin is called the separating hyperplane\nSoft margin = allow some misclassificaitons to occur\n\n\n\n\nWe use cross validation to know how many misclassifications to allow\nAim is to get best classification, whilst allowing some wrongly classified points\nMore than 2 datasets we go into 3D and use a plane not a line\nCan decide how we seperate data, One-to-One or One-to-Rest\nUnderlying theory is structural risk minimisation: minimise error on unseen data with no assumptions on the distribution\nSelectable\n\nType of kernel\nHyperparameters like C and Gamma (or Sigma) control SVM wiggle\n\nC controls training data and decision boundary maximisation plus margin errors. The bigger = narrower margin.\nGamma (or Sigma) = controls the distance of influence of a training point. low = big radius for classified points, high = low radius for classified points (only once we have transformed our data can we apply gamma)\n\nIf they aren’t linearly separable we can transform the data with the kernel trick (apply some function to make them linearly separable)\nHow do we select the best values of C and gamma: we test them all (or all the ones you want to) using grid search and compare them to our testing data…the ones that give the best accuracy are selected\nMany models have hyperparameters that can’t be learned directly from a single data set when training the model. This means you might have to test the hyperparameters after model training / run the model several times. However, in tidymodels, we can train many models in a grid of possible hyperparameter values and see which ones turn out best\n\nIn SVM we want to make sure each data set is on the correct side of a hyper plane, it does so through:\n\nMaximising the margin (the smallest residual)\nMinimising misclassified points: \"soft margin\"\nChanging C changes the “slope” - consider more points"
  },
  {
    "objectID": "WEEK6.html#summary-practical",
    "href": "WEEK6.html#summary-practical",
    "title": "WEEK 6",
    "section": "2 Summary: practical",
    "text": "2 Summary: practical\n\nThis week’s practical will consist mainly of the following:\n\nEO data acquisition and cloud removal using GEE\nTraining a CART classifier for land use supervised classification using GEE\nAccuracy check of land use classification using GEE by dividing training and test sets through random forest method\n\n\nDuring this week, I used GEE to classify land use in Nanchang, China (my hometown), referring to practical’s guidance. The first step was to obtain Sentinel data and remove the effect of clouds by taking the median, after which the CART classifier was trained by supervised classification, after which the training and test sets were divided by the random forest method, and the land use of Nanchang was classified and checked for accuracy.\n\n\n\nPractical output: Nanchang land use classification through supervised classification."
  },
  {
    "objectID": "WEEK6.html#application",
    "href": "WEEK6.html#application",
    "title": "WEEK 6",
    "section": "3 Application",
    "text": "3 Application\n\nThis week I have learnt about machine learning, classification and regression trees (CART) and image classification. I hope to delve into the application of image classification in the field of remote sensing.\n\n\n3.1 Applications of image classification in remote sensing\nThe applications of image classification in the field of remote sensing are mainly in the following areas:\nLand cover and land use classification: Image classification techniques can assign pixels in remote sensing images to different land cover and land use categories, such as forests, grasslands, farmlands, cities, wetlands and so on. This helps to understand the distribution, use and change of land resources and provides important information for urban planning, environmental protection and resource management.\nVegetation and forest monitoring: Image classification methods can identify vegetation types such as trees, shrubs, grasslands, etc. in remotely sensed images. This helps to assess forest cover, biodiversity and ecosystem health. Also, image classification can be used to monitor disaster events such as forest fires, pests and diseases, providing a basis for forest protection and management.\nAgricultural monitoring: Image classification allows the identification of crop growing areas in remotely sensed images to estimate crop acreage, growth and yield. This contributes to early warning for food security, agricultural policy development and fine-grained agricultural management.\nThere are also specific application scenarios and examples in the field of urban planning:\nConstruction land extraction: Image classification techniques can extract various types of construction land from remote sensing images, such as residential, commercial and industrial areas. This helps to assess the current situation and development trend of urban land, and provides a basis for urban land use planning and urban expansion.\nTraffic facilities extraction: Image classification can extract information on traffic facilities such as roads, bridges and railways from remote sensing images. This helps to understand the layout and development status of urban transport networks and provides a basis for transport planning and construction.\nGreenery coverage extraction: Image classification technology can extract greenery coverage information such as green areas, parks and woodlands from remote sensing images. This helps to assess the state of urban greenery and ecological environment quality, and provides a basis for urban greenery planning and ecological protection.\nUrban expansion and change monitoring: By classifying multi-temporal remote sensing images, urban expansion and change can be identified, providing a basis for urban development trend analysis and planning adjustment.\n\n\n3.2 Application case\n\n\n\n\n\n\nSourse\n\n\n\nAssessing contextual descriptive features for plot-based classification of urban areas , Sourse: Hermosilla et al. (2012)\n\n\nA methodology for mapping urban land-use types integrating information from multiple data sources (high spatial resolution imagery, LiDAR data, and cadastral plots) is presented. A large set of complementary descriptive features that allow distinguishing different urban structures (historical, urban, residential, and industrial) is extracted and, after a selection process, a plot-based image classification approach applied, facilitating to directly relate the classification results and the urban descriptive parameters computed to the existent land-use/land-cover units in geospatial databases.\n\n\n\nExamples of the urban classes defined in colour-infrared composition: (a) historical; (b) urban; (c) open urban; (d) detached housing; (e) semi-detached/terraced housing; and (f) industrial. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)\n\n\nThe descriptive features are extracted by considering different hierarchical scale levels with semantic meaning in urban environments: buildings, plots, and urban blocks. Plots are characterised by means of image-based (spectral and textural), three-dimensional, and geometrical features. In addition, two groups of contextual features are defined: internal and external. Internal contextual features describe the main land cover types inside the plot (buildings and vegetation). External contextual features describe each object in terms of the properties of the urban block to which it belongs. After the evaluation in an heterogeneous Mediterranean urban area, the land-use classification accuracy values obtained show that the complementary descriptive features proposed improve the characterisation of urban typologies. A progressive introduction of the different groups of descriptive features in the classification tests show how the subsequent addition of internal and external contextual features have a positive effect by increasing the final accuracy of the urban classes considered in this study.\n\n\n\nThree details of colour infrared images (left) and a land-use thematic map (right) derived from the classification using the most efficient set of features.\n\n\n\n\n3.3 Case comments\nAdvantages or contribution\n\nMulti-source data fusion: The study proposes a method for integrating multi-source data (high-resolution remote sensing images, LiDAR data and cadastral maps) for mapping urban land use types, enabling the differentiation of different urban structures (historical, urban, residential and industrial).\nIntegrated feature extraction: The thesis extracts a set of complementary descriptive features, including basic image features (spectral and texture), 3D features and geometric features, as well as internal and external contextual features. These features describe the main land cover types (buildings and vegetation) within the parcel, and the attributes of the urban neighbourhood to which the parcel belongs, respectively.\nHierarchical structural treatment: The thesis extracts descriptive features by considering different hierarchical structural scales (buildings, plots and urban blocks) that have semantic significance in the urban environment.\nAccuracy of results: The thesis verifies that the proposed descriptive features improve the accuracy of the classification of urban land use types through an empirical study in a Mediterranean urban area. The results of classification experiments where different groups of descriptive features are introduced step by step show that the addition of internal and external contextual features is effective in improving the accuracy of the final classification.\n\nDisadvantages or potential\n\nData accessibility: The multi-source data used in the thesis, including high-resolution remote sensing imagery, LiDAR data and cadastral maps, may be difficult to access or require expensive purchase costs in some areas. This limits the application of the method in areas where resources are limited or data is difficult to obtain.\nFeature selection sensitivity: The feature selection methods used in the thesis may have an impact on the accuracy of the final classification results. Different feature selection methods may lead to different classification results.\nScene adaptation: The methods in the thesis may require parameter adaptation and optimisation for different urban scenarios and land use types. This may increase the complexity and difficulty of the methods in practical application."
  },
  {
    "objectID": "WEEK6.html#reflection",
    "href": "WEEK6.html#reflection",
    "title": "WEEK 6",
    "section": "4 Reflection",
    "text": "4 Reflection\nThe learning this week has been very informative and exciting, with image classification based on machine learning offering huge potential for remote sensing image analysis, and applications in the urban domain to do work that would be difficult to do by hand alone. But for me personally, there is an overwhelming amount of knowledge coming in and it will take a while to understand the principles of the knowledge.\nBut is this perhaps also a black box? For me, with a focus on urban analysis, I should know more about how to apply these tools appropriately to urban scenarios, rather than knowing every step of the way (of course it’s better to understand them), and understanding the inputs and outputs of these tools properly might as well be able to meet most of my needs.\n\n\n\n\nHermosilla, T., L. A. Ruiz, J. A. Recio, and M. Cambra-López. 2012. “Assessing Contextual Descriptive Features for Plot-Based Classification of Urban Areas.” Landscape and Urban Planning 106 (1): 124–37. https://doi.org/10.1016/j.landurbplan.2012.02.008."
  },
  {
    "objectID": "WEEK7.html",
    "href": "WEEK7.html",
    "title": "WEEK 7",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 7, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK7.html#summary-lecture",
    "href": "WEEK7.html#summary-lecture",
    "title": "WEEK 7",
    "section": "1 Summary: lecture",
    "text": "1 Summary: lecture\nThis week started with Object based image analysis (OBIA) and sub pixel analysis, and continued with accuracy assessment methods, mainly spatial cross validation.\n\n\n\nMindmap of Week 7 Leacture\n\n\n\n\n1.1 Object based image analysis and sub pixel analysis\n\nObject based image analysis (OBIA)\n\n\n\nSegOptim. Source: João Gonçalves 2020\n\n\n\nInstead of considering cells we consider shapes based on the similarity (homogeneity) or difference (heterogeneity) of the cells = superpixels\nSLIC (Simple Linear Iterative Clustering) Algorithm for Superpixel generation is the most common method\n\nRegular points on the image\nWork out spatial distance (from point to centre of pixel) = closeness to centre\nColour difference (RGB vs RGB to centre point) = homogenity of colours\nCan only use Euclidean distance in SLIC\nEach iteration the centre moves- 4-10 is best (based on orignal paper)\nThe values can change and the boarders move (like k-means?)\nDoesn’t consider connectivity = very small cells\nWe can then take the average values per object and classify them using methods we’ve seen\nSupercells package can use any distance measure (e.g. dissimilarity)\n\nNote that there are many OBIA classifiers, they all do similar, but slightly different processes, more advanced package would be SegOptim that can use algorithms from other software\n\n\n\nSub pixel analysis\n\nTermed (all the same): Sub pixel classification, Spectral Mixture Analysis (SMA), Linear spectral unmixing\n\nCharacteristic\n\n\n\nSource: Machado and Small (2013) 2017\n\n\nSMA determines the proportion or abundance of landcover per pixel. The assumption that reflectance measured at each pixel is represented by the linear sum of endmembers weighted by the associated endmember fraction. Typically we have a few endmembers that are spectrally pure.\nFormula\nSum of end member reflectance * fraction contribution to best-fit mixed spectrum\n\\[\np_\\lambda=\\sum_{i=1}^{n} (p_{i\\lambda} * f_i) + e_\\lambda\n\\]\n\n\\(p_\\lambda\\) = The pixel reflectance\n\\(p_i\\lambda\\) = reflectance of endmember \\(i\\)\n\\(f_i\\) = fractional cover of end member \\(i\\)\n\\(n\\) = number of endmembers\n\\(e_\\lambda\\) = model error\n\nNumber of End members\nSimplify the process and use the V-I-S model in urban areas: Vegetation-Impervious surface-Soil (V-I-S) fractions\nMultiple endmember spectral analysis (MESMA)\nIncrease computation or use a spectral library\n\n\n\n1.2 Accuracy assessment\n\nAfter producing and output we need to assign an accuracy value to it (common to machine learning).\n\n\n\n\nSource: Barsi et al. 2018 Accuracy Dimensions in Remote Sensing\n\n\n\nRemote sensing focus on\n\nPA Producer accuracy (recall or true positive rate or sensitivity)\nUA User’s accuracy (consumer’s accuracy or precision or positive predictive value\nOA the (overall) accuracy\n\n\n\nWhere model is correct\n\nTrue positive = model predicts positive class correctly\nTrue negative = model predicts negative class correctly\n\n\n\nWhere model is incorrect\n\nFalse positive = model predicts positive, but it is negative\nFalse negative = model predicts negative, but it is positive\n\n\n\nCalculation\n\nProducer’s accuracy defined as the fraction of correctly classified pixels (TP) compared to ground truth data (TP+FN)\nUser’s accuracy defined as the fraction of correctly classified pixels (TP) relative to all others classified as a particular land cover(TP+FP)\nOverall accuracy that represents the combined fraction of correctly classified pixels (TP +TN) across all land cover types (TP+FP+FN+TN)\nErrors of omission (100-producer’s accuracy)\nErrors of commission (100- user’s accuracy)\n\n\n\nKappa coefficient\n\\[\nk=\\frac{p_o - p_e}{1- p_e}\n\\]\n\n\\(p_o\\) is the proportion of cases correctly classified (accuracy)\n\\(p_e\\) expected cases correctly classified by chance (further equations in Foody 2020)\n\nDesigned to express the accuracy of an image compared to the results by chance, ranges from 0 to 1.\n\n“Sadly the calls to abandon the use of the kappa coefficient in accuracy assessment seem to have fallen on deaf ears. It may be that the kappa coefficient is still widely used because it has become ingrained in practice and there may be a sense of obligation to use it”\n\n\n\nBeyond traditional remote sensing accuracy assessment\n\nProblem with recall (Producer accuracy) vs Precision (User accuracy)\nFalse positives (Producer) or false negatives (User) more important?\n\nmodel with high recall (Producer accuracy) = true positives but some false positives (predicted urban but land cover that isn’t urban)\nModel with high precision (User’s accuracy) = actual urban but predicted other landcover We can’t have both a high high producer accuracy (recall) and a high user’s accuracy (precision)\n\nUser’s accuracy (precision)\n\nI have gone to a site, the model predicted it to be urban, it is not urban…\nHow well can the user use the data / classification\n\nProducer’s accuracy (recall)\n\nI have gone all the urban sites, they were urban. BUT I can see in the distance a site that was predicted to be GRASS but is actually URBAN\nHow well did the producer make the data/ classification\n\n\nF1 score\nThe F1-Score (or F Measure) combines both recall (Producer accuracy) and Precision (User accuracy):\n\\[\nF1 = \\frac{TP}{TP + \\frac{1}{2}*(FP+FN)}\n\\]\nValue from 0 to 1, where 1 is better performance\n\nIssues\n\nNo True Negatives (TN) in the equation\nNegative categories that are correctly classified as negative\nAre precision and recall equally important ?\n\nPrecision (producer): how many positive points are correct\nRecall (user): how precise the model is at positive predictions\n\nWhat if our data is very unbalanced ? - More negatives than positives?\n\n\n\n\nReceiver Operating Characteristic Curve (the ROC Curve)\n\nChanging the threshold value of classifier will change the True Positive rate\nMaximise true positives (1) and minimise false positives (0)\nVertical columns here - uses whole matrix\n\nFirst is True positive: true positive rate = TP/TP+FN\nSecond is False positive rate: false positive rate = FP/FP+TN\n\n\nArea Under the ROC Curve (AUC, or AUROC)\n\n\n\nSource: MLU-EXPLAIN\n\n\n\nSimply the area under the curve\nCompare models easily (no need to look at the ROC curve)\nPerfect value will be 1, random will be 0.5\n\n\n“The AUC is the probability that the model will rank a randomly chosen positive example more highly than a randomly chosen negative example.”\n\n\n\nHow do we get test data for the accuracy assessment?\n\nSometimes - remote sensing approach\nGood approach - train and test split\nBest approach - cross validation\n\nSpatial cross validation\n\n\n\nSpatial visualization of selected test and training observations for cross-validation of one repetition. Random (upper row) and spatial partitioning (lower row). Source: Lovelace et al. 2022\n\n\n\nSpatially partition the folded data, folds are from cross validation\nDisjoint (no common boundary) using k -means clustering (number of points and a distance)\nSame as cross validation but with clustering to the folds\nStops our training data and testing data being near each other > In other words this makes sure all the points (or pixels) we train the model with a far away from the points (or pixels) we test the model with\n\n\n\n\n\n\n\nSource\n\n\n\nUse a Support Vector Machine classifier that requires hyperparameters (set before the classification).Source: Lovelace et al. (2022)\n\n\n\nStandard SVM then the classifier will try to overfit = perfect for the current data but useless for anything else\nCortes and Vapnik - soft margin, permit misclassifications = controlled with C\n\nC = adds penalty (proportional to distance from decision line) for each classified point. Small = image on right, large = image on left. changes the slope\nGamma (or also called Sigma) = controls the influence of a training point within the classified data\nPerformance level each spatial fold (taken from our first k-means cross validation fold division). = Top row below, a typical cross validation fold\nTuning level each fold (outer) is then divided into 5 again (inner fold).= Bottom row below\nPerformance estimation Use the 50 randomly selected hyperparameters in each of these inner subfolds, i.e., fit 250 models with random C and Gamma use the best values to outer fold, based on AUROC with testing data"
  },
  {
    "objectID": "WEEK7.html#summary-practical",
    "href": "WEEK7.html#summary-practical",
    "title": "WEEK 7",
    "section": "2 Summary: practical",
    "text": "2 Summary: practical\n\nThis week’s practical will consist mainly of the following:\n\nObjectbased image analysis (OBIA) using GEE\nSpectral unfixing with GEE\n\n\nThis week’s practical focused on deepening the content of the lecture and carrying out practical exercises. I followed the instructions and choosed Dar es Salaam as my research area, did spectral unfixing and object based image analysis (OBIA) using GEE. The content is relatively complex and requires further practice or application to fully understand the content of this section.\n\n\n\nThe process of performing OBIA on Dar es salaam remote sensing images."
  },
  {
    "objectID": "WEEK7.html#application",
    "href": "WEEK7.html#application",
    "title": "WEEK 7",
    "section": "3 Application",
    "text": "3 Application\n\nThis week’s study included many interesting topics such as object based image analysis (OBIA), sub pixel analysis, and spatial cross validation. In particular, sub pixel analysis significantly expanding the application scenarios and accuracy of remote sensing image analysis.\n\n\n3.1 Applications of sub pixel analysis\nSub pixel analysis has a wide range of application scenarios in the field of remote sensing, mainly including the following:\nImage resolution enhancement: Sub pixel analysis can be used to improve the spatial resolution of remote sensing images. Traditional remote sensing images are often limited by the size of image elements, resulting in insufficient ability to describe the details of the features. Sub-pixel analysis techniques can extract more feature detail from the information within the image element, thereby increasing the resolution of the image and helping to identify and measure surface features more accurately.\nTarget detection and classification: Sub pixel analysis plays an important role in the detection and classification of targets in remotely sensed images. For example, features such as buildings, vegetation and water bodies in remotely sensed images may be mixed within an image element, making it difficult for traditional element-based classification methods to accurately distinguish these features. Sub-pixel analysis can extract detailed information within these mixed pixels to improve the accuracy of target detection and classification.\nEnvironmental monitoring: Sub pixel analysis also has important applications in environmental monitoring. For example, by analysing sub-pixel information in satellite remote sensing images, environmental parameters such as vegetation cover and water body area can be estimated more accurately, providing an important basis for environmental protection and planning.\nRadiative transfer models: Sub-pixel analysis techniques can also be used in the study of radiative transfer models. Radiative transfer models are the basis of remote sensing inversions and are used to describe the radiative transfer processes between the Earth’s surface and the atmosphere. Sub-pixel techniques can help researchers to model this process more accurately and improve the accuracy of remote sensing inversions.\nThere are also extensive applications in the field of urban planning.\nBuilding and road extraction: Sub pixel analysis techniques can be used to extract building and road information from urban remote sensing images more accurately. This is important for the planning, construction and maintenance of urban infrastructure. By increasing image resolution, sub-pixel analysis helps to identify and measure detailed features in the city, such as building outlines, road widths, etc.\nGreen space and water monitoring: Sub pixel analysis can be applied to urban green space and water monitoring. By analysing the detailed information in the mixed image elements, sub-pixel analysis can provide more accurate estimates of environmental parameters such as green space coverage and water body areas, providing a basis for urban greening and water resource management.\nUrban sprawl and land use change monitoring: Sub pixel analysis can help urban planners monitor urban sprawl and land use change. This technique can improve the accuracy of change detection and help to analyse urban development trends and develop sound urban planning strategies.\nHeat island effect research: Sub pixel analysis techniques can be applied to the study of urban heat island effect. By improving the resolution and accuracy of remotely sensed images, sub-pixel analysis can provide a more accurate description of urban surface temperature distribution, help to identify the causes and extent of the urban heat island phenomenon, and provide support to urban planners in formulating measures to reduce the heat island effect.\nPopulation density estimation: Sub pixel analysis techniques can be used to more accurately estimate urban population density. By analysing detailed information about buildings and residential areas in remotely sensed images, sub-pixel analysis can provide more accurate data to support urban population distribution and planning.\n\n\n3.2 Application case\n\n\n\n\n\n\nSourse\n\n\n\nMapping sub-pixel urban expansion in China using MODIS and DMSP/OLS nighttime lights , Sourse: Huang, Schneider, and Friedl (2016)\n\n\nUrbanization accelerated rapidly in China during the first decade of the 21st century, largely at the expense of agricultural lands. To improve available regional information related to the coupled dynamics between these two land use types, this paper fused data from the Moderate Resolution Imaging Spectroradiometer (MODIS) and stable nighttime lights observations from DMSP/OLS instruments to map fractional urban cover at 250m spatial resolution for cities in Eastern, Central, and Southern China where recent urban expansion has been rapid and pronounced.\n\n\n\nA comparison of the Landsat-based maps, the percentage urban cover from MODIS, the difference in percentage urban land, as well as the bias for each date for three cities: Chengdu (top row), Guangzhou (middle row), and Kunming (bottom row).\n\n\nTo accomplish this, this paper constructed Random Forest regression models to estimate sub-pixel urban percentage for 2001 and 2010 using high quality calibration information derived from Landsat data. Separate models were built for temperate and tropical regions and then evaluated for nine cities between 18,000 and 31,000km2 in area. Urban area estimated from MODIS compared favorably with Landsat-based results, with mean absolute errors of 9-15%. Tests of different input feature sets showed that including data from downscaled MODIS 500m bands and nighttime lights can improve estimates of urban land area compared to using MODIS 250m features alone. Based on these results this paper produced wall-to-wall maps of urban land use in 2001 and 2010 for four MODIS tiles covering temperate and subtropical China, thereby demonstrating the utility of coarse spatial resolution data for mapping urban land use and loss of agricultural land at regional and larger scales.\n\n\n\nA comparison of (left to right) the Landsat false color composite (red, green, blue set to SWIR, NIR, and green), the mean annual enhanced vegetation index (EVI) from MODIS, and the DMSP/OLS nighttime lights, the 250 m urban fraction maps produced in this work for two cities in Eastern and Central China: Shijiazhuang and Xinxiang. Note that no training data were drawn from these areas.\n\n\n\n\n3.3 Case comments\nAdvantages or contribution\n\nImproved access to spatial resolution and regional information on rapid urban expansion in eastern, central and southern China using a combination of MODIS and DMSP/OLS nighttime lighting data.\nEstimated sub pixel urban coverage percentages for 2001 and 2010 using a random forest regression model and obtained high quality calibration information using Landsat data.\nSeparate models were constructed for different climatic regions (temperate and tropical), assessing nine cities within a range of 18,000-31,000 km2 .\nCompared to Landsat-based results, the urban areas estimated using MODIS have a high accuracy, with an average absolute error of about 9-15%.\nDifferent sets of input features were tested and the results show that incorporating downscaled MODIS 500m band and nighttime light data into the model improves the accuracy of urban land area estimates, outperforming the use of MODIS 250m features only.\n\nDisadvantages or potential\n\nThe article focuses on the impact of urban expansion on agricultural land, but does not discuss in depth the changes in other land types (e.g. forests, wetlands, etc.) during urban expansion, possibly overlooking the impact of urbanisation on other ecosystems.\nThe article uses MODIS and DMSP/OLS nighttime lighting data for the analysis, but there may be limitations in the spatial and temporal resolution and sensor performance of these two data sources that affect the accurate identification of urban expansion and land use change.\nThis study only analyses urban land use for the years 2001 and 2010 without dynamic change analysis, thus making it difficult to capture the stage characteristics and trends in the urban expansion process.\nThe article relies mainly on remote sensing data for urban expansion analysis and lacks the support of field surveys and socio-economic data, which may lead to the analysis results deviating from the actual situation."
  },
  {
    "objectID": "WEEK7.html#reflection",
    "href": "WEEK7.html#reflection",
    "title": "WEEK 7",
    "section": "4 Reflection",
    "text": "4 Reflection\nThis week has been interesting and challenging, with new knowledge added to improve the accuracy of remote sensing image analysis and broaden the application scenarios. Based on what I have learnt this week, I am not only able to carry out more in-depth analysis, but also able to assess the accuracy of the analysis.\nIn my practical work in detailed urban planning and design, the spatial resolution of many remote sensing data is too large (around 30m is common), but what this week learnt has reduced this limitation. However, it will still take some practice and application for me to master the content of this week.\n\n\n\n\nHuang, Xiaoman, Annemarie Schneider, and Mark A. Friedl. 2016. “Mapping Sub-Pixel Urban Expansion in China Using MODIS and DMSP/OLS Nighttime Lights.” Remote Sensing of Environment 175 (March): 92–108. https://doi.org/10.1016/j.rse.2015.12.042."
  },
  {
    "objectID": "WEEK8.html",
    "href": "WEEK8.html",
    "title": "WEEK 8",
    "section": "",
    "text": "This is a learning diary of CASA0023 WEEK 8, the lecture presentation is here, and the practical material is here."
  },
  {
    "objectID": "WEEK8.html#summary-lecture",
    "href": "WEEK8.html#summary-lecture",
    "title": "WEEK 8",
    "section": "1 Summary: lecture",
    "text": "1 Summary: lecture\nThe week began with a study of urban heat islands, followed by a number of remote sensing-related policy scenarios, and prompted reflection on policy development and implementation.\n\n\n\nMindmap of Week 8 Leacture\n\n\n\n\n1.1 What is the Urban Heat Island\n\nUrban areas obtain comparatively higher atmospheric and surface temperatures than surrounding rural areas\n\n\n\n\nSource: EARTH.ORG\n\n\n\nFactors\n\nMore dark surfaces that retain heat\nLess vegetation that cools the environment (evapotranspiration and solar blocking)\nA low Sky View Factor (SVF): radiation received (or emitted) by a planar surface to the radiation emitted (or received) by the entire hemispheric environment\nAir speed, cloud cover, cyclic solar radiation, building material type and anthropogenic energy\n\n\n\nHow much does it cost\nSocial\nPopulation adjusted excess mortality rates during the 1998 Shanghai heatwave were estimated at 27.3 per 100,000 within the urban area compared to only 7 per 100,000 in the exurban districts\nEnvironmental\n\nEach degree of ambient temperature rise the increase in peak electricity load has been estimated between 0.45 and 4.6%, corresponding to around 21 W per degree rise per person\nFossil fuel + pollution\n\nEconomic\n\nGross Domestic Product (GDP) = value of finished goods and services within a country\nPercent GDP lost from UHI\n\nUnder low Green House Gas scenario: 0.71% (in 2050) and 1.04% (in 2100)\nUnder very high Green House Gas scenario: 0.80% (in 2050) and 1.79% (in 2100)\n\nUHI excluded from Global Climate Change (GCC) scenarios\nHope: reduction in economic damages through policies\n\n\n\n\n1.2 Global policy documents\n\nNew Urban Agenda\n\nStandards and principles for planning, construction, development, management and urban improvement\n\nPoint 37\nWe commit ourselves to promoting safe, inclusive, accessible, green and quality public spaces, including streets, sidewalks and cycling lanes, squares, waterfront areas, gardens and parks, that are multifunctional areas for social interaction and inclusion, human health and well-being\nPoint 54\nWe commit ourselves to the generation and use of renewable and affordable energy and sustainable and efficient transport infrastructure and services, where possible, achieving the benefits of connectivity and reducing the financial, environmental and public health costs of inefficient mobility, congestion, air pollution, urban heat island effects and noise. We also commit ourselves to giving particular attention to the energy and transport needs of all people, particularly the poor and those living in informal settlements. We also note that reductions in renewable energy costs give cities and human settlements an effective tool to lower energy supply costs.\nPoint 79\nWe commit ourselves to promoting international, national, subnational and local climate action, including climate change adaptation and mitigation, and to supporting the efforts of cities and human settlements, their inhabitants and all local stakeholders as important implementers.\n\n\nSustainable Development Goals (SDG)\n\nTargets with measurable indicators for monitoring\n\nGoal 11\nMake cities and human settlements inclusive, safe, resilient and sustainable\n2018 SDG 11 issue brief\n\nInvesting in parks and green spaces in urban areas will help to amelioratethe urban heat island effect and improve air quality in urban spaces.\nWe work with national coordination units that support integrated urban planning and mapping and promote sustainable heating and cooling in related and cross-sector policy frameworks at multiple levels\n\nCOP26\nFollowing 2021 United Nations Climate Change Conference in Glasgow - beat the heat handbook\n\n\n\n1.3 Beat The Heat Handbook\n\nIf is the first full guide on UHI that suggests\n\nBaseline assessment\nKey factors to consider(p. 60) such as albedo, urban form, city zoning, green cover, heat maps (that mention satellite data) - Chapter 5\nFirst major document that calls for specific integration into policy\nHas many examples of mitigation…although some aren't in response to the UHI, they were in place before / an associated benefit is temperature reduction\n\n\n\nSuperblocks\n\n\n\nSource: Beating the Heat: A Sustainable Cooling Handbook for Cities. Image: regenerativedesign.world\n\n\nBackground\n\nThe idea has been proposed many times - dating back to Barcelona’s Plan Macià, 1932, and Josep Lluís Sert and Le Corbusier\nFirst superblock was in 1993\n\nSuperille (2016)\n\nCommunity did not want\nCars = less business…but at that time only 5% used cars\nGentrification concerns - 15 minute cities? Council used social housing then 120 other places\n\nFuture\n\nTransform mobility (2024 Urban Mobility Plan)\n67Km more bus lanes that align with superblocks\nGreen axes\n\n\n\nMedellín Green Corridors\n\nRapid and uncontrolled growth\n2016-2019 Government Plan = Medellín, Environmental Urbanism\nRestore green corridors\n\n36 corridors\nAlong 18 roads and waterways\nReduced temperature 4 degrees Celsius\n\n\n\n\nSydney’s western suburbs\n\nTurn Down the Heat Strategy and Action Plan in 2018.\nAn in-depth assessment of the cooling landscape was foundational to the development of this comprehensive Strategy and Action Plan and included aspects such as:\n\nAssessment of the current state of urban heat in Western Sydney today;\nThe future of urban heat in Western Sydney, highlighting the increasing severity and frequency of heat waves; impacts of urban heat on people, infrastructure, the economy and the environment; ans taking stock of the existing work across Western Sydney to address heat.\n\n\n\n\nReflections\n\nUseful as it is first real guidance that states this should become part of city planning / policy\n\nIt doesn’t actually give specifics\n\nHow are you meant to use data to solve these problems?\nWhat sort of planning rules need to be changed\nDo all cities have appropriate staff (a GIS team?) to solve these challenges\nIs there sufficient interest within local / metropolitan / national government\nIs there buy in from the public\n\n\n\nDoes provide some useful project ideas\n\nAssessing or determining the potential for reflective roofs / pavements / sidewalks\nCommunity engagement\n2021 Cool Roads Trial in Western Sydney\nAccessibility to cool or green spaces / heat inequity\nDisparities in the way communities are planned, developed, and maintained\nDeveloping countries, which area has access to cooler spaces?\n\n\n\n\n1.4 Metropolitan (city) policy / temperature reduction activities\n\nVoluntary\n\nChicago’s green roof\nBaltimore’s tree vouchers\n\n\n\nPolicy\nMetropolitan strategies\n\nPerth and Peel 3.5 million\nThe London Plan\nSingapore’s Master Plan\n\nLocal city mandates\n\nSeattle’s Green Factor\n\nIncreases the amount of and improves the quality of landscaping in new development\nDevelopment standards for certain areas require landscaping that meets a minimum Green Factor score\nYou must reach a minimum score established by the zoning of your property\ne.g. “Commercial and Neighborhood Commercial (NC1, NC2, NC3, C1, C2): Minimum score 0.30”\n\nBaton Rouge’s landscape ordinance\nFremantle’s Urban Forest:\n20% canopy coverage (2020) – AUD 2.57million\nMaintain and enhance vegetation\nIncrease quantity and distribution of green areas/tress (20% canopy coverage)\nEncourage greening of hard surfaces (e.g. parking) and in private realm\nFirst city to use data to inform their cooling / greening strategy\nTemperature image from one day in January\nBelieve this is from Landsat data (see practical), 30 m data that has been aggregated to block (street block level)\n\n\n\n\n1.5 Rethinking planning requirements\n\nPerth Metropolitan Area\nFollows the original landscape ordinance of 10% of any gross sub divisible area required for open space\n\nUnaltered since Stephenson– Hepburn metropolitan regional plan was legislated in 1955\nBased on population density values, with an assumed number of persons likely to be housed across various residential codes\nGrose (2017) = gross underestimtation of open space\n\n\n\nSingapore\nSingapore’s 2011 open space provisioning is defined as 4.05 m2 for every 56.0 m2 of gross floor area Detailed landscaping requirements such as grass coverage, tree girth, and minimum branches, yet excludes landscape arrangement conditions\n\n\nA Data-Driven Approach for Mitigating Urban Heat\n\n\n\nSource: MacLachlan et al. 2021\n\n\n\nMean radiant temperature (MRT), this is the temperature that surrounds a point\n\n\nLow density is the statistical area of Currambine – North of Perth.\nHigh density is from the city of Subiaco, West of Perth. Follows the Subiaco Redevelopment Scheme which supersedes the Metropolitan Region Scheme. It seeks improved social, economic and environmental development outcomes and transformed underutilized industrial land.\nIn 2011 – population density was very similar, now Subiaco has more than double the density of Currambine with lower temperatures of between 1 and 0.6 degree Celsius dependent on land cover.\nRan 4 scenarios:\n\nOriginal (existing) development (from satellite imagery)\nProposed redevelopment as in the plan\nProposed redevelopment removing trees\nProposed redevelopment with trees covering the hottest pixels\n\nOn average reduced temperature by 0.8 degrees Celsius across the study area.\n\n\n\nMaking sense of this\n\nThere is a gap between global, metropolitan, local policy and data analysis\nThe analysis needs to solve the problem and be usable\nShould we focus on equal access/ distribution or equitable access / distribution or providing environmental justice\nAre policies themselves the problem\nHow could other cities use the same methods - e.g. could Sydney use the same temperature approach as Fremantle.\n\n\n\n\n1.6 Approaching projects\n\nFirst\n\nSearch for EO data…we have seen (or will see) the following data\n\nTemperature\nLandcover\nPollution\nElevation\nTexture / Spectral\nNot constrained to this list\n\nIdentify an issue (look at local policy documents)\nLook at global policy documents (to see the link)\n\n\n\nSecond\n\nWhat can be solved with the data\nWhat could this data contribute to another question (e.g. including it as a variable)\nHow could the remotely sensed data be included within a data workflow\nAnything else as long as it includes EO data (or some sort, at some stage) and analysis for solving a policy question"
  },
  {
    "objectID": "WEEK8.html#summary-practical",
    "href": "WEEK8.html#summary-practical",
    "title": "WEEK 8",
    "section": "2 Summary: practical",
    "text": "2 Summary: practical\n\nThis week’s practical will consist mainly of the following:\n\nExploring the UHI in GEE using Landsat and MODIS.\nExploration of time series data\nPlot the average temperature in R to explore UHI.\n\n\nIn this week’s practical, I have used Landsat and MODIS data for Beijing and followed the practical’s instructions to plot the average temperature of Beijing to analyse and visualise the urban heat island (UHI) effect, in addition to plotting a time series of MODIS data.\n\n\n\nMean summer temperature in Beijing."
  },
  {
    "objectID": "WEEK8.html#application",
    "href": "WEEK8.html#application",
    "title": "WEEK 8",
    "section": "3 Application",
    "text": "3 Application\n\nThis week’s learning covers the theory and analysis of the urban heat island (UHI) effect and a discussion of policies related to remote sensing, so the application of remote sensing in response to UHI effect policies will be explored.\n\n\n3.1 Applications of remote sensing in response to UHI\nRemote sensing can be used to obtain a large amount of image data, thus enabling monitoring, analysis and assessment of the urban heat island effect, and thus responding to policy.\nOn the one hand, remote sensing can enable monitoring of the urban heat island effect. Monitoring can use satellite remote sensing and drone remote sensing technology to conduct high-precision infrared thermal imaging of the city and its surrounding areas to obtain the spatial distribution characteristics of the urban heat field. Based on the monitoring results, the government can formulate targeted policies and implement different regulatory measures for the urban heat island effect in different areas.\nOn the other hand, remote sensing can also evaluate the implementation of urban heat island effect policies. Through the time series data obtained by remote sensing technology, the urban heat island effect before and after the implementation of the policy can be compared and analysed, and the effect of the policy can then be evaluated.\n\n\n3.2 Application case\n\n\n\n\n\n\nSourse\n\n\n\nModelling the urban heat island effect of smart growth policy scenarios in Brisbane , Sourse: Deilami and Kamruzzaman (2017)\n\n\nSmart growth policy has been identified as a panacea to tackle a range of undesirable outcomes of sprawl development. Various neighbourhood planning concepts have been developed following smart growth principles such as transit oriented development, and infill development. Existing empirical studies, however, do not answer to a key policy question: can smart growth policies reduce the urban heat island (UHI) effect? If so, what type of smart growth policy would be most effective? This research examined the questions by deriving five alternative neighbourhood planning scenarios for Brisbane for 2023: a) business as usual, b) transit oriented development (TOD), c) infill development, d) motorway corridor oriented development, and e) sprawl development. The research utilises Landsat remote sensing images of 1991, 2004, and 2013 to: first, estimate and validate a Geographically Weighted Regression model in order to identify statistically significant factors influencing the UHI intensities in Brisbane; and second, predict the UHI intensities of the five policy scenarios. Two factors were identified to have significant influence on the UHI intensities in Brisbane: population density, and porosity.\n\n\n\nSpatial patterns of the UHI intensities in Brisbane: a) 1991, b) 2004, and c) 2013.\n\n\nResults show that compared to the 2004 and 2013 levels, Brisbane will respectively experience a higher and lower levels of UHI effect in 2023, irrespective of the policy scenarios. On average, the infill development scenario, as a smart growth policy, has a marginally better potential to mitigate the UHI effect in Brisbane in 2023 compared to the sprawl development scenario conditional on the definition applied in this research. The UHI effect would be more equitably balanced spatially under the sprawl development scenario.\n\n\n\nSpatial patterns of the projected UHI intensities for Brisbane for 2023: a) business as usual scenario, b) transit oriented development scenario, c) infill development scenario, d) motorway corridor development scenario, and e) sprawl development scenario.\n\n\n\n\n3.3 Case comments\nAdvantages or contribution\n\nThe study employs remote sensing techniques and geo-weighted regression models, which can provide effective estimates and predictions of the heat island effect and assist in scientific decision-making for policy.\nThe study considers the impact of different neighbourhood planning scenarios on the heat island effect, providing a valuable reference for urban planning and policy formulation.\nThe study finds that infill development as a smart growth policy has good potential to mitigate the heat island effect, which provides important insights for promoting sustainable urban development.\n\nDisadvantages or potential\n\nThe policy options adopted in the study may have uncertainties and limitations and are not necessarily optimal, and the impact of different policy options on the heat island effect at the societal level needs to be further explored.\nOther factors that may affect the heat island effect, such as climate change and land use change, are not addressed in the study and need further research and analysis."
  },
  {
    "objectID": "WEEK8.html#reflection",
    "href": "WEEK8.html#reflection",
    "title": "WEEK 8",
    "section": "4 Reflection",
    "text": "4 Reflection\nPolicy making is often a complex process that requires both scientific and rational judgment to ensure that the policy can bring positive benefits to the society; and to weigh the interests of different groups to ensure benefits while taking into account equity, while the balance between equity and benefits is a difficult point to grasp.\nIn the formulation of urban policies, the assistance of remote sensing can be good for the science of policies, such as this week’s case to judge the trend of urban heat island effect by predicting different smart growth patterns, and urban planning plays an important role as a policy tool in it. Thus the combination of remote sensing and urban planning can largely contribute to the virtuous promotion of urban policies.\n\n\n\n\nDeilami, Kaveh, and Md. Kamruzzaman. 2017. “Modelling the Urban Heat Island Effect of Smart Growth Policy Scenarios in Brisbane.” Land Use Policy 64 (May): 38–55. https://doi.org/10.1016/j.landusepol.2017.02.027."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Abbas, Sawaid, Qian Peng, Man Sing Wong, Zhilin Li, Jicheng Wang, Kathy\nTze Kwun Ng, Coco Yin Tung Kwok, and Karena Ka Wai Hui. 2021.\n“Characterizing and Classifying Urban Tree Species Using\nBi-Monthly Terrestrial Hyperspectral Images in Hong\nKong.” ISPRS Journal of Photogrammetry and\nRemote Sensing 177 (July): 204–16. https://doi.org/10.1016/j.isprsjprs.2021.05.003.\n\n\nDeilami, Kaveh, and Md. Kamruzzaman. 2017. “Modelling the Urban\nHeat Island Effect of Smart Growth Policy Scenarios in\nBrisbane.” Land Use Policy 64 (May): 38–55.\nhttps://doi.org/10.1016/j.landusepol.2017.02.027.\n\n\nDeng, J. S., K. Wang, Y. H. Deng, and G. J. Qi. 2008.\n“PCA‐based Land‐use Change Detection and Analysis\nUsing Multitemporal and Multisensor Satellite Data.”\nInternational Journal of Remote Sensing 29 (16): 4823–38. https://doi.org/10.1080/01431160801950162.\n\n\nErdem Okumus, Deniz, and Fatih Terzi. 2021. “Evaluating the Role\nof Urban Fabric on Surface Urban Heat Island: The Case of\nIstanbul.” Sustainable Cities and Society\n73 (October): 103128. https://doi.org/10.1016/j.scs.2021.103128.\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A.\nTyukavina, D. Thau, et al. 2013. “High-Resolution\nGlobal Maps of 21st-Century\nForest Cover Change.”\nScience 342 (6160): 850–53. https://doi.org/10.1126/science.1244693.\n\n\nHermosilla, T., L. A. Ruiz, J. A. Recio, and M. Cambra-López. 2012.\n“Assessing Contextual Descriptive Features for Plot-Based\nClassification of Urban Areas.” Landscape and Urban\nPlanning 106 (1): 124–37. https://doi.org/10.1016/j.landurbplan.2012.02.008.\n\n\nHuang, Xiaoman, Annemarie Schneider, and Mark A. Friedl. 2016.\n“Mapping Sub-Pixel Urban Expansion in China Using\nMODIS and DMSP/OLS Nighttime\nLights.” Remote Sensing of Environment 175 (March):\n92–108. https://doi.org/10.1016/j.rse.2015.12.042."
  }
]